{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea3b7cc-8ead-4343-a437-bc0fbfc28ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c1d2dc-4959-4a79-b27a-77acbc54e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from fastai.data.all import *\n",
    "from fastai.text.models.core import *\n",
    "from fastai.text.models.awdlstm import *\n",
    "from xcube.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204a2ebb-00ba-4295-9717-2f800a36ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b4e9f7-bc4b-454a-abb3-d7af066b7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp text.models.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19621d0-6614-40f5-ab68-b1b2d29725a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb9980-a025-45bc-a614-0bcb621bea72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Core text modules\n",
    "\n",
    "> Contain the modules common between different architectures and the generic functions to get models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c319081-5bc4-4dca-a277-e725860f2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_model_meta = {AWD_LSTM: {'hid_name':'emb_sz', 'url':URLs.WT103_FWD, 'url_bwd':URLs.WT103_BWD,\n",
    "                          'config_lm':awd_lstm_lm_config, 'split_lm': awd_lstm_lm_split,\n",
    "                          'config_clas':awd_lstm_clas_config, 'split_clas': awd_lstm_clas_split},}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d811afdb-22d7-4e86-b15a-77b63e1a511e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1c5748-ef36-401c-bc6b-72f0fcb4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SequentialRNN(nn.Sequential):\n",
    "    \"A sequential pytorch module that passes the reset call to its children.\"\n",
    "    def reset(self):\n",
    "        for c in self.children(): getattr(c, 'reset', noop)()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b84e3-067f-4110-9546-3500b69ceff2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e098324-afd1-41ed-9d3e-a4f040f7a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _pad_tensor(t, bs):\n",
    "    if t.size(0) < bs: return torch.cat([t, t.new_zeros(bs-t.size(0), *t.shape[1:])])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff116dfc-1388-4dd6-81f1-3e618ccac43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SentenceEncoder(Module):\n",
    "    \"Create an encoder over `module` that can process a full sentence.\"\n",
    "    def __init__(self, bptt, module, pad_idx=1, max_len=None): store_attr('bptt,module,pad_idx,max_len')\n",
    "    def reset(self): getattr(self.module, 'reset', noop)()\n",
    "\n",
    "    def forward(self, input):\n",
    "        bs,sl = input.size()\n",
    "        self.reset()\n",
    "        mask = input == self.pad_idx\n",
    "        outs,masks = [],[]\n",
    "        for i in range(0, sl, self.bptt):\n",
    "            #Note: this expects that sequence really begins on a round multiple of bptt\n",
    "            real_bs = (input[:,i] != self.pad_idx).long().sum()\n",
    "            o = self.module(input[:real_bs,i: min(i+self.bptt, sl)])\n",
    "            if self.max_len is None or sl-i <= self.max_len:\n",
    "                outs.append(o)\n",
    "                masks.append(mask[:,i: min(i+self.bptt, sl)])\n",
    "        outs = torch.cat([_pad_tensor(o, bs) for o in outs], dim=1)\n",
    "        mask = torch.cat(masks, dim=1)\n",
    "        return outs,mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c0410-fe06-471b-a8f2-97045891bfe5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73de757-737b-4371-a6d8-2819180b1091",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emb_sz': 400,\n",
       " 'n_hid': 1152,\n",
       " 'n_layers': 3,\n",
       " 'pad_token': 1,\n",
       " 'bidir': False,\n",
       " 'hidden_p': 0.3,\n",
       " 'input_p': 0.4,\n",
       " 'embed_p': 0.05,\n",
       " 'weight_p': 0.5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = awd_lstm_clas_config.copy()\n",
    "del config['output_p']\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba46e005-7bbd-4738-b0fe-9c5eae1b86b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceEncoder(\n",
       "  (module): AWD_LSTM(\n",
       "    (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60008, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = SentenceEncoder(72, AWD_LSTM(vocab_sz=60008, **config), pad_idx=1, max_len=72*20).cuda()\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d355c2-825a-4bb9-aae9-da6b3d56bb78",
   "metadata": {
    "tags": []
   },
   "source": [
    "> Warning: This module expects the inputs padded with most of the padding first, with the sequence beginning at a round multiple of bptt (and the rest of the padding at the end). Use `pad_input_chunk` to get your data in a suitable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cbbcff-6828-4e9e-9fed-2fe7ec1ab0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def masked_concat_pool(output, mask, bptt):\n",
    "    \"Pool `MultiBatchEncoder` outputs into one vector [last_hidden, max_pool, avg_pool]\"\n",
    "    lens = output.shape[1] - mask.long().sum(dim=1)\n",
    "    last_lens = mask[:,-bptt:].long().sum(dim=1)\n",
    "    avg_pool = output.masked_fill(mask[:, :, None], 0).sum(dim=1)\n",
    "    avg_pool.div_(lens.type(avg_pool.dtype)[:,None])\n",
    "    max_pool = output.masked_fill(mask[:,:,None], -float('inf')).max(dim=1)[0]\n",
    "    x = torch.cat([output[torch.arange(0, output.size(0)),-last_lens-1], max_pool, avg_pool], 1) #Concat pooling.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8ef957-8ac6-40a4-bbb1-693d9b6738f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = to_device(torch.randint(low=0, high=60008, size=(128, 18398)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5de1239f-e073-4546-aed1-4b72d198bb2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out, mask = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc8dfda-9f5d-4297-bc33-6e212ef56d14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1406, 400]), torch.Size([128, 1406]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94171767-3926-4a8b-b13b-a304b366918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PoolingLinearClassifier(Module):\n",
    "    \"Create a linear classifier with pooling\"\n",
    "    def __init__(self, dims, ps, bptt, y_range=None):\n",
    "        if len(ps) != len(dims)-1: raise ValueError(\"Number of layers and dropout values do not match.\")\n",
    "        acts = [nn.ReLU(inplace=True)] * (len(dims) - 2) + [None]\n",
    "        layers = [LinBnDrop(i, o, p=p, act=a) for i,o,p,a in zip(dims[:-1], dims[1:], ps, acts)]\n",
    "        if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.bptt = bptt\n",
    "\n",
    "    def forward(self, input):\n",
    "        out,mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        x = self.layers(x)\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "709afd48-96e6-474d-847a-03bbeab7ac9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1200])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = masked_concat_pool(out, mask, bptt=72)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1f904-1006-488c-990f-136915d6a235",
   "metadata": {},
   "source": [
    "The output of `masked_concat_pool` is fed into the decoder. So Let's now check out the decoder which compresses the incoming features (in this case 1200) to 50 linear features and then outputs the number of classes (in this example 6594)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fd6824d-39df-4f8f-a61e-1788750d70b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolingLinearClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.04, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [1200, 50, 6594]\n",
    "ps = [0.04, 0.1]\n",
    "decoder = PoolingLinearClassifier(layers, ps, bptt=72).cuda()\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e2302f0-50e3-48bc-ad3e-b9ce86d7ab68",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds, *_ = decoder((out, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "118c6390-6700-4295-92fb-c08a36f8aad6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4707918c-b0ff-4a1d-b175-3b8523eaed59",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d32cc-82d6-417c-9d63-7bfeba1a5263",
   "metadata": {
    "tags": []
   },
   "source": [
    "Breaking down the `PoolingLinearClassifier.__init__`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d473ae-1eb1-463a-ad01-a1390c23e7e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that in the `__init__` while creating `PoolingLinearClassifier` `dims` is `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e9bb1-ffea-4d9e-aaa4-00895bb9174b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims = [1200, 50, 6594]\n"
     ]
    }
   ],
   "source": [
    "dims = layers\n",
    "print(f\"{dims = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7c827-98c5-424c-8219-9595e5fff51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps = [0.04000000000000001, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{ps = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d3aad-c229-4c5c-b3d7-9c0c05d0ac1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Also note that `bptt` is `seq_len`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf407421-4bca-422b-82fa-52b06bd56f38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bptt = 72\n"
     ]
    }
   ],
   "source": [
    "bptt = seq_len\n",
    "print(f\"{bptt = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f26d4-f483-4084-aa63-7afd7b68d049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_range = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e832e-f1f1-4f91-b632-4713e8f153e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(ps) != len(dims) - 1: raise ValueError(\"Number of layers and dopout values do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5b9df-836c-45b5-81d2-9063aaaa007c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ReLU(inplace=True), None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts = [nn.ReLU(inplace=True)] * (len(dims) - 2) + [None]\n",
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b04422-b855-4b64-8323-128b3d5a0637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1200, o = 50, p = 0.04000000000000001, a = ReLU(inplace=True)\n",
      "i = 50, o = 6594, p = 0.1, a = None\n"
     ]
    }
   ],
   "source": [
    "for i, o, p, a in zip(dims[:-1], dims[1:], ps, acts):\n",
    "    print(f\"{i = }, {o = }, {p = }, {a = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c1eef-7b7b-49af-8266-c5d24d6c66bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LinBnDrop(\n",
       "   (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): Dropout(p=0.04000000000000001, inplace=False)\n",
       "   (2): Linear(in_features=1200, out_features=50, bias=False)\n",
       "   (3): ReLU(inplace=True)\n",
       " ),\n",
       " LinBnDrop(\n",
       "   (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): Dropout(p=0.1, inplace=False)\n",
       "   (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       " )]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [LinBnDrop(i, o, p=p, act=a) for i, o, p, a in zip(dims[:-1], dims[1:], ps, acts)]\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d11a33-b94d-40d2-9632-3f8d11549299",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f56bd99-2f56-4053-9792-7555b7893064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OurPoolingLinearClassifier(Module):\n",
    "    def __init__(self, dims, ps, bptt, y_range=None):\n",
    "        self.layer = LinBnDrop(dims[0], dims[1], p=ps, act=None)\n",
    "        self.bptt = bptt\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        x = self.layer(x)\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae922f0-c0cc-4842-a2f9-23670ace4ade",
   "metadata": {},
   "source": [
    "Note that `OurPoolingLinearClassifier` is exactly same as fastai's `PoolingLinearClassifier` except that we do not do the feature compression from 1200 to 50 linear features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ae080b2-a9cf-4dc7-8ef6-ecd11be76e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder = OurPoolingLinearClassifier(dims=[1200, 6594], ps=0.04, bptt=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba36050b-80b7-4675-b68e-6587e465d6e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OurPoolingLinearClassifier(\n",
       "  (layer): LinBnDrop(\n",
       "    (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.04, inplace=False)\n",
       "    (2): Linear(in_features=1200, out_features=6594, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9d961-79ea-4342-874e-f9e10fb60daf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note: Also try `OurPoolingLinearClassifier` w/o dropouts and batch normalization (Verify this, but as far as what I found it does not work well as compared to /w batch normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c85678-04c1-4a62-83f4-f112d34c5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LabelAttentionClassifier(Module):\n",
    "    def __init__(self, dims, ps, bptt, y_range=None):\n",
    "        self.lbs = dims[-1] \n",
    "        self.fts = dims[0]//3\n",
    "        # self.layers = LinBnDrop(self.lbs, self.fts, p=ps, act=None) # wrong_deb\n",
    "        \n",
    "        # ps = 0.1 # deb\n",
    "        self.layers = LinBnDrop(self.lbs, ln=False, p=ps, act=None) # deb\n",
    "        self.bptt = bptt\n",
    "        self.emb_label = Embedding(self.lbs, self.fts) # deb\n",
    "        self.final_lin = nn.Linear(self.fts, self.lbs) \n",
    "\n",
    "    def forward(self, input):\n",
    "        out, _ = input\n",
    "        # x = masked_concat_pool(out, mask, self.bptt)\n",
    "        \n",
    "        bs = out.shape[0]\n",
    "        # ctx = out.new_zeros((bs, self.lbs, self.fts))\n",
    "        # for out_split in torch.split(out, 1, dim=1):\n",
    "        attn_wgts = out @ self.emb_label.weight.transpose(0, 1) # deb\n",
    "        attn_wgts = F.softmax(attn_wgts, 1) # deb\n",
    "        # attn_wgts = torch.nn.functional.log_softmax(attn_wgts, 1) # deb\n",
    "        # attn_wgts = torch.log(attn_wgts)/(attn_wgts.sum(dim=1, keepdim=True) + 1e-12)\n",
    "        # attn_wgts[torch.isnan(attn_wgts)] = tensor(0.)\n",
    "        # attn_wgts = torch.nn.functional.normalize(torch.log(attn_wgts), dim=1)\n",
    "        ctx = attn_wgts.transpose(1,2) @ out # deb\n",
    "\n",
    "        x = self.layers(ctx)\n",
    "        # x = self.final_lin.weight.mul(x).sum(dim=2).add(self.final_lin.bias) #missed_deb\n",
    "        x = (self.final_lin.weight * x).sum(dim=2)\n",
    "        \n",
    "        # x = x.view(x.shape[0], x.shape[1])\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600bc6c3-723b-440b-ac36-268a1de404bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f68980b9-2d41-4504-959a-f670125e38f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelAttentionClassifier(\n",
       "  (layers): LinBnDrop(\n",
       "    (0): BatchNorm1d(6594, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (emb_label): Embedding(6594, 400)\n",
       "  (final_lin): Linear(in_features=400, out_features=6594, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = LabelAttentionClassifier([1200, 6594], ps=0.04, bptt=72).cuda()\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce16e252-7c0a-4187-9785-b79b0fb39905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, *_ = decoder((out, None))\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2edaf0-4b2c-4424-87a4-9b8c548da909",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4ad25-394c-4c39-aa2b-8f806a27126e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Breaking down `LabelAttentionClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c21e9b06-7425-4b99-9958-c4ce90e5c596",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6594, 400])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.emb_label.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "419afd16-0d1e-4100-8013-d5384ab348af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1406, 400]), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, out.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38ed6d03-c45f-431a-8471-668048f8f95a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1406, 6594]), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_wgts = out @ decoder.emb_label.weight.transpose(0,1)\n",
    "attn_wgts.shape, attn_wgts.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f4bcc24-7d0b-4c61-bbd6-900d844fec79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn_wgts = F.softmax(attn_wgts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbce3e2a-d205-46aa-97f7-4ac06725d155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attn_wgts = None\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582372d8-3259-494f-8969-fe2e4d202255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#out[:, :, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b3703d1-3bb0-4fcd-98ca-768539f811ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1406])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_wgts.transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06366c01-a872-4a36-9b20-b5bf942c39e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = attn_wgts.transpose(1,2) @ out\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f41e16a7-8363-446d-b8e3-75a58b74921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(10).reshape(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1d78289-cfc6-4c5a-9e85-fec9f757d189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3],\n",
       "         [4, 5],\n",
       "         [6, 7],\n",
       "         [8, 9]]),\n",
       " torch.Size([5, 2]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "819c6172-d47a-43f7-a6a6-fa686ed584ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]]) torch.Size([2, 2])\n",
      "****\n",
      "tensor([[4, 5],\n",
      "        [6, 7]]) torch.Size([2, 2])\n",
      "****\n",
      "tensor([[8, 9]]) torch.Size([1, 2])\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "for a_split in torch.split(a, 2): print(a_split, a_split.shape, end='\\n****\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c07db-8d92-4b5c-90de-28a580b73ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a3b07-33e6-4e35-9e8f-7223156c932a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a177d9e-b78b-45e1-92cc-812918305e00",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914f7b3e-f778-4758-bfb1-6eed725de8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_classifier(arch, vocab_sz, n_class, seq_len=72, config=None, drop_mult=1., lin_ftrs=None,\n",
    "                       ps=None, pad_idx=1, max_len=72*20, y_range=None):\n",
    "    \"Create a text classifier from `arch` and its `config`, maybe `pretrained`\"\n",
    "    meta = _model_meta[arch]\n",
    "    config = ifnone(config, meta['config_clas']).copy()\n",
    "    for k in config.keys():\n",
    "        if k.endswith('_p'): config[k] *= drop_mult\n",
    "    if lin_ftrs is None: lin_ftrs = [50]\n",
    "    if ps is None: ps = [0.1]*len(lin_ftrs) # not required if not using OurPoolingLinearClasifier\n",
    "#     layers = [config[meta['hid_name']] * 3] + lin_ftrs + [n_class]  # required if using fastai's PoolingLinearClassifier\n",
    "    layers = [config[meta['hid_name']] * 3] + [n_class]\n",
    "#     ps = [config.pop('output_p')] + ps\n",
    "    ps = config.pop('output_p')\n",
    "    init = config.pop('init') if 'init' in config else None\n",
    "    encoder = SentenceEncoder(seq_len, arch(vocab_sz, **config), pad_idx=pad_idx, max_len=max_len)\n",
    "    decoder = OurPoolingLinearClassifier(layers, ps, bptt=seq_len, y_range=y_range)\n",
    "    # decoder = LabelAttentionClassifier(layers, ps, bptt=seq_len, y_range=y_range)\n",
    "    model = SequentialRNN(encoder, decoder)\n",
    "    return model if init is None else model.apply(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2a15e0-19b3-4d4b-9289-9f30566b4f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_text.models.core.ipynb.\n",
      "Converted 03_text.learner.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
