{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: arch_research.html\n",
    "title: import pdb; pdb.set_trace()\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3faeb-7634-4c78-9937-d474b07cd5f4",
   "metadata": {},
   "source": [
    "## `Learner` for Multi-Label Classifier Fine-Tuning (Frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28ccf9-c660-4cfa-b0d4-693b1bbd1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_clas = torch.load(path_model/'dls_clas_full_64.pkl')\n",
    "# dls_clas = torch.load(path_model/'dls_clas_sample_64.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ff287c-d390-47d7-a3de-2b018d097f4d",
   "metadata": {},
   "source": [
    "### Architecture Creation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d2bea-0ec7-4364-a331-db6d166128b9",
   "metadata": {},
   "source": [
    "To create an architecture that we can use to build a `model` we need to unwrap fastai's `get_text_classifier`. Let's do that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b243366-ed83-4ff6-996e-300b9c6afba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_text_classifier(AWD_LSTM,\n",
    "#                             len(vocab),\n",
    "#                             n_out,\n",
    "#                             seq_len=seq_len,\n",
    "#                             config=config,\n",
    "#                             y_range=y_range,\n",
    "#                             drop_mult=drop_mult,\n",
    "#                             lin_ftrs=lin_ftrs,\n",
    "#                             max_len=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d026e67-851c-4bd1-811f-71743e9061d2",
   "metadata": {},
   "source": [
    "The following is a dictionary where keys are the well known (possibly pretarianed) NLP architectures and values are the configurations, urls (where we can download the pretrained weights from) and other info we need to create that architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9672d84-2658-47dd-a888-c2b2b10d90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_meta = {\n",
    "    AWD_LSTM: {'hid_name':'emb_sz', 'url':URLs.WT103_FWD, 'url_bwd':URLs.WT103_BWD,'config_lm':awd_lstm_lm_config, 'split_lm': awd_lstm_lm_split,            \n",
    "                'config_clas':awd_lstm_clas_config, 'split_clas': awd_lstm_clas_split\n",
    "              }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82493cf5-2976-46f4-9dd4-a5923af65e8a",
   "metadata": {},
   "source": [
    "Let's define an architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be173ae2-2f01-4329-bc04-d722e33b2942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.models.awdlstm.AWD_LSTM"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = AWD_LSTM\n",
    "arch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29378c5-4a00-4ee4-b9aa-f63070d7bfc3",
   "metadata": {},
   "source": [
    "Let's get the value (information) of that architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b059582-e4f1-4247-8a67-c41da626d050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hid_name': 'emb_sz',\n",
       " 'url': 'https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz',\n",
       " 'url_bwd': 'https://s3.amazonaws.com/fast-ai-modelzoo/wt103-bwd.tgz',\n",
       " 'config_lm': {'emb_sz': 400,\n",
       "  'n_hid': 1152,\n",
       "  'n_layers': 3,\n",
       "  'pad_token': 1,\n",
       "  'bidir': False,\n",
       "  'output_p': 0.1,\n",
       "  'hidden_p': 0.15,\n",
       "  'input_p': 0.25,\n",
       "  'embed_p': 0.02,\n",
       "  'weight_p': 0.2,\n",
       "  'tie_weights': True,\n",
       "  'out_bias': True},\n",
       " 'split_lm': <function fastai.text.models.awdlstm.awd_lstm_lm_split(model)>,\n",
       " 'config_clas': {'emb_sz': 400,\n",
       "  'n_hid': 1152,\n",
       "  'n_layers': 3,\n",
       "  'pad_token': 1,\n",
       "  'bidir': False,\n",
       "  'output_p': 0.4,\n",
       "  'hidden_p': 0.3,\n",
       "  'input_p': 0.4,\n",
       "  'embed_p': 0.05,\n",
       "  'weight_p': 0.5},\n",
       " 'split_clas': <function fastai.text.models.awdlstm.awd_lstm_clas_split(model)>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = _model_meta[arch]\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d8bfa-77eb-4ad8-9ce4-118dc8a07d57",
   "metadata": {},
   "source": [
    "Let's now get the default configuration required to build that architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c9710-cda7-41d9-89f6-25f388670f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emb_sz': 400,\n",
       " 'n_hid': 1152,\n",
       " 'n_layers': 3,\n",
       " 'pad_token': 1,\n",
       " 'bidir': False,\n",
       " 'output_p': 0.4,\n",
       " 'hidden_p': 0.3,\n",
       " 'input_p': 0.4,\n",
       " 'embed_p': 0.05,\n",
       " 'weight_p': 0.5}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = None\n",
    "config = ifnone(config, meta['config_clas']).copy()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af924a-a373-4bd5-80b5-834c81bd64d0",
   "metadata": {},
   "source": [
    "Alternatively, we could have just grabbed the configuration provided by a fastai convenienece dictionary called `awd_lstm_clas_config`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e40059-4e2f-4024-9f46-67d5a3b1c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = awd_lstm_clas_config.copy()\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44274b09-27e8-476a-8dc8-69a59711deab",
   "metadata": {},
   "source": [
    "**Dropout**:  \n",
    "As we can see the the default configuration has some default dropout probabilities. We can use a multiplier to multiply with each of these probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a1a0e-b1ca-4405-8804-a5d2e6e8f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mult = 0.1\n",
    "for k in config.keys():\n",
    "    if k.endswith('_p'): config[k] *= drop_mult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75ec3f-153d-4b65-96d0-055a1491c332",
   "metadata": {},
   "source": [
    "NOT SURE (Find out later!) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2856e1-b27b-4017-8443-8993a6a28a13",
   "metadata": {},
   "source": [
    "Note: In fastai `ps` was $0.1$, we made it $0.01$ (because in extreme multi-label classification we want to drop out less activations, but need to investigate this later!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1dbade-00a5-4197-8705-268efdfa102b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.1], [50])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ftrs, ps = None, None\n",
    "if lin_ftrs is None: lin_ftrs = [50]\n",
    "if ps is None: ps = [0.1] * len(lin_ftrs)\n",
    "ps, lin_ftrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14872545-8fd2-47a8-a86b-b78467ff1b32",
   "metadata": {},
   "source": [
    "Let's find out the total number of classes from dls (becuase we need this info to build the architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57b74d-3fb1-4a33-ae6f-cccc7900be4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8922"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_out = get_c(dls_clas)\n",
    "n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5d450-f55a-498e-85a0-6d95aa24cb69",
   "metadata": {},
   "source": [
    "The embedding size as per the default config is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22addc6-2522-46f0-8bf4-499b0909c70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sz = config.get('emb_sz')\n",
    "emb_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ec593-c17c-4cf1-ad21-f2f9ab534d21",
   "metadata": {},
   "source": [
    "The decoder for text classification will be a `PoolingLinearClassifier` with two linear layers:\n",
    "- the first layer will have number of input features 1200 and number of output features 50\n",
    "- the second layer will have number of input features 50 and number of output features equal to `n_out`\n",
    "\n",
    "Let's make these layer configuarion in a list called `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e72dcd-406d-40ec-8f63-a94f26c62533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1200, 50, 8922]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [emb_sz * 3] + lin_ftrs + [n_out]\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce11aaa-70e5-40fb-ab6e-f512e22a0a1c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4960601-cdda-4565-9e67-0836129e8334",
   "metadata": {},
   "source": [
    "**IMPORTANT**: \n",
    "\n",
    "In fastai the number of output features coming out was 400. Then we did a `masked_concat_pool` so the final output fed to the `PoolingLinearClassifier` was 1200. In order to implement **attention** we concat a context of 400 to those previous 1200 features. So the total number output features with attention is 1200+400=1600. Hence the change below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c8b41-2c6a-4fa5-87b8-794efbe2e921",
   "metadata": {},
   "source": [
    "If using attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ea975-7d73-494d-90e5-fc1d6cd2865c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14275200, 50, 8922]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_attn = [n_out * (emb_sz * 3 + emb_sz) ] + lin_ftrs + [n_out]\n",
    "layers_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef896b-c219-4b9d-b590-a3445b855e3b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765953c-9cc7-452c-8e30-fb59ee32dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1]\n",
      "[0.04000000000000001, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(ps)\n",
    "ps = [config.pop('output_p')] + ps\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40fb16-679c-48cd-a1c0-f85970d94172",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = config.pop('init') if 'init' in config else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17279cf0-93ad-4dad-9ac0-157da62169d7",
   "metadata": {},
   "source": [
    "Now we have reached a point where we can make our Encoder (which in this case will be an AWD_LSTM that is the architecture that we are using). To make the `AWD_LSTM` module we need to pass the `vocab_sz` and the `config` dictionary (after peeling off `output_p` and `init`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f6cc5-a789-4064-974a-811a110cfa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60008"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = dls_clas.vocab[0]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47713b-05ee-4d67-8c60-447a34fa00ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch = <class 'fastai.text.models.awdlstm.AWD_LSTM'>, \n",
      "\n",
      " config = {'emb_sz': 400, 'n_hid': 1152, 'n_layers': 3, 'pad_token': 1, 'bidir': False, 'hidden_p': 0.03, 'input_p': 0.04000000000000001, 'embed_p': 0.005000000000000001, 'weight_p': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{arch = }, \\n\\n {config = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34312c1-a5d5-49ad-add8-d2142583fa6f",
   "metadata": {},
   "source": [
    "Let's take a look at how our AWD_LSTM model looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b08fba-e8a3-45a3-936b-c4383d0232ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.models.awdlstm.AWD_LSTM"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b479d2-ff43-40be-aead-91d6075c306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.update({'bidir': True})\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96969a7-b877-4a6c-b181-c22a3c922837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AWD_LSTM(\n",
       "  (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "  (encoder_dp): EmbeddingDropout(\n",
       "    (emb): Embedding(60008, 400, padding_idx=1)\n",
       "  )\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDropout(\n",
       "      (module): LSTM(400, 1152, batch_first=True)\n",
       "    )\n",
       "    (1): WeightDropout(\n",
       "      (module): LSTM(1152, 1152, batch_first=True)\n",
       "    )\n",
       "    (2): WeightDropout(\n",
       "      (module): LSTM(1152, 400, batch_first=True)\n",
       "    )\n",
       "  )\n",
       "  (input_dp): RNNDropout()\n",
       "  (hidden_dps): ModuleList(\n",
       "    (0): RNNDropout()\n",
       "    (1): RNNDropout()\n",
       "    (2): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch(vocab_sz=len(vocab), **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39e11e9-635a-4c0a-8bba-6acd76e87ce2",
   "metadata": {},
   "source": [
    "**An important thing (of immense practical importance) to note:**  \n",
    "Since we do not have infinite amount of GPU memory so we need to wrap our AWD_LSTM module inside a `SentenceEncoder`.  \n",
    "Need to elaborate further (later on!)\n",
    "\n",
    "fastai's `SentenceEncoder` takes the following positional and keyword arguments:\n",
    "- `bptt` (this is chunk size, mostly `seq_len`, the text document gets broken into)\n",
    "- `module` (this the module that we want to wrap a `SentenceEncoder` around)\n",
    "- `pad_idx` (has a default value of 1 everywhere in fastai)\n",
    "- `max_len` (has a default value 72 * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d1cd8-abc8-4350-9422-79b8f7478c96",
   "metadata": {},
   "source": [
    "We don't really need to write our own `SentenEncoder` we can just use fastai's. But it is exteremely important to understand this source code. So for the sake of completion we include it below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2c81d-a75e-4108-86db-4d683d434712",
   "metadata": {},
   "source": [
    "**IMPORTANT:** To make sure we look at the hidden state for each of the token in the entire document (meaning we want to be looking at `bs,seq_len,nh` where `seq_len` is the entire document length and not just `max_len`) before classifying, we need to let `SentenceEncoder` work with its default `max_len` (instead of passing something like $72*20$ which is what we would do for sentiment analysis)... [Elaborate this later explaining the difference between extreme multilabel classification and sentiment analysis...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce790755-1a92-4606-bfbd-2c760e5b906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceEncoder(\n",
       "  (module): AWD_LSTM(\n",
       "    (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60008, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 72\n",
    "# encoder = OurSentenceEncoder(seq_len, arch(vocab_sz=len(vocab), **config), pad_idx=1, max_len=seq_len*20)\n",
    "encoder = SentenceEncoder(seq_len, arch(vocab_sz=len(vocab), **config), pad_idx=1, max_len=seq_len*20)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5031496-c040-40e0-bb76-7e8b494ec2c7",
   "metadata": {},
   "source": [
    "So now have the encoder and ready to make the decoder. The decoder in this case would be a `PoolingLinearClassifier`. We will make it using the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184146b-867a-48b4-95b7-488a33d9861b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1200, 50, 8922], [0.04000000000000001, 0.1], 72)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_range = None\n",
    "layers, ps, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30364a6-c109-4658-8318-575be2c90c63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e5def-1d86-42b9-a8cd-82b29b88d551",
   "metadata": {},
   "source": [
    "If using attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4960558-8823-4f59-bb89-d39b1a34deb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([14275200, 50, 8922], [0.04000000000000001, 0.1], 72)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_attn, ps, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8398f1-4a17-46e5-8969-1079cefec7a2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e920d-748e-4948-894d-9bb10ff7aa68",
   "metadata": {},
   "source": [
    "Eventhough now we can just use fastai's `PoolingLinearClassifier`, but later on we will need to modify this module (to incorporate *attention*). So for the purpose of customizability let's copy the source code from fastai and (shamelessly) call it `OurPoolingLinearClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f6c24-6c0d-4085-8348-745875798a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurPoolingLinearClassifier(Module):\n",
    "    def __init__(self, dims, ps, bptt, y_range=None):\n",
    "        if len(ps) != len(dims)-1: raise ValueError(\"Number of layers and dropout values do not match.\")\n",
    "        acts = [nn.ReLU(inplace=True)] * (len(dims) - 2) + [None]\n",
    "        layers = [LinBnDrop(i, o, p=p, act=a) for i,o,p,a in zip(dims[:-1], dims[1:], ps, acts)]\n",
    "        if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.bptt = bptt\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        x = self.layers(x)\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92309296-c582-47c7-bdd0-6e44ba02f33b",
   "metadata": {},
   "source": [
    "#### Breaking down the `OurPoolingLinearClassifier.__init__`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0d14b-d337-4584-83d5-930c2c681fb8",
   "metadata": {},
   "source": [
    "Note that in the `__init__` while creating `OurPoolingLinearClassifier` `dims` is `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882175f7-89be-4233-8980-ef8646cbb77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims = [1200, 50, 6594]\n"
     ]
    }
   ],
   "source": [
    "dims = layers\n",
    "print(f\"{dims = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39990712-6988-4c6e-ac32-ba644ccba225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps = [0.04000000000000001, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{ps = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc954c-320e-4ffb-b8f3-ca1142e518ab",
   "metadata": {},
   "source": [
    "Also note that `bptt` is `seq_len`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e24c0-d75f-4eef-9d67-411e9bda6ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bptt = 72\n"
     ]
    }
   ],
   "source": [
    "bptt = seq_len\n",
    "print(f\"{bptt = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631364f6-dd90-492e-84e4-aa28d8b8f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a9a4d-dbc7-4459-9cc8-b4e625246980",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ps) != len(dims) - 1: raise ValueError(\"Number of layers and dopout values do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad916bdb-44ac-4ecf-80a6-54e765836c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ReLU(inplace=True), None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts = [nn.ReLU(inplace=True)] * (len(dims) - 2) + [None]\n",
    "acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832dcd3-bc3a-46e7-8d6a-bd0307685848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1200, o = 50, p = 0.04000000000000001, a = ReLU(inplace=True)\n",
      "i = 50, o = 6594, p = 0.1, a = None\n"
     ]
    }
   ],
   "source": [
    "for i, o, p, a in zip(dims[:-1], dims[1:], ps, acts):\n",
    "    print(f\"{i = }, {o = }, {p = }, {a = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a791c-618b-49a9-af9b-9af16cc7c045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LinBnDrop(\n",
       "   (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): Dropout(p=0.04000000000000001, inplace=False)\n",
       "   (2): Linear(in_features=1200, out_features=50, bias=False)\n",
       "   (3): ReLU(inplace=True)\n",
       " ),\n",
       " LinBnDrop(\n",
       "   (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): Dropout(p=0.1, inplace=False)\n",
       "   (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       " )]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [LinBnDrop(i, o, p=p, act=a) for i, o, p, a in zip(dims[:-1], dims[1:], ps, acts)]\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46590c56-ac3c-4125-88f9-1f6d30ffecc4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040464f-f9eb-4bfc-9758-56424649c15c",
   "metadata": {},
   "source": [
    "CAUTION: Work in Progress!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce22be58-351a-4b8c-b5c7-1d16a92f571a",
   "metadata": {},
   "source": [
    "#### Attempt #1: Implementing [CAML](https://arxiv.org/pdf/1802.05695.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28189b-91b1-4cac-851a-a2cb7f706519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAML1(Module):\n",
    "    def __init__(self, dims, ps, bptt):\n",
    "        layers = [LinBnDrop(dims[0], 50, p=ps, act=nn.ReLU(inplace=True))]\n",
    "        layers.append(LinBnDrop(50, n_out, p=0.1, act=None))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.bptt = bptt\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        x = self.layers(x)\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1ec4c-06ab-425c-a854-87b7641e06d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAML1(\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.04, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAML1(dims=[1200, 6594], ps=0.04, bptt=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e6beb-0304-4103-9385-9d2034b8eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAML2(Module):\n",
    "    def __init__(self, dims, ps, bptt):\n",
    "        self.layer = LinBnDrop(dims[0], dims[1], p=ps, act=None)\n",
    "        self.bptt = bptt\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        x = self.layer(x)\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9f9f8-5a33-49b6-965e-f886dd24b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = CAML2(dims=[1200, 8922], ps=0.04, bptt=seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab35d60-0b1a-499b-90dd-700d1dac9d6b",
   "metadata": {},
   "source": [
    "Note: Also try `CAML2` w/o dropouts and batch normalization (Verify this, but as far as what I found it does not work well as compared to /w batch normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6848c-9621-4a9c-9d73-a1a0a08eda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinBn2Drop(nn.Sequential):\n",
    "    \"Module grouping `BatchNorm2d`, `Dropout` and a `Linear` layer with just one output feature\"\n",
    "    def __init__(self, n_lbs, n_fts, bn=True, p=0., act=None, lin_first=False):\n",
    "        layers = [BatchNorm(n_lbs, ndim=1)] if bn else []\n",
    "        if p != 0: layers.append(nn.Dropout(p))\n",
    "        lin = [nn.Linear(n_fts, 1, bias=not bn)]\n",
    "        if act is not None: lin.append(act)\n",
    "        layers = lin+layers if lin_first else layers+lin\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782d9b6-8940-4d8a-a261-e42160c442de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAML3(Module):\n",
    "    def __init__(self, ps, bptt):\n",
    "        self.layers = LinBn2Drop(n_out, emb_sz, p=ps, act=None) # deb\n",
    "        self.bptt = bptt\n",
    "        self.emb_label = nn.Embedding(n_out, emb_sz) # deb\n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        out, _ = input\n",
    "        # breakpoint()\n",
    "        # x = masked_concat_pool(out, mask, self.bptt)\n",
    "        attn_wgts = out @ self.emb_label.weight.transpose(0, 1) # deb\n",
    "        attn_wgts = F.softmax(attn_wgts, 1) # deb\n",
    "        ctx = attn_wgts.transpose(1,2) @ out # deb\n",
    "        \n",
    "        x = self.layers(ctx)\n",
    "        x = x.view(x.shape[0], x.shape[1])\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe10c7-208a-4869-9d28-b21a78fd27ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAML3(\n",
       "  (layers): LinBn2Drop(\n",
       "    (0): BatchNorm1d(6594, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.04, inplace=False)\n",
       "    (2): Linear(in_features=400, out_features=1, bias=False)\n",
       "  )\n",
       "  (emb_label): Embedding(6594, 400)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAML3(ps=0.04, bptt=seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db614add-2c2b-45f3-aac5-c27805e44d80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2fbbc-969e-41a8-b720-b9c6427c0f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1406, 400]), device(type='cuda', index=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.randn((128, 1406, 400)).cuda()\n",
    "out.shape, out.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9033d-a010-4fed-ac6c-f8dda5de714d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1406, 6594]), device(type='cuda', index=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_wgts = torch.randn((128, 1406, 6594)).cuda()\n",
    "attn_wgts.shape, attn_wgts.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefa603-142a-461b-9d5a-1a601d42a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out[:, :, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848aed07-dd7e-478b-89dd-74efbd759516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1406])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_wgts.transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37df8ef-29d0-42aa-bfb8-fe2ef014fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = attn_wgts.transpose(1,2) @ out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7deb50c-e294-4df0-8218-4e928c9a9b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ca29e-a260-417e-9032-472d3fcb4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = CAML3(ps=0.04, bptt=seq_len).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5372ad-e488-4151-bdfe-f7d3279df849",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, *_ = test_model((out, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610edc5-2030-4b36-853b-1985711fa7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae9162-fa4b-4404-9b3b-864c9f1ac527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c00fcc-51c1-425e-a8fb-e59b6580626c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bddd4cb5-491d-494e-ad43-17b00dc531a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124d654-6430-472d-97d2-f034e80327c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAML4(Module):\n",
    "    def __init__(self, dims, ps, bptt):\n",
    "        self.layer = LinBnDrop(dims[0], dims[1], p=ps, act=None)\n",
    "        self.bptt = bptt\n",
    "#         self.emb_label = nn.Embedding(n_out, emb_sz) # deb\n",
    "#         self.linear_final = nn.Linear(emb_sz) \n",
    "\n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "#         attn_wgts = x @ self.emb_label.weight.transpose(0, 1) # deb\n",
    "#         attn_wgts = F.softmax(attn_wgts, 1) # deb\n",
    "#         ctx = out[:, :, None] * attn_wgts[..., None] # deb\n",
    "#         ctx = ctx.sum(1)\n",
    "        x = self.layer(x)\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194d391-1f22-4ab6-8c8e-bbc6c93428ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAML3(\n",
       "  (layers): LinBn2Drop(\n",
       "    (0): BatchNorm1d(6594, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.04, inplace=False)\n",
       "    (2): Linear(in_features=400, out_features=1, bias=False)\n",
       "  )\n",
       "  (emb_label): Embedding(6594, 400)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = CAML3(ps=0.04, bptt=seq_len)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f69743-c9c4-4e54-80bb-ec7b12d76f8c",
   "metadata": {},
   "source": [
    "#### Attempt #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c534a-fbd8-4c64-8662-a7f95f5dbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurPoolingAttentionClassifier(Module):\n",
    "    def __init__(self, dims, ps, bptt, y_range=None):\n",
    "        if len(ps) != len(dims)-1: raise ValueError(\"Number of layers and dropout values do not match.\")\n",
    "        acts = [nn.ReLU(inplace=True)] * (len(dims) - 2) + [None]\n",
    "        layers = [LinBnDrop(i, o, p=p, act=a) for i,o,p,a in zip(dims[:-1], dims[1:], ps, acts)]\n",
    "        if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.bptt = bptt\n",
    "        \n",
    "        # new\n",
    "        label_emb_sz=49\n",
    "        self.emb_label = nn.Embedding(n_out, emb_sz)\n",
    "        self.lin = nn.Linear(emb_sz, emb_sz)\n",
    "        self.lin_for_tok_red = nn.Linear(seq_len*20, 50)\n",
    "        self.lin_for_rep_compress = nn.Linear(emb_sz, label_emb_sz)\n",
    "        self.lin_for_rep_decompress = nn.Linear(label_emb_sz, emb_sz)\n",
    "        self.V = self._init_param(label_emb_sz)\n",
    "        # new\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        \n",
    "        # new\n",
    "        num_tok = out.shape[1]\n",
    "        out = F.pad(out, (0,0,0,seq_len*20-num_tok))\n",
    "        bs = out.shape[0]\n",
    "        label_indices = torch.arange(n_out, device=out.device)\n",
    "        labels = label_indices.repeat(bs, 1)\n",
    "        after_grabbing_label_embedding = self.emb_label(labels)\n",
    "        after_first_matmul = self.lin(after_grabbing_label_embedding)\n",
    "        \n",
    "        out = self.lin_for_rep_compress(out)\n",
    "        after_first_matmul = self.lin_for_rep_compress(after_first_matmul)\n",
    "        \n",
    "        out = out.permute(0,2,1).contiguous()\n",
    "        out = self.lin_for_tok_red(out)\n",
    "        out = out.permute(0,2,1).contiguous()\n",
    "        after_nonlinearity = torch.tanh(out[:, :, None] + after_first_matmul[:,None])\n",
    "        attn_wgts = (after_nonlinearity @ self.V)\n",
    "        ctx = (out[:, :, None] * attn_wgts[..., None])\n",
    "        ctx = ctx.sum(1)\n",
    "        \n",
    "        ctx = self.lin_for_rep_decompress(torch.relu(ctx))\n",
    "        \n",
    "        x = x[:, None]\n",
    "        x = x.repeat(1, n_out, 1)\n",
    "        x = torch.cat((x, ctx), dim=-1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # new\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        return x, out, out\n",
    "    \n",
    "    def _init_param(self, *sz): \n",
    "        return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f886521-12ea-4154-9cc7-5c97f63f8cdf",
   "metadata": {},
   "source": [
    "CAUTION ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b0fc4-19c8-46d1-bf15-2fe09e67f371",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137e1b3-7e7b-474a-9ea2-7dc5ff48da5e",
   "metadata": {},
   "source": [
    "#### Creating the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef965e8-937b-4477-b806-cfcb6153a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = OurPoolingLinearClassifier(layers, ps, bptt=seq_len, y_range=y_range)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfeb97-b937-46bd-869a-f60f68b4763d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9c14d-fdb4-4c8f-8f30-f8e95575649d",
   "metadata": {},
   "source": [
    "If using attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caee339-b4b4-4876-a6a7-00914eb2b715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OurPoolingAttentionClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): BatchNorm1d(10550400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.04000000000000001, inplace=False)\n",
       "      (2): Linear(in_features=10550400, out_features=50, bias=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (emb_label): Embedding(6594, 400)\n",
       "  (lin): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (lin_for_tok_red): Linear(in_features=1440, out_features=50, bias=True)\n",
       "  (lin_for_rep_compress): Linear(in_features=400, out_features=49, bias=True)\n",
       "  (lin_for_rep_decompress): Linear(in_features=49, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = OurPoolingAttentionClassifier(layers_attn, ps, bptt=seq_len, y_range=y_range)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbfb88-fa36-45a1-8673-5bb24653f2ca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac03efa-c8a2-4bc2-813b-f8852666ec0f",
   "metadata": {},
   "source": [
    "#### Creating the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2199b7a-d8b6-4183-9bf5-d8dec85883f7",
   "metadata": {},
   "source": [
    "The last thing that we need to do in order to create our architecture module is stack the `encoder` and the `decoder` using `SequentialRNN` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96657b2d-b3fc-4a7e-a83d-a31ab9e47613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): SentenceEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60008, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): CAML2(\n",
       "    (layer): LinBnDrop(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.04, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=8922, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialRNN(encoder, decoder)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cdbc60-02f0-4857-bd78-e1d0582c9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "if init is not None: model = model.apply(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0f4fc-6388-4e16-a83d-fa6d33af917b",
   "metadata": {},
   "source": [
    "At this point we are done creating the `model` (that is have replicated every step inside `get_text_classifier`). Next, let's move on to `text_classifier_learner`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f89b71-18ea-4e6b-b675-8a1eac65fd3c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ca3cd-7c9e-4894-b95e-b6a630c81ca6",
   "metadata": {},
   "source": [
    "#### Scratchpad: (Build the pieces to implement attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc49b3d-ad1f-4d4e-84f8-59a1a3bd142d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 18398]),\n",
       " torch.Size([128, 6594]),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dls_clas.one_batch()\n",
    "x.shape, y.shape, x.device, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fce6f0-d065-4a8c-aec1-04e8a1543b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SentenceEncoder(\n",
       "   (module): AWD_LSTM(\n",
       "     (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "     (encoder_dp): EmbeddingDropout(\n",
       "       (emb): Embedding(60008, 400, padding_idx=1)\n",
       "     )\n",
       "     (rnns): ModuleList(\n",
       "       (0): WeightDropout(\n",
       "         (module): LSTM(400, 1152, batch_first=True)\n",
       "       )\n",
       "       (1): WeightDropout(\n",
       "         (module): LSTM(1152, 1152, batch_first=True)\n",
       "       )\n",
       "       (2): WeightDropout(\n",
       "         (module): LSTM(1152, 400, batch_first=True)\n",
       "       )\n",
       "     )\n",
       "     (input_dp): RNNDropout()\n",
       "     (hidden_dps): ModuleList(\n",
       "       (0): RNNDropout()\n",
       "       (1): RNNDropout()\n",
       "       (2): RNNDropout()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " OurPoolingAttentionClassifier(\n",
       "   (layers): Sequential(\n",
       "     (0): LinBnDrop(\n",
       "       (0): BatchNorm1d(10550400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (1): Dropout(p=0.04000000000000001, inplace=False)\n",
       "       (2): Linear(in_features=10550400, out_features=50, bias=False)\n",
       "       (3): ReLU(inplace=True)\n",
       "     )\n",
       "     (1): LinBnDrop(\n",
       "       (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (1): Dropout(p=0.1, inplace=False)\n",
       "       (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (emb_label): Embedding(6594, 400)\n",
       "   (lin): Linear(in_features=400, out_features=400, bias=True)\n",
       "   (lin_for_tok_red): Linear(in_features=1440, out_features=50, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder = model[0], model[1]\n",
    "encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00b8b9-4bf6-44e3-9e38-f9e203ac60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder = encoder.cuda(), decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0f9c8-375d-4ec8-89a4-1c0da69cacb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535bcf1-16b5-482c-9a65-154fac8fae7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1406, 400]), torch.Size([2, 1406]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, mask = encoder(x[:2])\n",
    "out.shape, mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587309bc-4353-4744-834e-37e72958b853",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077284d7-6399-4b49-94f1-0c472996b670",
   "metadata": {},
   "source": [
    "After getting the output from the `encoder` we will do a masked concat pooling as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69f20e-fced-4a8c-9f38-ea17a1437004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_concat_pool = masked_concat_pool(out, mask, bptt=seq_len)\n",
    "# out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084413d1-5c8c-4a51-b14d-11c7f2abd801",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d8d97-765d-4884-81e5-e0b19f117255",
   "metadata": {},
   "source": [
    "Testing the decoder which is `OurPoolingAttentionCalssifier`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fbe77-06fc-41f3-ae74-3331bac8fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# out, mask, preds, model, encoder, decoder, x, y, dls_clas, learn, m, out_concat_pool = None, None, None, None, None, None, None, None, None, None, None, None\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f5038-bfab-420e-9a14-d3de4c9c359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _, _ = decoder((out, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e192e0-37a7-41e0-ae2e-7c7da5feb79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6594])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7fe708-ec83-4821-9b34-5604f6c043d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000e856-2bcd-4bcb-8f26-5cd1fc5d5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var = locals().get('out_concat_pool', 'Shit!!!')\n",
    "# print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419141a-591a-4bbf-9c41-cda3b4c00e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, encoder, dls_clas, out, mask, ind_var = None, None, None, None, None, None, None\n",
    "# import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff47a6-69c6-44a7-b933-0c5e95cd93da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a423f-5ef2-44d2-9c68-da6d9102427b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 400, 6594)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, emb_sz, n_out = 128, 400, get_c(dls_clas)\n",
    "bs, emb_sz, n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ee9f61-08a2-47ef-959a-c6bd495d6b70",
   "metadata": {},
   "source": [
    "`out` is the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65b3ab-4718-41c4-8611-e21436e8fd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1406, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = torch.randn(bs, 1406, emb_sz, dtype=torch.float)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470e1b9-41c2-46a8-8ac1-a73aa67eff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1846b-8fd2-48b8-97b8-d10a98d6b590",
   "metadata": {},
   "source": [
    "- The `out` is the memory: `(bs, sl, nh)`\n",
    "- meaning of the dimensions:\n",
    "    * For each of the 128 documents we are focussing on the last 1406 tokens each having a hidden vector of length 400\n",
    "- Let us say before predicting a label we want to know which part of the memory we want to pay attention to for that particular label\n",
    "- We need to compute the attention weights for each of the `sl` many `(bs,nh)`\n",
    "- The shape of the attention weights would be `bs,sl`\n",
    "---\n",
    "- To compute the attention weights we will use a mini \"neural network\"\n",
    "- **What would be the input to this mini-nn? The input to this neural network would be that particular label embedding that we want to predict**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c11674-ffe8-4494-a8b2-78099c66888a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "n_labels = n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea02c7-8b73-4fa9-a692-654501be5e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "label_emb_sz = 49\n",
    "emb_label = nn.Embedding(n_labels, emb_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f7837-56d8-48ee-beae-a110776b707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 1.0915, -0.2077, -0.4202,  ..., -0.1955, -0.0613, -0.1809],\n",
       "         [ 0.6431, -0.7658, -0.9118,  ...,  0.7211, -0.7179,  0.5732],\n",
       "         [-0.0820, -0.8173, -0.0974,  ..., -1.7775, -1.6814, -2.2647],\n",
       "         ...,\n",
       "         [ 0.3422, -0.4851, -0.4024,  ...,  0.2219,  0.8045,  0.0061],\n",
       "         [-1.0910, -0.1145,  2.0704,  ..., -0.0486,  0.2683, -0.0494],\n",
       "         [ 1.3110, -0.1406,  1.5179,  ..., -2.2415,  0.9447,  0.8938]], requires_grad=True),\n",
       " torch.Size([6594, 400]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_label.weight, emb_label.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b43a0-f932-4041-95ea-c1e2464fec10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0915,  0.6431, -0.0820,  ...,  0.3422, -1.0910,  1.3110],\n",
       "        [-0.2077, -0.7658, -0.8173,  ..., -0.4851, -0.1145, -0.1406],\n",
       "        [-0.4202, -0.9118, -0.0974,  ..., -0.4024,  2.0704,  1.5179],\n",
       "        ...,\n",
       "        [-0.1955,  0.7211, -1.7775,  ...,  0.2219, -0.0486, -2.2415],\n",
       "        [-0.0613, -0.7179, -1.6814,  ...,  0.8045,  0.2683,  0.9447],\n",
       "        [-0.1809,  0.5732, -2.2647,  ...,  0.0061, -0.0494,  0.8938]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_label.weight.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec3b52f-c8d3-4cfd-8460-468e41406a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 6594])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_label.weight.transpose(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68356f-e289-4119-bdf4-a0535124babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_label.weight.data = emb_label.weight.type(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80b789-9a87-430c-9203-8606034df372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_label.weight.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a18159-1bef-4b51-9cba-6170bcf97d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_label.__dict__\n",
    "# [o for o in dir(emb_label) if not o.startswith(\"__\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ac1f2-f040-4bfe-9a96-b476320ae4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(6594, 400)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a20898-20fe-4f55-b5b4-901fe45e62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randint(0,5,(10,5))\n",
    "# x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a82c7f-1bb6-4280-ae49-f04eaeb7d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_label(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f9f20-8c07-4513-bbdd-f43bdde680fa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29eba1-c461-468b-9b6f-0df55741c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.arange(5)[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca729e60-8c94-4cd0-bc70-fefa8b2af0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.ones(5, bs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b057a6-31a0-4e19-8374-bf7854f29332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.ones(bs, 5, dtype=torch.int64) * torch.arange(5)\n",
    "# labels.shape, labels.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0bdef-47fc-4778-8cea-a5ae48fbe63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "label_indices = torch.arange(n_labels)\n",
    "labels = label_indices.repeat(128, 1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2158500-3a16-44a4-80de-7373b996469b",
   "metadata": {},
   "source": [
    "Note: In `labels`,\n",
    "- 0th axis is bs\n",
    "- 1st axis is label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404db6d5-c24a-4f9a-8652-3984a80840a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        ...,\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels[:10, :]\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ab35c-c938-4bee-8e27-c7a0e7fac444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_label = labels[:,0]\n",
    "# a_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa1537-a6fb-44e5-ab7b-bb6223eced8f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7539f9-2634-4809-a84a-86ccfd03d168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "after_grabbing_label_embedding = emb_label(labels)\n",
    "after_grabbing_label_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412faad-fff0-4b33-bf6e-baf7dd4da1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.getsizeof(after_grabbing_label_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72190839-f1b6-4262-a95a-601155dc44c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb6d19-231e-4b3c-ba30-40d917e9ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.randint(0, 5, size=(3,2,4))\n",
    "# b = torch.randint(0, 5, size=(4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b091929-ff2a-479d-b43b-e9c09d358321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f002b-8090-457c-aff5-eabf46861eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdaa164-c1c8-4380-bc84-2f43591e0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a@b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44227e38-fbea-4650-9f19-e01f9c597b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a@b).permute(1,0,2).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a0248-d053-43a3-8e6c-0a8bca993633",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a819cfe-500b-4693-9fe6-c3f1b2856c15",
   "metadata": {},
   "source": [
    "*Step 0 of mini-nn:* `after_grabbing_label_embedding` is the input to the mini-nn which will answer the following question:   \n",
    "\n",
    "**Which part of the memory `out` should I pay attention before making a prediction about a label**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ea135-e61d-4b10-b956-4dbf5f21bbd4",
   "metadata": {},
   "source": [
    "*Step 1 of mini-nn: Doing the first matrix multiply:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc144bf-7c0d-4114-be36-28090a1f8c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=400, out_features=400, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "lin = nn.Linear(emb_sz, emb_sz)\n",
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac50861-bc3c-48f4-9949-4ee194ef5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.weight.data = lin.weight.type(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e863d4a-9e59-4b64-8880-507d66192fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6594, 400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "print(after_grabbing_label_embedding.shape)\n",
    "after_first_matmul = lin(after_grabbing_label_embedding)\n",
    "after_first_matmul.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea00a440-9d45-4ed0-a9c4-bfa77db90ced",
   "metadata": {},
   "source": [
    "At this point the axes mean the following:\n",
    "- 0th axis is the bs\n",
    "- 1st axis is label\n",
    "- 2nd axis is emb_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddab6cc-24c6-402d-801e-4e1228d82e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after_first_matmul = after_first_matmul.permute(1,0,2).contiguous()\n",
    "# after_first_matmul.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61597a0-a114-42e9-8f68-6d7eb3811755",
   "metadata": {},
   "source": [
    "Think of it this way:  \n",
    "In each of the 128 documents, each of the 6594 labels has a representation vector of length 400."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7e43e-04b2-4477-a1e9-c0ce725b5966",
   "metadata": {},
   "source": [
    "*Step 2 of mini-nn: Applying non-linearity:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c4cb7-2f58-421b-ab37-f2d563825ae7",
   "metadata": {},
   "source": [
    "But before applying a non-linearity we want to add the `after_first_matmul` to the entire memory `out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceadfe49-28f2-4a50-ba8b-a446c2b436f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1406, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0ef89-bb5b-479f-ba02-ae0b8742f647",
   "metadata": {},
   "source": [
    "To this memory we will add a singleton dimension at the 2nd position (think of this as adding a label specific dimension to our memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39bae0-b669-4a92-8d96-1705c6e4fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out[:, :, None].shape = torch.Size([128, 1406, 1, 400])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{out[:, :, None].shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1194f65-4103-444f-b199-ed649ff0697c",
   "metadata": {},
   "source": [
    "We want to literally add to our memory the `after_first_matmul`. So to line things up perfectly we add a singleton dimension at the 1st position in `after_first_matmul` (think of this as the token specific dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a8bb8-5796-4df2-9d6f-98bcd812d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after_first_matmul[:,None].shape = torch.Size([128, 1, 6594, 400])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{after_first_matmul[:,None].shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbab52a-99b5-4cc8-982e-30fbd0b9d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.type(torch.half), after_first_matmul.type(torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff10045-e9b5-4a3f-872e-43ef8e11a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = after_nonlinearity = torch.tanh(out[:, :50, None] + after_first_matmul[:,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5954f4-d544-4c70-8c68-9102e703de63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92245864-368a-4370-9b2d-3c96ddc7ffa6",
   "metadata": {},
   "source": [
    "At this point we are faced with a realistic issue:  \n",
    "We cannot afford to \n",
    "- consider all the 1406 tokens in our memory (stored in `out`), and \n",
    "- have those tokens have a representation length of 400.   \n",
    "Solution: (Like always) We we will have to do a matrix multiplication to preform compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a70f50-8a55-424d-9645-4c05dd20aec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1406, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07de1e-0a69-48ad-a3b7-ab0070613ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=400, out_features=49, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "lin_for_rep_red = nn.Linear(emb_sz, label_emb_sz)\n",
    "lin_for_rep_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312a6f7-dd6e-4016-b1d3-9619b4c28fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1406, 49])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = lin_for_rep_red(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4c624-ed71-46a9-b1ec-bd9a69f4d1d7",
   "metadata": {},
   "source": [
    "Let's also compress the representation length of the the last dimension in `after_first_matmul`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965ebd8-a3f3-4c41-a390-1753e8328f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_first_matmul.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74844adf-7034-4028-9060-e6f82b08e895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 49])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "after_first_matmul = lin_for_rep_red(after_first_matmul)\n",
    "after_first_matmul.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5949dda-d713-4e9e-b8f3-fedb0f58ce83",
   "metadata": {},
   "source": [
    "Now, let's compress the number of tokens in `out` from 1406 to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5288aa-3809-4e98-9c97-4710606c96a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 49, 1406])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = out.permute(0,2,1).contiguous()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b5bdd-3853-4c08-a86f-a64c307ff5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1406, out_features=50, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "lin_for_tok_red = nn.Linear(1406, 50)\n",
    "lin_for_tok_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfa079-8d4c-487b-bd16-a9ade129de81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 49, 50])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = lin_for_tok_red(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4350f9a-efeb-44df-bd4a-4bce9f766c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50, 49])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = out.permute(0,2,1).contiguous()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191ed6c-248f-4c8e-a0f8-96f231e6cf12",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93fae7-8b67-4453-8626-ade0a4ceb80e",
   "metadata": {},
   "source": [
    "Now we are good to add `after_first_matmul` to our compressed memory (stored in `out`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28947c41-57f2-42e0-aa21-9988c56ccff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape = torch.Size([128, 50, 49]), after_first_matmul.shape = torch.Size([128, 6594, 49])\n",
      "after_nonlinearity.shape = torch.Size([128, 50, 6594, 49])\n"
     ]
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "print(f\"{out.shape = }, {after_first_matmul.shape = }\")\n",
    "after_nonlinearity = torch.tanh(out[:, :, None] + after_first_matmul[:,None])\n",
    "print(f\"{after_nonlinearity.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e7980-be24-483d-b608-7823c54169d7",
   "metadata": {},
   "source": [
    "Note what each of the dimension of `after_nonlinearity` means:  \n",
    "In each of the **128 documents**, we are focussing on the last **50 (compressed from 1406) tokens**. Each one of those tokens has a **hidden (compressed) represenation vector of length 49** for each of the **6594 labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036a016-a872-4eb7-bb4f-16ed927f275f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_nonlinearity.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cb8be-a850-4400-972a-097a41ff3137",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c0fec-7522-444e-a0dc-b97e9b765af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "def init_param(*sz): print(f\"{sz = }\"); return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4429d-0fe2-456d-a894-ac0dfbf80a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_param(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64dd8b-7b33-46f0-a16a-8e842ef4e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_param(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddda806-126c-4dd8-9561-7070f2a271dd",
   "metadata": {},
   "source": [
    "`V` is for the second matrix multiply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c10544-eecd-4c5b-8ae0-cc56c174cdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sz = (49,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([49])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "V = init_param(label_emb_sz)\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f33f6b-834a-42a9-8c03-ebdbefe025e2",
   "metadata": {},
   "source": [
    "*Step 3 of mini-nn: Doing a second matrix multiply:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da87a1a1-6695-4b92-a4fc-cb0f3d30fad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50, 6594])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "attn_wgts = (after_nonlinearity @ V)\n",
    "attn_wgts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fc10c-a41f-42d5-b3d5-6591f1ac8e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5042, -0.4067,  0.2481,  ...,  0.4743,  0.6855,  0.3966],\n",
       "         [ 0.3884, -0.3913,  0.1412,  ...,  0.3579,  0.4673,  0.2750],\n",
       "         [ 0.3630, -0.3703,  0.1130,  ...,  0.3201,  0.4854,  0.1989],\n",
       "         ...,\n",
       "         [ 0.5318, -0.3458,  0.2158,  ...,  0.4740,  0.6765,  0.3409],\n",
       "         [ 0.0388, -0.7875, -0.2704,  ...,  0.0134,  0.2340, -0.1294],\n",
       "         [ 0.2823, -0.5718, -0.0493,  ...,  0.2117,  0.4972,  0.1334]],\n",
       "\n",
       "        [[ 0.1241, -0.7451, -0.1825,  ...,  0.0953,  0.2921, -0.0203],\n",
       "         [ 0.2909, -0.5416,  0.0215,  ...,  0.2523,  0.4723,  0.1960],\n",
       "         [ 0.1338, -0.5911, -0.0852,  ...,  0.2431,  0.3780,  0.0520],\n",
       "         ...,\n",
       "         [ 0.7050, -0.1777,  0.4014,  ...,  0.7176,  0.8624,  0.6345],\n",
       "         [ 0.4314, -0.4561,  0.2013,  ...,  0.4348,  0.5315,  0.3565],\n",
       "         [ 0.0490, -0.7727, -0.2656,  ..., -0.0220,  0.2699, -0.0791]],\n",
       "\n",
       "        [[ 0.9006,  0.1438,  0.7388,  ...,  1.0048,  1.0604,  0.8983],\n",
       "         [-0.1268, -0.8799, -0.4262,  ..., -0.1184, -0.0549, -0.2492],\n",
       "         [ 0.3554, -0.4827,  0.0140,  ...,  0.3103,  0.4728,  0.2540],\n",
       "         ...,\n",
       "         [ 0.2301, -0.5883,  0.0694,  ...,  0.3032,  0.3562,  0.1801],\n",
       "         [ 0.5709, -0.1793,  0.3390,  ...,  0.6076,  0.7982,  0.4759],\n",
       "         [ 0.0333, -0.8503, -0.3262,  ..., -0.0097,  0.2433, -0.1648]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_wgts[:3, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c0a14-44da-4b7b-ba7f-d0935b885099",
   "metadata": {},
   "source": [
    "Note that the \n",
    "- 0th axis is for the bs\n",
    "- 1st axis is actual attention wgts\n",
    "- 2nd axis is the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19c7a3-37e0-462a-a490-adcd27dfcee6",
   "metadata": {},
   "source": [
    "At this point what we have is the following:  \n",
    "- In all the **128 documents** we have **50 (compressed from 1406) numbers** for each of the **6594 labels**.\n",
    "- These 50 numbers are presumably the amount of *attention* we need to pay to   \n",
    "those **50 tokens** each of which have a **49 (compressed) length** hidden represenation vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23364c-1723-4128-8740-518b842c0fa2",
   "metadata": {},
   "source": [
    "Taking linear combination of the memory (`out`) based on the `attn_wgts` to get `ctx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa0c98-fb0f-4009-9e63-7c6c74798db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 50, 49]), torch.Size([128, 50, 6594]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, attn_wgts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22753def-a4d5-4c4b-a64c-58d9d1ee3a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 50, 1, 49]), torch.Size([128, 50, 6594, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out[None,...].shape, attn_wgts[...,None].shape\n",
    "out[:, :, None].shape, attn_wgts[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fab8a-e2d7-406e-9c20-86c4147f13ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50, 6594, 49])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "ctx = (out[:, :, None] * attn_wgts[..., None])\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8331b-a3bd-4127-aeae-80c20b238550",
   "metadata": {},
   "source": [
    "At this point the meaning of `ctx` is:  \n",
    "For each of the **128 documents**, for each of the **50 (compressed from 1406)** tokens, for each of the **6594 labels** we have a **hidden compressed representation of length 49**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86cc524-0bab-4276-b924-6d2cfee3935c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.7465e-03,  6.1149e-02, -2.2250e-01,  ..., -1.0547e-02, -8.3051e-02, -7.1283e-02],\n",
       "          [-1.4087e-03, -4.9323e-02,  1.7947e-01,  ...,  8.5075e-03,  6.6989e-02,  5.7497e-02],\n",
       "          [ 8.5931e-04,  3.0086e-02, -1.0947e-01,  ..., -5.1895e-03, -4.0863e-02, -3.5073e-02],\n",
       "          ...,\n",
       "          [ 1.6427e-03,  5.7516e-02, -2.0928e-01,  ..., -9.9206e-03, -7.8116e-02, -6.7048e-02],\n",
       "          [ 2.3742e-03,  8.3127e-02, -3.0247e-01,  ..., -1.4338e-02, -1.1290e-01, -9.6903e-02],\n",
       "          [ 1.3736e-03,  4.8094e-02, -1.7500e-01,  ..., -8.2956e-03, -6.5320e-02, -5.6065e-02]],\n",
       "\n",
       "         [[ 1.9480e-01, -1.0085e-01, -6.0489e-02,  ..., -1.6415e-02,  7.1366e-02, -7.5854e-02],\n",
       "          [-1.9623e-01,  1.0160e-01,  6.0934e-02,  ...,  1.6536e-02, -7.1891e-02,  7.6413e-02],\n",
       "          [ 7.0810e-02, -3.6661e-02, -2.1989e-02,  ..., -5.9670e-03,  2.5942e-02, -2.7574e-02],\n",
       "          ...,\n",
       "          [ 1.7948e-01, -9.2922e-02, -5.5732e-02,  ..., -1.5124e-02,  6.5753e-02, -6.9889e-02],\n",
       "          [ 2.3434e-01, -1.2133e-01, -7.2768e-02,  ..., -1.9747e-02,  8.5853e-02, -9.1252e-02],\n",
       "          [ 1.3789e-01, -7.1392e-02, -4.2820e-02,  ..., -1.1620e-02,  5.0519e-02, -5.3696e-02]],\n",
       "\n",
       "         [[ 2.0679e-01, -1.9689e-01,  7.2514e-02,  ..., -7.1185e-03,  4.9860e-02, -1.0741e-01],\n",
       "          [-2.1099e-01,  2.0088e-01, -7.3985e-02,  ...,  7.2628e-03, -5.0871e-02,  1.0959e-01],\n",
       "          [ 6.4356e-02, -6.1273e-02,  2.2567e-02,  ..., -2.2153e-03,  1.5517e-02, -3.3427e-02],\n",
       "          ...,\n",
       "          [ 1.8236e-01, -1.7363e-01,  6.3948e-02,  ..., -6.2775e-03,  4.3970e-02, -9.4721e-02],\n",
       "          [ 2.7656e-01, -2.6331e-01,  9.6979e-02,  ..., -9.5201e-03,  6.6682e-02, -1.4365e-01],\n",
       "          [ 1.1330e-01, -1.0787e-01,  3.9731e-02,  ..., -3.9002e-03,  2.7319e-02, -5.8850e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.4640e-01,  1.5364e-01, -8.2277e-02,  ...,  5.0683e-02,  5.1475e-02,  2.4160e-02],\n",
       "          [-2.2529e-01, -9.9923e-02,  5.3511e-02,  ..., -3.2963e-02, -3.3478e-02, -1.5713e-02],\n",
       "          [ 1.4057e-01,  6.2346e-02, -3.3388e-02,  ...,  2.0567e-02,  2.0889e-02,  9.8043e-03],\n",
       "          ...,\n",
       "          [ 3.0877e-01,  1.3695e-01, -7.3340e-02,  ...,  4.5178e-02,  4.5884e-02,  2.1536e-02],\n",
       "          [ 4.4071e-01,  1.9547e-01, -1.0468e-01,  ...,  6.4483e-02,  6.5490e-02,  3.0738e-02],\n",
       "          [ 2.2204e-01,  9.8483e-02, -5.2740e-02,  ...,  3.2488e-02,  3.2996e-02,  1.5487e-02]],\n",
       "\n",
       "         [[ 2.8909e-02,  2.0587e-03,  6.7105e-04,  ..., -7.5653e-03,  5.1221e-03, -2.0617e-02],\n",
       "          [-5.8716e-01, -4.1812e-02, -1.3629e-02,  ...,  1.5366e-01, -1.0403e-01,  4.1874e-01],\n",
       "          [-2.0164e-01, -1.4359e-02, -4.6806e-03,  ...,  5.2768e-02, -3.5727e-02,  1.4380e-01],\n",
       "          ...,\n",
       "          [ 1.0019e-02,  7.1343e-04,  2.3255e-04,  ..., -2.6218e-03,  1.7751e-03, -7.1448e-03],\n",
       "          [ 1.7445e-01,  1.2423e-02,  4.0495e-03,  ..., -4.5653e-02,  3.0909e-02, -1.2441e-01],\n",
       "          [-9.6473e-02, -6.8699e-03, -2.2394e-03,  ...,  2.5246e-02, -1.7093e-02,  6.8800e-02]],\n",
       "\n",
       "         [[-3.7299e-03,  1.8332e-01, -4.7049e-02,  ..., -3.2168e-02, -9.8785e-02,  1.9971e-02],\n",
       "          [ 7.5544e-03, -3.7129e-01,  9.5291e-02,  ...,  6.5153e-02,  2.0008e-01, -4.0450e-02],\n",
       "          [ 6.5156e-04, -3.2024e-02,  8.2189e-03,  ...,  5.6194e-03,  1.7257e-02, -3.4888e-03],\n",
       "          ...,\n",
       "          [-2.7972e-03,  1.3748e-01, -3.5284e-02,  ..., -2.4124e-02, -7.4083e-02,  1.4977e-02],\n",
       "          [-6.5683e-03,  3.2283e-01, -8.2853e-02,  ..., -5.6648e-02, -1.7396e-01,  3.5170e-02],\n",
       "          [-1.7621e-03,  8.6607e-02, -2.2227e-02,  ..., -1.5197e-02, -4.6669e-02,  9.4351e-03]]],\n",
       "\n",
       "\n",
       "        [[[-2.7754e-02,  3.0815e-02,  2.6581e-02,  ...,  1.4434e-03, -3.0631e-04, -4.1400e-02],\n",
       "          [ 1.6667e-01, -1.8505e-01, -1.5963e-01,  ..., -8.6683e-03,  1.8395e-03,  2.4862e-01],\n",
       "          [ 4.0829e-02, -4.5331e-02, -3.9103e-02,  ..., -2.1234e-03,  4.5060e-04,  6.0902e-02],\n",
       "          ...,\n",
       "          [-2.1310e-02,  2.3660e-02,  2.0409e-02,  ...,  1.1083e-03, -2.3519e-04, -3.1788e-02],\n",
       "          [-6.5336e-02,  7.2541e-02,  6.2574e-02,  ...,  3.3980e-03, -7.2108e-04, -9.7459e-02],\n",
       "          [ 4.5340e-03, -5.0340e-03, -4.3423e-03,  ..., -2.3580e-04,  5.0040e-05,  6.7632e-03]],\n",
       "\n",
       "         [[-2.2598e-02,  5.4780e-03,  4.9353e-02,  ..., -4.6649e-02,  7.7002e-04,  1.2219e-01],\n",
       "          [ 4.2078e-02, -1.0200e-02, -9.1897e-02,  ...,  8.6863e-02, -1.4338e-03, -2.2752e-01],\n",
       "          [-1.6696e-03,  4.0473e-04,  3.6463e-03,  ..., -3.4466e-03,  5.6891e-05,  9.0275e-03],\n",
       "          ...,\n",
       "          [-1.9603e-02,  4.7521e-03,  4.2813e-02,  ..., -4.0468e-02,  6.6798e-04,  1.0600e-01],\n",
       "          [-3.6692e-02,  8.8946e-03,  8.0134e-02,  ..., -7.5744e-02,  1.2503e-03,  1.9840e-01],\n",
       "          [-1.5228e-02,  3.6915e-03,  3.3258e-02,  ..., -3.1436e-02,  5.1890e-04,  8.2339e-02]],\n",
       "\n",
       "         [[-1.1614e-02, -1.4625e-02,  2.2434e-02,  ..., -2.1929e-02, -3.3679e-02, -4.8604e-02],\n",
       "          [ 5.1314e-02,  6.4619e-02, -9.9125e-02,  ...,  9.6894e-02,  1.4881e-01,  2.1475e-01],\n",
       "          [ 7.3930e-03,  9.3100e-03, -1.4281e-02,  ...,  1.3960e-02,  2.1440e-02,  3.0941e-02],\n",
       "          ...,\n",
       "          [-2.1101e-02, -2.6572e-02,  4.0761e-02,  ..., -3.9844e-02, -6.1192e-02, -8.8309e-02],\n",
       "          [-3.2814e-02, -4.1323e-02,  6.3389e-02,  ..., -6.1962e-02, -9.5161e-02, -1.3733e-01],\n",
       "          [-4.5096e-03, -5.6789e-03,  8.7113e-03,  ..., -8.5152e-03, -1.3078e-02, -1.8873e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.7286e-02,  5.7431e-02,  2.1055e-01,  ...,  1.1118e-01,  2.3440e-01,  1.0904e-01],\n",
       "          [-1.9484e-02, -1.4478e-02, -5.3079e-02,  ..., -2.8028e-02, -5.9092e-02, -2.7488e-02],\n",
       "          [ 4.3999e-02,  3.2696e-02,  1.1986e-01,  ...,  6.3294e-02,  1.3344e-01,  6.2075e-02],\n",
       "          ...,\n",
       "          [ 7.8666e-02,  5.8456e-02,  2.1430e-01,  ...,  1.1316e-01,  2.3858e-01,  1.1098e-01],\n",
       "          [ 9.4541e-02,  7.0253e-02,  2.5755e-01,  ...,  1.3600e-01,  2.8673e-01,  1.3338e-01],\n",
       "          [ 6.9557e-02,  5.1688e-02,  1.8949e-01,  ...,  1.0006e-01,  2.1096e-01,  9.8133e-02]],\n",
       "\n",
       "         [[-5.9713e-02, -4.3760e-03,  1.2829e-01,  ...,  9.0876e-02, -7.9220e-02, -1.9887e-02],\n",
       "          [ 6.3125e-02,  4.6261e-03, -1.3562e-01,  ..., -9.6068e-02,  8.3747e-02,  2.1024e-02],\n",
       "          [-2.7866e-02, -2.0421e-03,  5.9870e-02,  ...,  4.2409e-02, -3.6969e-02, -9.2808e-03],\n",
       "          ...,\n",
       "          [-6.0179e-02, -4.4102e-03,  1.2929e-01,  ...,  9.1586e-02, -7.9839e-02, -2.0043e-02],\n",
       "          [-7.3566e-02, -5.3912e-03,  1.5806e-01,  ...,  1.1196e-01, -9.7599e-02, -2.4501e-02],\n",
       "          [-4.9341e-02, -3.6160e-03,  1.0601e-01,  ...,  7.5092e-02, -6.5461e-02, -1.6433e-02]],\n",
       "\n",
       "         [[ 1.2593e-02, -6.9963e-04, -1.8169e-02,  ..., -3.0383e-03,  8.6847e-03, -1.5792e-02],\n",
       "          [-1.9843e-01,  1.1024e-02,  2.8629e-01,  ...,  4.7876e-02, -1.3685e-01,  2.4883e-01],\n",
       "          [-6.8205e-02,  3.7892e-03,  9.8401e-02,  ...,  1.6456e-02, -4.7036e-02,  8.5528e-02],\n",
       "          ...,\n",
       "          [-5.6383e-03,  3.1324e-04,  8.1345e-03,  ...,  1.3603e-03, -3.8884e-03,  7.0704e-03],\n",
       "          [ 6.9322e-02, -3.8513e-03, -1.0001e-01,  ..., -1.6725e-02,  4.7807e-02, -8.6929e-02],\n",
       "          [-2.0307e-02,  1.1282e-03,  2.9297e-02,  ...,  4.8994e-03, -1.4004e-02,  2.5465e-02]]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx[:2, :7, :, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e1661-937c-4e4a-8aa1-d2e7dfab1bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 49])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "ctx = ctx.sum(1)\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be3b3c-7a38-4f31-ba01-bfb94638f690",
   "metadata": {},
   "source": [
    "Now, let's decompress the hidden representation length from 49 back to 400 by doing a non-linearity followed by matrix multiply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2acd5-fa52-4db7-bb06-38527fd5a023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "lin_for_rep_decompress = nn.Linear(label_emb_sz, emb_sz)\n",
    "ctx = lin_for_rep_decompress(torch.relu(ctx))\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f7c23-77d9-4356-a914-aadad14b3b41",
   "metadata": {},
   "source": [
    "Let's recap what we have so far `ctx`:  \n",
    "For each of the **128 documents** for each of the **6594 labels** we have a **represenation vector of lenth 400** (we obtained this by paying attention to specific parts of the memory).\n",
    "\n",
    "Now this `ctx` will get concatenated with whatever the decoder was previously using without attention (i.e., the output of `masked_concat_pool`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ed0d4-fefc-4154-92b7-ef21a03b319c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d5e6c-4df1-40e8-90b2-54ca8e8aa6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1200])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_concat_pool = torch.randn((128,1200))\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f8a0d-41c3-4f38-8ea4-905f1560f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 1200])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out_concat_pool = out_concat_pool[:, None]\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a81d07-f466-44bd-b801-38a46d08ec34",
   "metadata": {},
   "source": [
    "Think of `out_concat_pool` as the label-agnostic **1200 length represenation** of each of the **128 documents**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728a5f2-4abe-4ecf-8223-c8d4a35f9164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1200])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out_concat_pool = out_concat_pool.repeat(1, n_labels, 1)\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3d59b-40ef-4377-a401-ec092646f6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ctx = ctx.permute(1,0,2).contiguous()\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a4edb-8b13-459c-9035-b7aa0be0eba4",
   "metadata": {},
   "source": [
    "Think of `ctx` as label-specific **400 length representation** of each of the **128 documents**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d388b5f-6c7f-4aa9-857d-ca9eba212abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1600])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out_concat_pool = torch.cat((out_concat_pool, ctx), dim=-1)\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8fbd84-8716-4b65-a8eb-a883e5c91953",
   "metadata": {},
   "source": [
    "At this point we can flattan the features before feeding it into the Linear-BatchNorm-Droput layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11cd94-03f8-473d-8958-319bc309494b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1600])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(128, 6594, 1600)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65991a3d-1fa9-4435-9e6f-d5505e1056f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1350451200])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05477f4-afb7-4d1c-a77e-5e77b425a030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10550400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(t.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748754b-437d-46e0-89f7-8fb644ce0478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10550400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out_concat_pool = out_concat_pool.view(out_concat_pool.shape[0], -1)\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca2d49-89f9-44ec-9ff2-293200ff3da3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a720bedc-e462-4933-b867-a449a838fd05",
   "metadata": {},
   "source": [
    "Let's see how to perform batchnorm on this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04095dc6-077a-4002-8505-655360c9bf83",
   "metadata": {},
   "source": [
    "First let's see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60548f1-93a6-40cb-9069-cc06e652bb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(100)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e29f8b-3e66-44b0-b2d6-931901d4a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a2629-28a8-4411-a000-9f4c869df6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80f83e-4445-4c0f-9152-c11fe8ea9812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(18)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff008c76-8758-4777-be5a-ee85a0b5daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(20, 18, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3660a-0499-4768-8eed-da9eb07d88a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 18, 100])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44bcfc1-a54a-4a94-a506-1dbac9e23117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(6594, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(n_out)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf83b3-ef3a-40c1-af18-2d77debd3bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1600])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(out_concat_pool).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823eaa3a-6f2b-496b-9c34-ca04a1c11bba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921846a2-8369-4ef8-9130-b76f856251de",
   "metadata": {},
   "source": [
    "##### Practice some ufuncs in PyTorch and Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01acda7-dd4f-48b1-8e12-85afd0f97162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be581270-424f-4143-85cd-3668dd613afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[1,2], [3,4]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fbe9a-a0e3-4e05-93ec-ee67af58be89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 3, 3, 4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(arr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc38b3-3c14-4163-a7ea-36787a6ed004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 2, 2],\n",
       "       [3, 3, 3, 4, 4, 4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(arr, 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55845b0-c456-4007-af86-9fcd671135ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(arr, [1, 2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d1025-4e6a-447d-9cf6-77953629bd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), 1, (3,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0, 1, 2])\n",
    "a, a.ndim, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a614d-8758-461b-80d9-2031cee25296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8ba76-2c7a-4c53-afc7-f706720a7a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "       [0, 1, 2, 0, 1, 2, 0, 1, 2]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a, (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd205c60-6173-46d4-a054-995c53292aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 2, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 0, 1, 2]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a, (2,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76005ecc-85cf-460d-8529-bc84841c50ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2],\n",
       "        [3, 4]]),\n",
       " (2, 2),\n",
       " 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[1,2], [3, 4]])\n",
    "b, b.shape, b.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b560c-533d-4b7b-9443-9b00ea121969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 2],\n",
       "       [3, 4, 3, 4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(b,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956ec4d-5f8d-4b0c-ac88-e156ccf88875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(b, (2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8b406-9beb-427d-a0ad-d82a66d294ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 2, 1, 2],\n",
       "       [3, 4, 3, 4, 3, 4],\n",
       "       [1, 2, 1, 2, 1, 2],\n",
       "       [3, 4, 3, 4, 3, 4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(b, (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da7c2c-b0b3-4bfb-8b57-cf8c3ad0369e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([1, 2, 3, 4])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96348f-d721-4b46-abd8-f8c6443b7ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
       "       [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
       "       [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
       "       [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(c, (4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a029fe4-ab50-4b9e-b2f5-740f65b410b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea4160-b858-4b3e-80c0-5268cbdfaad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 4, 0, 3, 1],\n",
       "         [3, 1, 3, 0, 3, 2],\n",
       "         [3, 2, 1, 0, 1, 0]]),\n",
       " torch.Size([3, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randint(0, 5, (3,6))\n",
    "t, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5f1b2-992b-4460-848a-99c1a784ef2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 1, 4, 0, 3, 1]],\n",
       " \n",
       "         [[3, 1, 3, 0, 3, 2]],\n",
       " \n",
       "         [[3, 2, 1, 0, 1, 0]]]),\n",
       " torch.Size([3, 1, 6]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t[:, None]\n",
    "t, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9742e8f-02ce-4659-b877-ca99519466cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 4, 0, 3, 1],\n",
       "         [1, 1, 4, 0, 3, 1],\n",
       "         [1, 1, 4, 0, 3, 1],\n",
       "         [1, 1, 4, 0, 3, 1],\n",
       "         [1, 1, 4, 0, 3, 1]],\n",
       "\n",
       "        [[3, 1, 3, 0, 3, 2],\n",
       "         [3, 1, 3, 0, 3, 2],\n",
       "         [3, 1, 3, 0, 3, 2],\n",
       "         [3, 1, 3, 0, 3, 2],\n",
       "         [3, 1, 3, 0, 3, 2]],\n",
       "\n",
       "        [[3, 2, 1, 0, 1, 0],\n",
       "         [3, 2, 1, 0, 1, 0],\n",
       "         [3, 2, 1, 0, 1, 0],\n",
       "         [3, 2, 1, 0, 1, 0],\n",
       "         [3, 2, 1, 0, 1, 0]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.repeat(1, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdede4ee-80c9-4c86-9995-ba83ee1705fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921a629-fd16-49b1-aaec-ed3c99cdb189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[1], [2], [3]])\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbfc67-19c5-4760-bb04-07a73d00d263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.expand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b94d4-cefd-49a7-913b-c1fcfa0a4b1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (5) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [5, 3].  Tensor sizes: [3, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4561/3650102684.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (5) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [5, 3].  Tensor sizes: [3, 1]"
     ]
    }
   ],
   "source": [
    "b.expand(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34822db1-fc1c-466a-9f87-7beb298503aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041a274-b1b0-4166-bda2-caa5c340ec60",
   "metadata": {},
   "source": [
    "### `Learner` Creation: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff39ffd-8fa0-4a6d-abe9-418aec277d3f",
   "metadata": {},
   "source": [
    "In this section we will replicate all the steps in `text_classifier_learner`:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3700d-dda0-420e-9e8e-6ae5c294ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.01, metrics=PrecisionK).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5d116-cf69-4a65-9eec-651f580e85ea",
   "metadata": {},
   "source": [
    "There are three things that happens inside `text_classifier_learner`\n",
    "- create the `model` - we have already done this in the previous section\n",
    "- create a `Learner` using `TextLearner`\n",
    "    * `TextLearner` is a Basic class for a `Learner` in NLP.\n",
    "    * Adds a `ModelResetter` and an `RNNRegularizer` with `alpha` and `beta` to the callbacks, the rest is same as `Learner` init.\n",
    "    * Adding functionality to the base class, it has the methods - `load_pretrained`, `save_encoder` and `load_encoder`.\n",
    "- load the pretrained weights (grabbing that information from `_model_meta`) into the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52db9b-33ad-46c9-bf10-d4930f098a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = _model_meta[arch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404990a1-eddc-41bc-83ef-922e2372a404",
   "metadata": {},
   "source": [
    "#### Metrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70b0c6-8ade-40d0-a22c-e5246d39643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(yhat_raw, y, k=15):\n",
    "    \"\"\"\n",
    "        Inputs: \n",
    "            yhat_raw: activation matrix of ndarray and shape (n_samples, n_labels)\n",
    "            y: binary ground truth matrix of type ndarray and shape (n_samples, n_labels)\n",
    "            k: for @k metric\n",
    "    \"\"\"\n",
    "    yhat_raw, y = to_np(yhat_raw), to_np(y)\n",
    "    # num true labels in the top k predictions / k\n",
    "    sortd = yhat_raw.argsort()[:,::-1]\n",
    "    topk = sortd[:, :k]\n",
    "    \n",
    "    # get precision at k for each sample\n",
    "    vals = []\n",
    "    for i, tk in enumerate(topk):\n",
    "        num_true_in_top_k = y[i,tk].sum()\n",
    "        vals.append(num_true_in_top_k / float(k))\n",
    "    \n",
    "    return np.mean(vals)\n",
    "\n",
    "def precision_at_r(yhat_raw, y):\n",
    "    \"\"\"\n",
    "        Inputs: \n",
    "            yhat_raw: activation matrix of ndarray and shape (n_samples, n_labels)\n",
    "            y: binary ground truth matrix of type ndarray and shape (n_samples, n_labels)\n",
    "    \"\"\"\n",
    "    yhat_raw, y = to_np(yhat_raw), to_np(y)\n",
    "    # num true labels in the top r predictions / r, where r = number of labels associated with that sample \n",
    "    sortd = yhat_raw.argsort()[:, ::-1]\n",
    "    \n",
    "    # get precision at r for each sample\n",
    "    vals = []\n",
    "    for i, sorted_activation_indices in enumerate(sortd):\n",
    "        # compute the number of labels associated with this sample\n",
    "        r = int(y[i].sum())\n",
    "        top_r_indices = sorted_activation_indices[:r] \n",
    "        num_true_in_top_r = y[i, top_r_indices].sum()\n",
    "        vals.append(num_true_in_top_r / float(r))\n",
    "    \n",
    "    return np.mean(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36915ec6-e197-4e66-9c05-0f13e94ae4c1",
   "metadata": {},
   "source": [
    "#### `TextLearner`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8cd5e-94aa-41b9-90d3-fd5cf49bc718",
   "metadata": {},
   "source": [
    "Let's create the `Learner` (we can pass our metrics here:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698ce34-147f-42cf-b03b-f274b5be1a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = TextLearner(dls_clas, model, splitter=meta['split_clas'], metrics=[precision_at_k, precision_at_r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13795dde-85d7-45a1-9075-780ed8974c59",
   "metadata": {},
   "source": [
    "Note that in this case fastai was clever to figure out the correct loss (`BCEWithLogitsLoss`) from the `Dataloaders dls_clas`! We could overide this cleverness by specifically passing a `loss_func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaedbf7-f64d-4751-9821-5b2251cced5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlattenedLoss of BCEWithLogitsLoss()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246276a-c334-474a-bb18-62f57eb463c6",
   "metadata": {},
   "source": [
    "#### Pretrained Weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7d8ae-1bfd-480f-9b73-a0d2a0a3a0c2",
   "metadata": {},
   "source": [
    "Now let's replace the random weights of the encoder using the pretrained weights (from the url in meta). Note that in this case we can skip this step, because we are anyway later on going to load the encoder weights from our finetuned language model. But let's not skip this step for completeness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961eca2f-a8b4-4031-b59c-a7d9c0a6c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "backwards = False\n",
    "url = 'url_bwd' if backwards else 'url'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc016d7-6ecf-4fa0-a024-7e32c432a88e",
   "metadata": {},
   "source": [
    "Let's check if we have pretrained weights for that `arch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aac8c8-a59e-4080-8446-ec0116f2cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if url not in meta: warn(\"There are no pretrained weights for that architecture yet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83f5e5-6872-4833-a722-64b62be46518",
   "metadata": {},
   "source": [
    "Get the path which contains the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2884c03-e686-4492-94e7-ffde51e43c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/ubuntu/.fastai/models/wt103-fwd/lstm_fwd.pth'),Path('/home/ubuntu/.fastai/models/wt103-fwd/itos_wt103.pkl')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_path = untar_data(meta[url], c_key='model')\n",
    "pretrained_model_path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aafb2d-fa83-440a-bebb-f8eb5b5e28ef",
   "metadata": {},
   "source": [
    "Let's get the weights of the pretrained model and the vocab that was used to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a14db-a86e-4f0f-ab7c-f53ca052c0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/home/ubuntu/.fastai/models/wt103-fwd/lstm_fwd.pth'),\n",
       " Path('/home/ubuntu/.fastai/models/wt103-fwd/itos_wt103.pkl'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = [list(pretrained_model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "wgts_fname, vocab_fname = fnames\n",
    "wgts_fname, vocab_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b652f6-9b6b-4248-ab95-7dd5b914df4b",
   "metadata": {},
   "source": [
    "Just for fun why don't we take a look at the pretrained weights and the vocab that got used to train that model:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c3671-94f9-4501-9012-1e343bdec34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(collections.OrderedDict, list)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_wgts, old_vocab = torch.load(wgts_fname), load_pickle(vocab_fname)\n",
    "type(pretrained_wgts), type(old_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f52336-dea2-490a-a9fe-5c9b309a2942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.encoder.weight  0.encoder_dp.emb.weight  0.rnns.0.weight_hh_l0_raw  0.rnns.0.module.weight_ih_l0  0.rnns.0.module.weight_hh_l0  0.rnns.0.module.bias_ih_l0  0.rnns.0.module.bias_hh_l0  0.rnns.1.weight_hh_l0_raw  0.rnns.1.module.weight_ih_l0  0.rnns.1.module.weight_hh_l0  0.rnns.1.module.bias_ih_l0  0.rnns.1.module.bias_hh_l0  0.rnns.2.weight_hh_l0_raw  0.rnns.2.module.weight_ih_l0  0.rnns.2.module.weight_hh_l0  0.rnns.2.module.bias_ih_l0  0.rnns.2.module.bias_hh_l0  1.decoder.weight  1.decoder.bias  "
     ]
    }
   ],
   "source": [
    "for key in pretrained_wgts: print(key, end='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec2c6f-76bd-4ce8-aab7-9ddf355c700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#60000) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxmaj','xxup','xxrep','xxwrep','the',',','.','of','and','in','to','a','=','\"','was','on','-',\"'s\",'as','for','that','with','by','\\n ',')','(','\\n \\n ','is','his','at','he','it','from','were','an','had','which','be','this','but',\"'\",'are','not','first','their'...]\n"
     ]
    }
   ],
   "source": [
    "print(coll_repr(old_vocab, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2683239-69d1-4e44-b702-98a1bcbce112",
   "metadata": {},
   "source": [
    "Now we write that magic line which will replace the random weights in our `encoder` i.e., `learn.model[0]`, with the `pretrained_wgts`.  \n",
    "\n",
    "**IMPORTANT**: We need to pass the\n",
    "- `wgts_fname`,\n",
    "- and the `vocab_fname`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4bca72-9d4d-446a-a67f-4079c9dcfbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be344cb4-26c9-4646-a184-5624269af173",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load_pretrained(wgts_fname, vocab_fname, model=learn.model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d70e36-b0ec-4e86-8058-139394735554",
   "metadata": {},
   "source": [
    "Additionally, we also need to freeze the `encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5550504-c92d-4583-a6e7-1a4370d75790",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f423bca6-1636-4d30-ab94-82653710c2d7",
   "metadata": {},
   "source": [
    "Also, to do mixed precision training, we need the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcab6f8-ec44-49c2-93ea-6dc757c78c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6e697-05aa-4489-b31e-b58ae31df755",
   "metadata": {},
   "source": [
    "#### LM weights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb22a07-0315-4dde-9245-a6f1182ce102",
   "metadata": {},
   "source": [
    "Additionally, we also need to freeze the `encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b21ca-f7e3-472d-819f-be2d5cf77d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a773db-aba5-4534-9c09-3ed88a4f0f6c",
   "metadata": {},
   "source": [
    "Also, to do mixed precision training, we need the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7cd11-5d02-4eaa-a562-c2f0e8e3f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e88f79e-9082-46b7-a057-55372763f375",
   "metadata": {},
   "source": [
    "**IMPORTANT:**  \n",
    "This is where the \"Magic\" happens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12bd8b-7cf2-4b81-9d87-1bc9a6b0854d",
   "metadata": {},
   "source": [
    "The final step prior to training the classifier is to load the encoder from our fine-tuned language model. We will use `load_encoder` instead of `load` because we have only the pretrained weights available for the encoder; `load` by default raises an exception if an incomplete model is loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb111278-87f7-446e-9aaf-159061dd71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lht {path_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048afd2e-f0e4-475a-b429-79814a33877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load_encoder(path_model/'lm_finetuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
