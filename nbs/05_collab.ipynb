{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20673dc-20ba-4283-b0c9-e2e2e3ff999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# skip\n",
    "! [ -e /content ] && pip install -Uqq fastai # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96433927-66e1-4824-a865-cb01441754e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp collab\n",
    "# default_class_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3c3cea-e9ef-460f-ac49-561e8af296bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.tabular.all import *\n",
    "from fastai.collab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "688c74c3-41a5-494a-aa7b-80a4674f70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41320ed0-06c5-49f3-9f75-e832e36cfa6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Collaborative filtering\n",
    "> Tools to add to the [fastai collab](https://docs.fast.ai/collab.html) to make the learning transferable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542e307-dbc8-4667-9e53-0c26c1237610",
   "metadata": {},
   "source": [
    "## Loading `users`/`items` embeddings from a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ab11e-6b6a-4ba5-a501-b53ea37ba7c0",
   "metadata": {},
   "source": [
    "In a collab model, to load a pretrained vocabulary, we need to adapt the embeddings of the  vocabulary used for the pre-training to the vocabulary of our current collab corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c152c2c3-0e98-4b6f-b1d2-ebcaf75a8432",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2806520920.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [16]\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# export \n",
    "def match_embeds(\n",
    "    old_wgts:dict, # Embedding weights of the pretrained model\n",
    "    old_vocab:dict, # Vocabulary (tokens and labels) of the corpus used for pretraining\n",
    "    new_vocab:list # Current collab corpus vocabulary (`items` and `users`)\n",
    ") -> \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669edc9f-72e7-4be4-a3b8-0ed4fd27a8aa",
   "metadata": {},
   "source": [
    "## Create a `Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360213ad-8a42-4f10-ad19-ef9acc26c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CollabLearner(Learner):\n",
    "    \"Basic class for a `Learner` in Collab.\"\n",
    "    def save(self, file, **kwargs):\n",
    "        \"Save model and optimizer state (if `with_opt`) to `self.path/self.model_dir/file`\"\n",
    "        file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "        vocab_file = join_path_file('collab_vocab', self.path/self.model_dir, ext='.pkl')\n",
    "        save_model(file, self.model, getattr(self,'opt', None), **kwargs)\n",
    "        save_pickle(vocab_file, self.dls.classes)\n",
    "        return file\n",
    "    \n",
    "    def load_vocab(self,\n",
    "        wgts_fname:str, #Filename of the saved weights\n",
    "        vocab_fname:str, # Saved vocabulary filename in pickle format\n",
    "        model=None # Model to load parameters from, deafults to `learner.model`\n",
    "    ):\n",
    "        \"Load the vocabulary (`users` and/or `items`) from a pretrained model and adapt it to the collab vocabulary.\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f02a8a92-7213-4888-91ff-089d6246d359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"CollabLearner\" class=\"doc_header\"><code>class</code> <code>CollabLearner</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>CollabLearner</code>(**`dls`**, **`model`**, **`loss_func`**=*`None`*, **`opt_func`**=*`Adam`*, **`lr`**=*`0.001`*, **`splitter`**=*`trainable_params`*, **`cbs`**=*`None`*, **`metrics`**=*`None`*, **`path`**=*`None`*, **`model_dir`**=*`'models'`*, **`wd`**=*`None`*, **`wd_bn_bias`**=*`False`*, **`train_bn`**=*`True`*, **`moms`**=*`(0.95, 0.85, 0.95)`*) :: `Learner`\n",
       "\n",
       "Basic class for a `Learner` in Collab."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CollabLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c7894-9ad8-472a-b54e-593269cea8ce",
   "metadata": {},
   "source": [
    "It works exactly as a normal `learner`, the only difference is that it also saves the `items` vocabulary used by `self.model`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933fa328-8e5a-45f5-b86c-9c202f4d36b5",
   "metadata": {},
   "source": [
    "The following function lets us quickly create a `Learner` for collaborative filtering from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7f8cc78-127c-4dc3-b7d3-d0fc3fecf029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "def collab_learner(dls, n_factors=50, use_nn=False, emb_szs=None, layers=None, config=None, y_range=None, loss_func=None, **kwargs):\n",
    "    \"Create a Learner for collaborative filtering on `dls`.\"\n",
    "    emb_szs = get_emb_sz(dls, ifnone(emb_szs, {}))\n",
    "    if loss_func is None: loss_func = MSELossFlat()\n",
    "    if config is None: config = tabular_config()\n",
    "    if y_range is not None: config['y_range'] = y_range\n",
    "    if layers is None: layers = [n_factors]\n",
    "    if use_nn: model = EmbeddingNN(emb_szs=emb_szs, layers=layers, **config)\n",
    "    else:      model = EmbeddingDotBias.from_classes(n_factors, dls.classes, y_range=y_range)\n",
    "    return CollabLearner(dls, model, loss_func=loss_func, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bbccae-b927-454b-bee7-f8e473fd95a9",
   "metadata": {},
   "source": [
    "If `use_nn=False`, the model used is an `EmbeddingDotBias` with `n_factors` and `y_range`. Otherwise, it's a `EmbeddingNN` for which you can pass `emb_szs` (will be inferred from the `dls` with `get_emb_sz` if you don't provide any), `layers` (defaults to `[n_factors]`) `y_range`, and a `config` that you can create with `tabular_config` to customize your model. \n",
    "\n",
    "`loss_func` will default to `MSELossFlat` and all the other arguments are passed to `Learner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48e3defd-d2bf-40fa-8e92-d76f5b49bb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>1097</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1255504951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>561</td>\n",
       "      <td>924</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1172695223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>260</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1291598691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358</td>\n",
       "      <td>1210</td>\n",
       "      <td>5.0</td>\n",
       "      <td>957481884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>316</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1138999234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0      73     1097     4.0  1255504951\n",
       "1     561      924     3.5  1172695223\n",
       "2     157      260     3.5  1291598691\n",
       "3     358     1210     5.0   957481884\n",
       "4     130      316     2.0  1138999234"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.ML_SAMPLE)\n",
    "ratings = pd.read_csv(path/'ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d96803ac-46af-4eb4-837d-070120dfb96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>654</td>\n",
       "      <td>2396</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>733</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262</td>\n",
       "      <td>1073</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>316</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>564</td>\n",
       "      <td>2858</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>518</td>\n",
       "      <td>1097</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>119</td>\n",
       "      <td>1923</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>608</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>439</td>\n",
       "      <td>593</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>423</td>\n",
       "      <td>592</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = CollabDataLoaders.from_df(ratings, bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02abb03d-9b3c-46d8-b96c-bda19df7fe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.483533</td>\n",
       "      <td>2.210738</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    learn = collab_learner(dls, y_range=(0,5), path=d)\n",
    "    learn.fit(1)\n",
    "    \n",
    "    # Test save created a file\n",
    "    learn.save('tmp')\n",
    "    assert (Path(d)/'models/tmp.pth').exists()\n",
    "    assert (Path(d)/'models/collab_vocab.pkl').exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e1a9b7b-22e9-4e12-9c86-64047ec91efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_text.models.core.ipynb.\n",
      "Converted 03_text.learner.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 05_collab.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
