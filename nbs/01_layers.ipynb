{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69e757c-1d09-45b4-ba3f-8f6a360ab34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7ece6e-cd30-465c-8e45-8e445a929440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e98b977-31ce-49dd-ba3d-5e3e5c02fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.torch_imports import *\n",
    "from fastai.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c1482e-61fe-4214-81a6-f54f1bcc5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5d5b9-8b99-4629-8a5c-3baeeb91f5c4",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Some layers which tops up the ones in fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c725aa-cd29-4bce-94bd-65f0bed0e682",
   "metadata": {},
   "source": [
    "## BatchNorm layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd9ab037-d625-44e8-a825-8d8675137a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LinBnDrop(nn.Sequential):\n",
    "    \"Module grouping `BatchNorm1d`, `Dropout` and `Linear` layers\"\n",
    "    def __init__(self, n_in, n_out=None, bn=True, ln=True, p=0., act=None, lin_first=False):\n",
    "        layers = [BatchNorm(n_out if ln and lin_first else n_in, ndim=1)] if bn else []\n",
    "        if p != 0: layers.append(nn.Dropout(p))\n",
    "        lin = [nn.Linear(n_in, n_out, bias=not bn)] if ln else []\n",
    "        if ln and act is not None: lin.append(act)\n",
    "        layers = lin+layers if lin_first else layers+lin\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4d5799-65f4-43d8-bce0-285b8f9e4222",
   "metadata": {},
   "source": [
    "The `BatchNorm` or the `Linear` layer is skipped if `bn=False` or `ln=False`, as is the dropout if `p=0`. Optionally, you can add an activation for after the linear layer with act."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9880666-3e6e-4700-8758-bca2b9a62b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Linear(in_features=10, out_features=20, bias=False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = LinBnDrop(10, 20)\n",
    "list(tst.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27e9232-d79b-483f-bbbe-7b8f0e1fa824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinBnDrop(\n",
       "  (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.02, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = LinBnDrop(10, 20, ln=False, p=0.02)\n",
    "tst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3f9ff-e93b-4192-b90c-3bce1b259898",
   "metadata": {},
   "source": [
    "The `LinBnDrop` layer ia not going to add an activation if `ln` is `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b45d03-63b1-4822-98e7-f200a0c2c6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinBnDrop(\n",
       "  (0): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.02, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = LinBnDrop(10, 20, ln=False, p=0.02, act=nn.ReLU(inplace=True))\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39817d8a-8a71-4f88-9e40-d44f9a28130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# not needed remove this later\n",
    "class Lin1BnDrop(nn.Sequential):\n",
    "    \"Module grouping `BatchNorm1d`, `Dropout` and a `Linear` layer with just one output feature\"\n",
    "    def __init__(self, n_in, n_out, bn=True, p=0., act=None, lin_first=False):\n",
    "        layers = [BatchNorm(n_in, ndim=1)] if bn else []\n",
    "        if p != 0: layers.append(nn.Dropout(p))\n",
    "        lin = [nn.Linear(n_out, 1, bias=not bn)]\n",
    "        if act is not None: lin.append(act)\n",
    "        layers = lin+layers if lin_first else layers+lin\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "642749ac-24d4-4512-8b91-9c7f8b2a784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = Lin1BnDrop(6594, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73bd576-bda1-48ea-ab93-9f7669d21628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lin1BnDrop(\n",
       "  (0): BatchNorm1d(6594, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Linear(in_features=400, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e43f43-af5b-419c-af39-c5c5d102650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lin1BnDrop(\n",
       "  (0): Linear(in_features=400, out_features=1, bias=False)\n",
       "  (1): BatchNorm1d(6594, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = Lin1BnDrop(6594, 400, lin_first=True)\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce4cfb3e-bb87-4cad-a522-7f28556d6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_text.models.core.ipynb.\n",
      "Converted 03_text.learner.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
