{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef844da-aed1-4c6e-86b4-ddc81e32bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536330ce-bfe5-4be2-931b-b9b748dbf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.data.all import *\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2142bc-faef-4706-a382-8c2bc2ce9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d9c99-e59d-46e9-b87d-9aafbb74b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63838f84-a61d-46b0-8402-71dbcdb78d07",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> Definition of metrics that tops up the ones in fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d91b41-cf9b-4801-89d4-ad60fe1b0793",
   "metadata": {},
   "source": [
    "## Extreme Multilabel Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42ccec-1b59-4a3c-a48b-08e125a26cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def PrecisionK(yhat_raw, y, k=15):\n",
    "    \"\"\"\n",
    "        Inputs: \n",
    "            yhat_raw: activation matrix of ndarray and shape (n_samples, n_labels)\n",
    "            y: binary ground truth matrix of type ndarray and shape (n_samples, n_labels)\n",
    "            k: for @k metric\n",
    "    \"\"\"\n",
    "    yhat_raw, y = to_np(yhat_raw), to_np(y)\n",
    "    # num true labels in the top k predictions / k\n",
    "    sortd = yhat_raw.argsort()[:,::-1]\n",
    "    topk = sortd[:, :k]\n",
    "    \n",
    "    # get precision at k for each sample\n",
    "    vals = []\n",
    "    for i, tk in enumerate(topk):\n",
    "        num_true_in_top_k = y[i,tk].sum()\n",
    "        vals.append(num_true_in_top_k / float(k))\n",
    "    \n",
    "    return np.mean(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee0dc8-b950-4002-90e7-1fd9096def97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def PrecisionR(yhat_raw, y):\n",
    "    \"\"\"\n",
    "        Inputs: \n",
    "            yhat_raw: activation matrix of ndarray and shape (n_samples, n_labels)\n",
    "            y: binary ground truth matrix of type ndarray and shape (n_samples, n_labels)\n",
    "    \"\"\"\n",
    "    yhat_raw, y = to_np(yhat_raw), to_np(y)\n",
    "    # num true labels in the top r predictions / r, where r = number of labels associated with that sample \n",
    "    sortd = yhat_raw.argsort()[:, ::-1]\n",
    "    \n",
    "    # get precision at r for each sample\n",
    "    vals = []\n",
    "    for i, sorted_activation_indices in enumerate(sortd):\n",
    "        # compute the number of labels associated with this sample\n",
    "        r = int(y[i].sum())\n",
    "        top_r_indices = sorted_activation_indices[:r] \n",
    "        num_true_in_top_r = y[i, top_r_indices].sum()\n",
    "        vals.append(num_true_in_top_r / float(r))\n",
    "    \n",
    "    return np.mean(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294269ac-6a2f-4bc0-8160-7e4ea3cab241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
