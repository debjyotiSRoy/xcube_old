{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Definition of metrics that tops up the ones in fastai\n",
    "output-file: metrics.html\n",
    "title: Metrics\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ef844da-aed1-4c6e-86b4-ddc81e32bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "530d9c99-e59d-46e9-b87d-9aafbb74b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "536330ce-bfe5-4be2-931b-b9b748dbf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.all import *\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee2142bc-faef-4706-a382-8c2bc2ce9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6296c70-e60d-4f7b-9bc3-f904ad00576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d91b41-cf9b-4801-89d4-ad60fe1b0793",
   "metadata": {},
   "source": [
    "## Extreme Multilabel Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de42ccec-1b59-4a3c-a48b-08e125a26cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrecisionK(yhat_raw, y, k=15):\n",
    "    \"\"\"\n",
    "        Inputs: \n",
    "            yhat_raw: activation matrix of ndarray and shape (n_samples, n_labels)\n",
    "            y: binary ground truth matrix of type ndarray and shape (n_samples, n_labels)\n",
    "            k: for @k metric\n",
    "    \"\"\"\n",
    "    yhat_raw, y = to_np(yhat_raw), to_np(y)\n",
    "    # num true labels in the top k predictions / k\n",
    "    sortd = yhat_raw.argsort()[:,::-1]\n",
    "    topk = sortd[:, :k]\n",
    "    \n",
    "    # get precision at k for each sample\n",
    "    vals = []\n",
    "    for i, tk in enumerate(topk):\n",
    "        num_true_in_top_k = y[i,tk].sum()\n",
    "        vals.append(num_true_in_top_k / float(k))\n",
    "    \n",
    "    return np.mean(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eaee0dc8-b950-4002-90e7-1fd9096def97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrecisionR(yhat_raw, y):\n",
    "    \"\"\"\n",
    "        Inputs: \n",
    "            yhat_raw: activation matrix of ndarray and shape (n_samples, n_labels)\n",
    "            y: binary ground truth matrix of type ndarray and shape (n_samples, n_labels)\n",
    "    \"\"\"\n",
    "    yhat_raw, y = to_np(yhat_raw), to_np(y)\n",
    "    # num true labels in the top r predictions / r, where r = number of labels associated with that sample \n",
    "    sortd = yhat_raw.argsort()[:, ::-1]\n",
    "    \n",
    "    # get precision at r for each sample\n",
    "    vals = []\n",
    "    for i, sorted_activation_indices in enumerate(sortd):\n",
    "        # compute the number of labels associated with this sample\n",
    "        r = int(y[i].sum())\n",
    "        top_r_indices = sorted_activation_indices[:r] \n",
    "        num_true_in_top_r = y[i, top_r_indices].sum()\n",
    "        vals.append(num_true_in_top_r / float(r))\n",
    "    \n",
    "    return np.mean(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b371b4-686f-4a68-8414-3a69032133c6",
   "metadata": {},
   "source": [
    "## Learning to Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3988e1cd-b3a2-467d-863d-5230a9e041f4",
   "metadata": {},
   "source": [
    "We want to compute a metric which measures how many orderings did the model get right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ab4d917-22b3-4ea5-8672-c56ad506c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_lbs_accuracy(preds, xb, len=1000, resamps=10, threshold=.5):\n",
    "    preds = preds.squeeze(-1)\n",
    "    tok_sl = xb.shape[2]\n",
    "    acc = 0\n",
    "    for _ in range(resamps):\n",
    "        rnd_idxs = torch.randperm(tok_sl)[:len]\n",
    "        rnd_xb = xb[:, :, rnd_idxs]\n",
    "        rnd_preds = preds[:, :, rnd_idxs] \n",
    "        srtd_relv, srtd_idxs = rnd_xb[:, :, :, -1].sort(descending=True)\n",
    "        srtd_preds = torch.take_along_dim(rnd_preds, srtd_idxs, dim=-1)\n",
    "        sl = torch.arange(len if tok_sl > len else tok_sl, device=xb.device)\n",
    "        ij = torch.cartesian_prod(sl, sl)\n",
    "        idxs, = torch.nonzero(ij[:, 0] < ij[:, 1], as_tuple=True)\n",
    "        ij = ij[idxs]\n",
    "        # si_sj = srtd_relv[:, :, ij]\n",
    "        # (si_sj[:, :, :, 0] >= si_sj[:, :, :, 1]).shape, (*srtd_relv.shape[:2], 49950)\n",
    "        # torch.equal(si_sj.new_ones(*si_sj.shape[:-1]), (si_sj[:, :, :, 0] >= si_sj[:, :, :, 1]))\n",
    "        pi_pj = srtd_preds[:, :, ij]\n",
    "        probs_hat = torch.sigmoid(pi_pj[:, :, :, 0] - pi_pj[:, :, :, 1])\n",
    "        probs_hat = (probs_hat > threshold).float()\n",
    "        # acc += (pi_pj[:, :, :, 0] > pi_pj[:, :, :, 1]).float().mean(dim=-1) # earlier this was wrong\n",
    "        acc += probs_hat.mean(-1) # the last axis is the token pair (more relevant, less relevant)\n",
    "    return acc/resamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e2bb728-39f2-4397-80fc-35798fcb8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(xb, model):\n",
    "    if len(xb.shape) != 4: xb = xb.unsqueeze(0) # add the batch dim if it is not there (0: batch, 1: lbs, 2: toks, 3: tok_id,lbl_id,score)\n",
    "    btch_acc = []\n",
    "    for btch_splt in torch.split(xb, 4, dim=0):\n",
    "        lbs_acc = []\n",
    "        for lbs_splt in torch.split(btch_splt, 100, dim=1):\n",
    "            lbs_acc.append(batch_lbs_accuracy(model(lbs_splt), lbs_splt))\n",
    "        # import pdb; pdb.set_trace()\n",
    "        lbs_acc = torch.cat(lbs_acc, dim=-1)\n",
    "        btch_acc.append(lbs_acc)\n",
    "    btch_acc = torch.cat(btch_acc, dim=0)\n",
    "    return btch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e67073-8d76-4e77-a658-7eb677881201",
   "metadata": {},
   "source": [
    "<mark>NOTE: The following `ndcg` only used on a batch: </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88e11b84-cf17-44e5-bfbb-1e185fdbdac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(preds, xb, k=None):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    preds.squeeze_(-1)\n",
    "    preds_rank = preds.argsort(dim=-1, descending=True).argsort(dim=-1)\n",
    "    ideal_rank = xb[:, :, :, -1].argsort(dim=-1, descending=True).argsort(dim=-1)\n",
    "    discnt_fac = torch.log2(preds_rank+2)\n",
    "    ideal_discnt_fac = torch.log2(ideal_rank+2)\n",
    "    # eps = preds.new_empty(1).fill_(1e-15)\n",
    "    discntd_gain = torch.pow(2, xb[:, :, :, -1])  / (discnt_fac)\n",
    "    ideal_discntd_gain = torch.pow(2, xb[:, :, :, -1])  / (ideal_discnt_fac)\n",
    "    dcg = discntd_gain.sum(dim=-1)#.flatten()\n",
    "    idcg = ideal_discntd_gain.sum(dim=-1)#.flatten()\n",
    "    ndcg = dcg/idcg\n",
    "    \n",
    "    ndcg_at_k = None\n",
    "    \n",
    "    if k is not None:\n",
    "        topk_preds, topk_preds_idxs = torch.topk(preds, k=k, dim=-1, largest=True)\n",
    "        topk_preds_relv = torch.take_along_dim(xb[:, :, :, -1], topk_preds_idxs, dim=-1)\n",
    "        topk_df = torch.log2(2 + torch.arange(k)).cuda()# torch.take_along_dim(discnt_fac, topk_preds_idxs, dim=-1)\n",
    "        dg_at_k = torch.pow(2, topk_preds_relv) / (topk_df) # changed\n",
    "        dcg_at_k = dg_at_k.sum(dim=-1)\n",
    "\n",
    "        topk, topk_idxs = torch.topk(xb[:, :, :, -1], k=k, dim=-1, largest=True)\n",
    "        idg_at_k = torch.pow(2, topk) / (topk_df) # changed\n",
    "        idcg_at_k = idg_at_k.sum(dim=-1)\n",
    "        \n",
    "        ndcg_at_k = dcg_at_k / idcg_at_k\n",
    "\n",
    "    return preds, preds_rank, ideal_rank, discnt_fac, ideal_discnt_fac, discntd_gain, ideal_discntd_gain, dcg, idcg, ndcg, ndcg_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d92be7-26de-4cbc-8aa5-0c182102c3db",
   "metadata": {},
   "source": [
    "<mark>NOTE: The following `ndcg_at_k` only used on the entite dataset: </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "011606ba-cc14-4b6b-b0f4-a435aea6d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(dset, model, k=20):\n",
    "    dset = dset.unsqueeze(0)\n",
    "    dset_chnked = torch.split(dset, 100, dim=1)\n",
    "    ndcg_at_k_list = []\n",
    "    for chunk in  dset_chnked:\n",
    "        *_, ndcg_at_k = ndcg(model(chunk), chunk, k=k)\n",
    "        ndcg_at_k_list.append(ndcg_at_k)\n",
    "    ndcg_at_k_all = torch.cat(ndcg_at_k_list, dim=-1)\n",
    "    return ndcg_at_k_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbaf1c8-5f69-434e-b5ec-cea65706ef32",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "294269ac-6a2f-4bc0-8160-7e4ea3cab241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
