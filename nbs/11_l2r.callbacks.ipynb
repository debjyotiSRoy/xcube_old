{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "32b4035f-c7eb-44fb-b460-838432fbdb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval:false\n",
    "! [ -e /content ] && pip install -Uqq fastai # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d1927335-90e5-4bf8-addd-6d19996bcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp l2r.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88f55fa0-dbb1-446d-a10a-c9e69f688478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.torch_imports import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback.core import *\n",
    "from fastcore.all import *\n",
    "from xcube.imports import *\n",
    "from xcube.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c55272a4-7f3a-49ed-b78e-51cace9c6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "29280704-9e21-4ff3-9bc6-02e14f0178b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de112c-ddc5-4f90-bba1-0e44a0ce066c",
   "metadata": {},
   "source": [
    "# Callbacks for L2R\n",
    "\n",
    "> General purpose callbacks needed for L2R learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "453b888a-d274-4bb2-b9e1-0ce310a5367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TrackResults(Callback):\n",
    "    def __init__(self, train_metrics=False): \n",
    "        store_attr()\n",
    "        self.names = ['loss', 'ndcg', 'ndcg_at_6', 'acc']\n",
    "    \n",
    "    def before_fit(self): self.losses_full, self.grads_full, self.metrics_full = [], defaultdict(list), defaultdict(list) \n",
    "    \n",
    "    def before_epoch(self): self.losses, self.ndcgs, self.ndcgs_at_6, self.accs = [], [], [], []\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        if self.model.training: self.losses_full.extend(self.losses)\n",
    "        _li = [self.losses, self.ndcgs, self.ndcgs_at_6, self.accs]\n",
    "        _li = [torch.stack(o) if o else torch.Tensor() for o in _li] \n",
    "        [self.losses, self.ndcgs, self.ndcgs_at_6, self.accs] = _li\n",
    "        log = [round(o.mean().item(), 4) if o.sum() else \"NA\" for o in _li]\n",
    "        if self.model.training:\n",
    "            if self.train_metrics: self.metrics_full['trn'].append(log)\n",
    "        else: self.metrics_full['val'].append(log)\n",
    "        print(self.epoch, self.model.training, *log)\n",
    "    \n",
    "    def after_batch(self):\n",
    "        with torch.no_grad():\n",
    "            loss = self.loss_func(self.preds, self.xb)\n",
    "            self.losses.append(loss.mean())\n",
    "            if self.model.training:\n",
    "                if self.train_metrics: self._compute_metrics()\n",
    "            else: self._compute_metrics()\n",
    "                        \n",
    "    def _compute_metrics(self):\n",
    "        *_, _ndcg, _ndcg_at_k = ndcg(self.preds, self.xb, k=6)\n",
    "        self.ndcgs.append(_ndcg.mean())\n",
    "        self.ndcgs_at_6.append(_ndcg_at_k.mean())\n",
    "        acc = accuracy(self.xb, self.model).mean()\n",
    "        self.accs.append(acc.mean())\n",
    "        \n",
    "    def after_backward(self):\n",
    "        for name,param in self.model.named_parameters():\n",
    "            grad = param.grad.data.detach().clone()\n",
    "            self.grads_full[name].append(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "739fe6b6-c568-4a12-8aac-a628ddb772e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ProgressBarCallback(Callback):\n",
    "    order = 70\n",
    "    \n",
    "    def before_fit(self):\n",
    "        self.mbar = master_bar(range(self.n_epochs))\n",
    "        \n",
    "    def before_epoch(self):\n",
    "        if getattr(self, 'mbar', False): self.mbar.update(self.epoch)\n",
    "        self._launch_pbar()\n",
    "        \n",
    "    def _launch_pbar(self):\n",
    "        self.pbar = progress_bar(self.dl, parent=getattr(self, 'mbar', None), leave=False)\n",
    "        self.pbar.update(0)\n",
    "        \n",
    "    def after_batch(self):\n",
    "        self.pbar.update(self.iter_num+1)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        self.pbar.on_iter_end()\n",
    "        \n",
    "    def after_fit(self):\n",
    "        if getattr(self, 'mbar', False):\n",
    "            self.mbar.on_iter_end()\n",
    "            delattr(self, 'mbar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "824872d8-8fc0-4d09-8571-b6ac9681289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Monitor(Callback):\n",
    "    order = 60\n",
    "    \n",
    "    def __init__(self, monitor='ndcg_at_6', comp=None, min_delta=0., reset_on_fit=False):\n",
    "        if comp is None: comp = np.greater\n",
    "        if comp == np.less: min_delta *= -1\n",
    "        store_attr()\n",
    "        self.best = None\n",
    "       \n",
    "    def before_fit(self):\n",
    "        if self.reset_on_fit or self.best is None: self.best = float('inf') if self.comp == np.less else -float('inf')\n",
    "        assert self.monitor in self.track_results.names\n",
    "        self.idx = list(self.track_results.names).index(self.monitor)\n",
    "        \n",
    "    def after_epoch(self):\n",
    "        val = self.track_results.metrics_full.get('val')[-1][self.idx]\n",
    "        if self.comp(val - self.min_delta, self.best): self.best, self.new_best, = val, True\n",
    "        else: self.new_best = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "384ef72f-0b72-4959-b329-bc78962b8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveCallBack(Monitor):\n",
    "    order = Monitor.order+1\n",
    "    def __init__(self, fname, monitor='ndcg_at_6', comp=None, min_delta=0., reset_on_fit=False):\n",
    "        super().__init__(monitor=monitor, comp=comp, min_delta=min_delta, reset_on_fit=reset_on_fit)\n",
    "        self.last_saved_path = None\n",
    "        store_attr()\n",
    "        \n",
    "    def after_epoch(self):\n",
    "        super().after_epoch()\n",
    "        if self.new_best:\n",
    "            print(f'Better model found at epoch {self.epoch} with {self.monitor} value: {self.best}.')\n",
    "            self.learn.save(self.fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9428d-6d4b-4f18-a1a2-e4a963e011b4",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "294269ac-6a2f-4bc0-8160-7e4ea3cab241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
