{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05002451-bebb-4b1f-9809-7f34af0fa0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf79eed-ae89-4216-8fab-2a38a27cae72",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> API details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9a36ca-bd42-49eb-b6bd-c559366c7f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bc6cc2-4512-47de-8d1c-e973fd2e8ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca39c48-d864-4b36-8f6d-34263b7e394e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d50982-f79b-478c-a460-e61f0cac93bd",
   "metadata": {},
   "source": [
    "Application specific import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66767808-25be-4278-bca6-5ed90d81aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "from fastai.distributed import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb8f242-e9dc-4414-a8c1-3ceba7ce54cb",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Some Additional Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f3c78-9d90-4e37-84f5-54ca8b983856",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(only if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41a5b9d-9f7f-48ee-910e-cdab3c651db9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "def set_bg(color):    \n",
    "    script = (\n",
    "        \"var cell = this.closest('.jp-CodeCell');\"\n",
    "        \"var editor = cell.querySelector('.jp-Editor');\"\n",
    "        \"editor.style.background='{}';\"\n",
    "        \"this.parentNode.removeChild(this)\"\n",
    "    ).format(color)\n",
    "    \n",
    "    display(HTML('<img src onerror=\"{}\" style=\"display:none\">'.format(script)))\n",
    "    \n",
    "@register_cell_magic\n",
    "def bg(color, cell):\n",
    "    set_bg(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d578aee-3f61-4aed-b592-3bd1a84d0d42",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Setting the base path as the path of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd20d55-00c2-4d78-b72f-b9b7cff75fe6",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = Path.cwd()\n",
    "path_data = path/'data'\n",
    "path_model = path/'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8491b841-e927-4366-b086-ecc99b84a243",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/home/ubuntu/xcube'),\n",
       " Path('/home/ubuntu/xcube/data'),\n",
       " Path('/home/ubuntu/xcube/models'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, path_data, path_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9aa85-43e6-4083-90d9-fa169502ead0",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## `DataLoaders` for the Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9805d-51ef-41fd-8665-8245d7f97c0a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To be able to use Transfer Learning, first we need to fine-tune our Language Model (which we pretrained on Wikipedia) on the corpus of Mimic-III (the one we prepared in the notebook 01_data_extraction2). Here we will build the `DataLoaders` object using the `DataBlock` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9666c754-021c-48ce-8c93-b67c415cbe53",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data/'processed'/'notes_labelled.csv',\n",
    "                dtype={'text': str, 'labels': str, 'subject_id': np.int64, 'hadm_id': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0eb52c3-3ebc-4017-a7d4-da5b08afea62",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[['text', 'labels']] = df[['text', 'labels']].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84982b63-6d7f-4517-a791-30d440af517c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f5108ee-0951-4426-8716-8aa63e8b1323",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>Admission Date:  [**2101-10-20**]     Discharge Date:  [**2101-10-31**]\\n\\nDate of Birth:   [**2025-4-11**]     Sex:  M\\n\\nService:  Medicine\\n\\nCHIEF COMPLAINT:  Admitted from rehabilitation for\\nhypotension (systolic blood pressure to the 70s) and\\ndecreased urine output.\\n\\nHISTORY OF PRESENT ILLNESS:  The patient is a 76-year-old\\nmale who had been hospitalized at the [**Hospital1 190**] from [**10-11**] through [**10-19**] of [**2101**]\\nafter undergoing a left femoral-AT bypass graft and was\\nsubsequently discharged to a rehabilitation facility.\\n\\nOn [**2101-10-20**], he presented a...</td>\n",
       "      <td>038.9;785.59;584.9;427.5;410.71;428.0;682.6;425.4;263.9;96.04;99.62;89.64;96.72;38.93;96.6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>Admission Date:  [**2191-3-16**]     Discharge Date:  [**2191-3-23**]\\n\\nDate of Birth:   [**2143-5-12**]     Sex:  F\\n\\nService:\\n\\nCHIEF COMPLAINT:  Shortness of breath and fevers.\\n\\nHISTORY OF PRESENT ILLNESS:  The patient is a 47-year-old\\nfemale with a history of human immunodeficiency virus (last\\nCD4 count 42 and a viral load of 65,000), cirrhosis,\\ndiabetes, and hypothyroidism presented with eight days of\\nfevers to 104, chills, shortness of breath, cough, dyspnea on\\nexertion, and fatigue.\\n\\nThe patient states she has become progressively dyspneic to\\nthe point where she is shor...</td>\n",
       "      <td>042;136.3;799.4;276.3;790.7;571.5;041.11;V09.0;E931.7;38.93;88.72;33.23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>Admission Date: [**2175-5-30**]        Discharge Date:  [**2175-6-15**]\\n\\nDate of Birth:                    Sex:  F\\n\\nService:\\n\\n\\nADMISSION DIAGNOSIS:  End stage renal disease, admitted for\\ntransplant surgery.\\n\\nHISTORY OF PRESENT ILLNESS:  The patient is a 65 year-old\\nwoman with end stage renal disease, secondary to malignant\\nhypertension. She was started on dialysis in [**2174-2-7**].  She currently was on peritoneal dialysis and appears\\nto be doing well.  She has a history of gastric angiectasia\\nwhich she requires endoscopy. She was admitted on [**2175-5-30**] for\\na scheduled...</td>\n",
       "      <td>403.91;444.0;997.2;276.6;276.7;285.9;275.3;V15.82;55.69;91.0;39.57;38.06;99.04</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id  \\\n",
       "0           3   145834   \n",
       "1           4   185777   \n",
       "2           6   107064   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Admission Date:  [**2101-10-20**]     Discharge Date:  [**2101-10-31**]\\n\\nDate of Birth:   [**2025-4-11**]     Sex:  M\\n\\nService:  Medicine\\n\\nCHIEF COMPLAINT:  Admitted from rehabilitation for\\nhypotension (systolic blood pressure to the 70s) and\\ndecreased urine output.\\n\\nHISTORY OF PRESENT ILLNESS:  The patient is a 76-year-old\\nmale who had been hospitalized at the [**Hospital1 190**] from [**10-11**] through [**10-19**] of [**2101**]\\nafter undergoing a left femoral-AT bypass graft and was\\nsubsequently discharged to a rehabilitation facility.\\n\\nOn [**2101-10-20**], he presented a...   \n",
       "1  Admission Date:  [**2191-3-16**]     Discharge Date:  [**2191-3-23**]\\n\\nDate of Birth:   [**2143-5-12**]     Sex:  F\\n\\nService:\\n\\nCHIEF COMPLAINT:  Shortness of breath and fevers.\\n\\nHISTORY OF PRESENT ILLNESS:  The patient is a 47-year-old\\nfemale with a history of human immunodeficiency virus (last\\nCD4 count 42 and a viral load of 65,000), cirrhosis,\\ndiabetes, and hypothyroidism presented with eight days of\\nfevers to 104, chills, shortness of breath, cough, dyspnea on\\nexertion, and fatigue.\\n\\nThe patient states she has become progressively dyspneic to\\nthe point where she is shor...   \n",
       "2  Admission Date: [**2175-5-30**]        Discharge Date:  [**2175-6-15**]\\n\\nDate of Birth:                    Sex:  F\\n\\nService:\\n\\n\\nADMISSION DIAGNOSIS:  End stage renal disease, admitted for\\ntransplant surgery.\\n\\nHISTORY OF PRESENT ILLNESS:  The patient is a 65 year-old\\nwoman with end stage renal disease, secondary to malignant\\nhypertension. She was started on dialysis in [**2174-2-7**].  She currently was on peritoneal dialysis and appears\\nto be doing well.  She has a history of gastric angiectasia\\nwhich she requires endoscopy. She was admitted on [**2175-5-30**] for\\na scheduled...   \n",
       "\n",
       "                                                                                       labels  \\\n",
       "0  038.9;785.59;584.9;427.5;410.71;428.0;682.6;425.4;263.9;96.04;99.62;89.64;96.72;38.93;96.6   \n",
       "1                     042;136.3;799.4;276.3;790.7;571.5;041.11;V09.0;E931.7;38.93;88.72;33.23   \n",
       "2              403.91;444.0;997.2;276.6;276.7;285.9;275.3;V15.82;55.69;91.0;39.57;38.06;99.04   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6664931-d445-440a-8985-5b1c47227637",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now create the `DataLoaders` using `DataBlock` API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de686c8-1053-42b4-bf59-688d6b7c68ac",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls_lm = DataBlock(\n",
    "    blocks   = TextBlock.from_df('text', is_lm=True),\n",
    "    get_x    = ColReader('text'),\n",
    "    splitter = RandomSplitter(0.1)\n",
    ").dataloaders(df, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1fa19-be56-493c-b5af-3f140fb86941",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at the batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f76e8-9d27-422d-9133-861efc0e6b27",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51ab8b-4379-4201-b00b-8ec45986cdfd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The length of our vocabulary is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780e8ed-ac92-4bd9-b9df-78e226f2a353",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(dls_lm.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9da0bf-2a3e-48b8-8dd3-70a3f8d78603",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at some words of the vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ab254-2527-46b1-a338-b8097927829a",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "coll_repr(L(dls_lm.vocab), 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa02541-8770-48a1-b599-6305fa5bcf8e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creating the `DataLaoders` takes some time, so smash that *save* button (also a good idea to save the `dls_lm.vocab` for later use):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d732508-e303-4e7d-988e-a6e755aceafc",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(dls_lm, path_model/'dls_lm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85993758-3e22-4f0c-b86e-1ce34e8558c8",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(dls_lm.vocab, path_model/'dls_lm_vocab.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee3d1b-896c-4c06-9547-73a99a91eda1",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## `Learner` for the Language Model Fine-Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a79a12-2c1e-470b-96e3-ab87d51454b2",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(\n",
    "    dls_lm, AWD_LSTM, drop_mult=0.3,\n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b5024-72d6-498b-9329-2ea7b3a73643",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's compute the learning rate using the `lr_find`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366cf40-7973-417e-a062-400529e20fce",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "lr_min, lr_steep, lr_valley, lr_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2049fd-4933-4b17-add1-0f6faa98ef36",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, lr_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986b5c3-62ae-4f07-bfc8-a4bf78f5904b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It takes quite a while to train each epoch, so we'll be saving the intermediate model results during the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bd542-4286-4dc5-9f1a-a4cb68e7fa1e",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.save(path_model/'lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb019e-ca63-4990-b78a-378328f35611",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's now load back the `Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd36306-4dfa-490e-bcb0-726f7b44b72e",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = learn.load(path_model/'lm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7b4f8-36da-4f4e-bf8d-3e563c6f8a51",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's validate the `Learner` to make sure we loaded the correct version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffaf1b6-bb8f-4a8e-960c-116361cf846d",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6654e5-c5dc-43c0-81f3-30b14c60c274",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we have completed the initial training, we will now continue fine-tuning the model after unfreezing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750dd485-240f-4873-90a6-fa0d6681ec55",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6a7a5-6c96-4cf4-b537-6a1a0282a563",
   "metadata": {
    "hidden": true
   },
   "source": [
    "and run `lr_find` again, because we now have more layers to train, and the last layers weight have already been trained for one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c60e3-0744-4e71-a7bd-47565b9a6c58",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "lr_min, lr_steep, lr_valley, lr_slide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267739b-1a4b-4361-be98-c0787b9f9a1f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's now traing with a suitable learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc69e9-edad-4a8f-b579-0e1c516b7da3",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, lr_min, cbs=SaveModelCallback(fname=path_model/'lm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3f646-b35f-458e-9f60-7017c8896755",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note: Make sure if you have trained the most language model `Learner` for more epochs (then you need to save that version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e44906-8fd3-457a-b3e5-bc0fd1a04cd3",
   "metadata": {
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Saving the encoder of the Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f987e81-281f-4cb0-9d94-1d53317b2dc2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Crucial:** Once we have trained our LM we will save all of our model except the final layer that converts activation to probabilities of picking each token in our vocabulary. The model not including the final layer has a sexy name - *encoder*. We will save it using `save_encoder` method of the `Learner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286146dd-9e21-4464-9c33-e6df16e8c05c",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.save_encoder(path_model/'lm_finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df34333-92eb-4e52-8f76-354fa3dad844",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This completes the second stage of the text classification process - fine-tuning the Language Model pretrained on Wikipedia corpus. We will now use it to fine-tune a text multi-label text classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c085ce4a-2362-4f6e-9354-2827faa92acc",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## `DataLoaders` for the Multi_Label Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26f724-1d97-4971-b578-1c6f269dd96e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now move from language model fine-tuning to calssifier fine-tuning. In notebook 02_code_prediction2.ipynb we used the `DataBlock` API to built the Multi-Label Classifier `DataLoaders` object. In this notebook though we will build it using the Mid-Level Data API:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d652206",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Loading Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228c2a5-ec48-4150-873f-d617813be71e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's load the Dataframe (stored in file: notes_labelled.csv) that we created in notebook 01_data_extraction2.ipynb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe278c3-d9d2-45a4-afa8-bc95decf079c",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/ubuntu/xcube/data\u001b[00m\n",
      "├── DIAGNOSES_ICD.csv\n",
      "├── D_ICD_DIAGNOSES.csv\n",
      "├── D_ICD_PROCEDURES.csv\n",
      "├── ICD9_descriptions\n",
      "├── NOTEEVENTS.csv\n",
      "├── PROCEDURES_ICD.csv\n",
      "├── dev_50_hadm_ids.csv\n",
      "├── dev_full_hadm_ids.csv\n",
      "├── \u001b[01;34mprocessed\u001b[00m\n",
      "│   ├── ALL_CODES.csv\n",
      "│   ├── ALL_CODES_filtered.csv\n",
      "│   ├── code_descriptions.csv\n",
      "│   ├── disch_full.csv\n",
      "│   ├── notes_labelled.csv\n",
      "│   └── notes_labelled_sample.csv\n",
      "├── test_50_hadm_ids.csv\n",
      "├── test_full_hadm_ids.csv\n",
      "├── train_50_hadm_ids.csv\n",
      "└── train_full_hadm_ids.csv\n",
      "\n",
      "1 directory, 18 files\n"
     ]
    }
   ],
   "source": [
    "!tree {path_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a516a0-f921-4d3c-b06e-7cbe6bded3f4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you are loading the sample dataset use the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd625eb8-fbda-47f2-b560-64c9cd1af7ab",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "notes_file = path_data/'processed'/'notes_labelled_sample.csv'\n",
    "df =pd.read_csv(notes_file, dtype= {\n",
    "    'text': str,\n",
    "    'labels': str,\n",
    "    'subject_id': np.int64,\n",
    "    'hadm_id': np.int64\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3aaaa-b44c-4e23-8545-c4df4b650fff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to convert the datatypes of the required columns, `text` and `labels`, to str:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac9c728-278a-4597-8cef-8ee96abf913e",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[['text', 'labels']] = df[['text', 'labels']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d079da0d-7ac1-4bd0-98c3-f4f88f03d837",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30088</td>\n",
       "      <td>172719</td>\n",
       "      <td>Admission Date:  [**2179-3-7**]              Discharge Date:   [**2179-3-18**]\\n\\nDate of Birth:  [**2121-12-23**]             Sex:   M\\n\\nService: MEDICINE\\n\\nAllergies:\\nIbuprofen\\n\\nAttending:[**First Name3 (LF) 613**]\\nChief Complaint:\\ndyspnea, hyperkalemia\\n\\nMajor Surgical or Invasive Procedure:\\nHemodialysis\\nright Femoral central venous line placement and removal\\n\\n\\nHistory of Present Illness:\\n57 y/o M with hx of ESRD presents after intentionally missing\\ndialysis for last 9 days.  Came to the ED due to the coaxing of\\nhis wife.  Complains of SOB and DOE lasting about the last ...</td>\n",
       "      <td>276.7;585.6;348.39;790.7;427.32;507.0;403.10;825.0;E888.9;300.9;301.9;250.62;357.2;250.42;285.21;278.01;427.31;250.82;V15.81;276.52;707.07;707.22;041.19;39.95;38.93</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22624</td>\n",
       "      <td>138579</td>\n",
       "      <td>Admission Date:  [**2117-1-21**]              Discharge Date:   [**2117-1-28**]\\n\\nDate of Birth:  [**2070-8-1**]             Sex:   M\\n\\nService: MEDICINE\\n\\nAllergies:\\nPatient recorded as having No Known Allergies to Drugs\\n\\nAttending:[**First Name3 (LF) 943**]\\nChief Complaint:\\nBright red blood in stools\\n\\nMajor Surgical or Invasive Procedure:\\nUpper endoscopy\\nColonoscopy\\nTransfusion of platelets and fresh frozen plasma\\n\\n\\nHistory of Present Illness:\\nIn brief, a 46-year-old man with etoh cirrhosis, varices s/p\\nbanding in [**12-9**], HCV not on treatment, who initially presente...</td>\n",
       "      <td>455.5;303.00;571.2;291.81;070.70;284.8;286.7;562.10;571.1;211.2;456.21;305.1;276.8;45.13;45.23;99.05;99.07;96.34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93593</td>\n",
       "      <td>164601</td>\n",
       "      <td>Admission Date:  [**2161-5-8**]              Discharge Date:   [**2161-5-12**]\\n\\n\\nService: MEDICINE\\n\\nAllergies:\\nPercocet\\n\\nAttending:[**First Name3 (LF) 1115**]\\nChief Complaint:\\nGI bleed / coffee-ground emesis.\\n\\nMajor Surgical or Invasive Procedure:\\nEGD\\nBlood transfusion\\n\\n\\nHistory of Present Illness:\\nPatient is an 87-y/o woman with a history of colon cancer s/p\\nright colectomy who presented today to the emergency room after\\n2 episodes of coffee-ground emesis at her rehab facility.\\nHistory was taken from family members as patient was in\\nsignificant discomfort with the NG...</td>\n",
       "      <td>V10.05;V45.72;V15.82;788.30;531.40;998.59;682.6;438.89;728.87;458.29;564.09;401.9;285.9;294.8;311;272.0;E878.2;45.13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21976</td>\n",
       "      <td>187519</td>\n",
       "      <td>Admission Date: [**2173-5-10**]        Discharge Date: [**2173-6-13**]\\n\\nDate of Birth:  [**2173-5-10**]        Sex:  M\\n\\nService:  NB\\n\\n\\nHISTORY OF PRESENT ILLNESS:  [**First Name8 (NamePattern2) 16518**] [**Known lastname 3175**] is the first\\nborn of twins at 33-2/7 weeks gestation born to a 34-year-old\\nG2 P1 woman, prenatal screens of blood type O positive,\\nantibody negative, Rubella immune, RPR nonreactive, hepatitis\\nB surface antigen negative, Group B strep status unknown.\\nEstimated date of confinement was [**2173-5-27**]. The\\npregnancy was a spontaneous twin gestation with ...</td>\n",
       "      <td>V31.00;765.17;765.27;770.2;745.5;774.2;779.3;770.6;772.6;770.81;779.81;V50.2;V05.3;V29.0;V18.0;754.81;64.0;93.9;99.15;99.83;99.55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10676</td>\n",
       "      <td>142446</td>\n",
       "      <td>Admission Date:  [**2118-3-4**]       Discharge Date:  [**2118-3-17**]\\n\\nDate of Birth:   [**2052-5-23**]       Sex:  M\\n\\nService:  CCU\\n\\nHISTORY OF THE PRESENT ILLNESS:  The patient is a 65-year-old\\nwith known CAD who presented to an outside hospital on the\\nday of admission with right upper back pain.  The pain was\\nradiating to the left arm and he relates that this complaint\\nhas been occurring for at least several weeks.  This episode\\nis similar to his previous back pain which has been\\nunrelieved with NSAIDs in the past.  The pain is much worse\\nwith walking and is associated wit...</td>\n",
       "      <td>410.61;785.51;414.01;427.89;401.9;272.4;36.01;36.06;37.61;37.23;88.56;96.72;96.04</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id  \\\n",
       "0       30088   172719   \n",
       "1       22624   138579   \n",
       "2       93593   164601   \n",
       "3       21976   187519   \n",
       "4       10676   142446   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Admission Date:  [**2179-3-7**]              Discharge Date:   [**2179-3-18**]\\n\\nDate of Birth:  [**2121-12-23**]             Sex:   M\\n\\nService: MEDICINE\\n\\nAllergies:\\nIbuprofen\\n\\nAttending:[**First Name3 (LF) 613**]\\nChief Complaint:\\ndyspnea, hyperkalemia\\n\\nMajor Surgical or Invasive Procedure:\\nHemodialysis\\nright Femoral central venous line placement and removal\\n\\n\\nHistory of Present Illness:\\n57 y/o M with hx of ESRD presents after intentionally missing\\ndialysis for last 9 days.  Came to the ED due to the coaxing of\\nhis wife.  Complains of SOB and DOE lasting about the last ...   \n",
       "1  Admission Date:  [**2117-1-21**]              Discharge Date:   [**2117-1-28**]\\n\\nDate of Birth:  [**2070-8-1**]             Sex:   M\\n\\nService: MEDICINE\\n\\nAllergies:\\nPatient recorded as having No Known Allergies to Drugs\\n\\nAttending:[**First Name3 (LF) 943**]\\nChief Complaint:\\nBright red blood in stools\\n\\nMajor Surgical or Invasive Procedure:\\nUpper endoscopy\\nColonoscopy\\nTransfusion of platelets and fresh frozen plasma\\n\\n\\nHistory of Present Illness:\\nIn brief, a 46-year-old man with etoh cirrhosis, varices s/p\\nbanding in [**12-9**], HCV not on treatment, who initially presente...   \n",
       "2  Admission Date:  [**2161-5-8**]              Discharge Date:   [**2161-5-12**]\\n\\n\\nService: MEDICINE\\n\\nAllergies:\\nPercocet\\n\\nAttending:[**First Name3 (LF) 1115**]\\nChief Complaint:\\nGI bleed / coffee-ground emesis.\\n\\nMajor Surgical or Invasive Procedure:\\nEGD\\nBlood transfusion\\n\\n\\nHistory of Present Illness:\\nPatient is an 87-y/o woman with a history of colon cancer s/p\\nright colectomy who presented today to the emergency room after\\n2 episodes of coffee-ground emesis at her rehab facility.\\nHistory was taken from family members as patient was in\\nsignificant discomfort with the NG...   \n",
       "3  Admission Date: [**2173-5-10**]        Discharge Date: [**2173-6-13**]\\n\\nDate of Birth:  [**2173-5-10**]        Sex:  M\\n\\nService:  NB\\n\\n\\nHISTORY OF PRESENT ILLNESS:  [**First Name8 (NamePattern2) 16518**] [**Known lastname 3175**] is the first\\nborn of twins at 33-2/7 weeks gestation born to a 34-year-old\\nG2 P1 woman, prenatal screens of blood type O positive,\\nantibody negative, Rubella immune, RPR nonreactive, hepatitis\\nB surface antigen negative, Group B strep status unknown.\\nEstimated date of confinement was [**2173-5-27**]. The\\npregnancy was a spontaneous twin gestation with ...   \n",
       "4  Admission Date:  [**2118-3-4**]       Discharge Date:  [**2118-3-17**]\\n\\nDate of Birth:   [**2052-5-23**]       Sex:  M\\n\\nService:  CCU\\n\\nHISTORY OF THE PRESENT ILLNESS:  The patient is a 65-year-old\\nwith known CAD who presented to an outside hospital on the\\nday of admission with right upper back pain.  The pain was\\nradiating to the left arm and he relates that this complaint\\nhas been occurring for at least several weeks.  This episode\\nis similar to his previous back pain which has been\\nunrelieved with NSAIDs in the past.  The pain is much worse\\nwith walking and is associated wit...   \n",
       "\n",
       "                                                                                                                                                                 labels  \\\n",
       "0  276.7;585.6;348.39;790.7;427.32;507.0;403.10;825.0;E888.9;300.9;301.9;250.62;357.2;250.42;285.21;278.01;427.31;250.82;V15.81;276.52;707.07;707.22;041.19;39.95;38.93   \n",
       "1                                                      455.5;303.00;571.2;291.81;070.70;284.8;286.7;562.10;571.1;211.2;456.21;305.1;276.8;45.13;45.23;99.05;99.07;96.34   \n",
       "2                                                  V10.05;V45.72;V15.82;788.30;531.40;998.59;682.6;438.89;728.87;458.29;564.09;401.9;285.9;294.8;311;272.0;E878.2;45.13   \n",
       "3                                     V31.00;765.17;765.27;770.2;745.5;774.2;779.3;770.6;772.6;770.81;779.81;V50.2;V05.3;V29.0;V18.0;754.81;64.0;93.9;99.15;99.83;99.55   \n",
       "4                                                                                     410.61;785.51;414.01;427.89;401.9;272.4;36.01;36.06;37.61;37.23;88.56;96.72;96.04   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2      True  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e7071b-8f50-42e7-9b82-7c63dfcde216",
   "metadata": {
    "hidden": true
   },
   "source": [
    "let's now gather the labels from the 'labels' column of the df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35bc2ed0-30fc-4f8b-8934-b09873c44594",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_freq = Counter()\n",
    "for labels in df.labels: label_freq.update(labels.split(';'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c507b7-a753-43b4-9115-6ffcf522a09a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The total number of labels are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3727f7-b3ed-4162-bd4f-7903faced6fa",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66b73e-dd80-4db0-a07b-2c6ffb592d44",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at the most common labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84b64e4d-3a39-44ed-9ee5-0b2fbf20dbe7",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401.9</td>\n",
       "      <td>5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.93</td>\n",
       "      <td>4345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>428.0</td>\n",
       "      <td>3837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>427.31</td>\n",
       "      <td>3801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>414.01</td>\n",
       "      <td>3627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96.04</td>\n",
       "      <td>3026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96.6</td>\n",
       "      <td>2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>584.9</td>\n",
       "      <td>2685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>96.71</td>\n",
       "      <td>2674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250.00</td>\n",
       "      <td>2619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>272.4</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>518.81</td>\n",
       "      <td>2164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99.04</td>\n",
       "      <td>2136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39.61</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>599.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>530.81</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>96.72</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>272.0</td>\n",
       "      <td>1698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>285.9</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>88.56</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  frequency\n",
       "0    401.9       5975\n",
       "1    38.93       4345\n",
       "2    428.0       3837\n",
       "3   427.31       3801\n",
       "4   414.01       3627\n",
       "5    96.04       3026\n",
       "6     96.6       2782\n",
       "7    584.9       2685\n",
       "8    96.71       2674\n",
       "9   250.00       2619\n",
       "10   272.4       2522\n",
       "11  518.81       2164\n",
       "12   99.04       2136\n",
       "13   39.61       2035\n",
       "14   599.0       2010\n",
       "15  530.81       1850\n",
       "16   96.72       1759\n",
       "17   272.0       1698\n",
       "18   285.9       1607\n",
       "19   88.56       1495"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(label_freq.most_common(20), columns=['label', 'frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ca573-d97b-417e-8681-b383416b59db",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's make a list of all labels (We will use it later while creating the `DataLoader`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3933d579-d557-43b7-88ed-71dc0c9a15a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lbls = list(label_freq.keys()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390ccd9-8d01-4971-be3d-992beda5fe23",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "source": [
    "### Steps for creating the classifier `DataLoaders` using fastai `Transforms`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd6e92-a962-4263-9f4d-22015ad04140",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 1. train/valid `splitter`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a53f2-e140-48b3-903f-a41ac8471f26",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Okay, based on the `is_valid` column of our Dataframe, let's create a splitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b01d462-834c-4a77-b093-361af5d88ee7",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def splitter(df):\n",
    "    train = df.index[~df['is_valid']].tolist()\n",
    "    valid = df.index[df['is_valid']].to_list()\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9291bd4-5a47-4d81-a5e1-e4df06fababb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's check the train/valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f41d55a7-2920-4b2e-a026-ef2b8e123f25",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = [train, valid] = splitter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2daa4639-d9bf-4a27-a578-c07f569b4c2e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#14839) [0,1,3,4,5,6,8,9,10,11...], (#979) [2,7,13,16,21,26,38,43,61,63...])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(splits[0]), L(splits[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d49c77-b0a6-43cd-9fe9-442e4e606d63",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "source": [
    "#### 2. Define transforms for the independent and the dependent variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e20d36-b3bb-46e1-b5be-8a89d6c440fe",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### a) Transforms for independent variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a824f83-3618-400c-b476-f076fb27c4d3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now `Tokenize` and `Numericalize` the `text` column of the `df`. \n",
    "\n",
    "**Crucial:** We need the vocab of the language model so that we can make sure we use the same correspondence of token to index. Otherwise, the embeddings we learned in our fine-tuned language model won't make any sense to our classifier model, and the fine-tuning won't be of any use:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c844701-3360-40de-8adf-fc8d911802cb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So let's load the vocab of the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f940db8-2271-4191-9692-f178cd1c565f",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_vocab = torch.load(path_model/'dls_lm_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bffb8647-2480-4154-b07c-1b2e697c3608",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#60008) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','*'...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(lm_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6426fb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Crucial**: This is where we pass the `lm_vocab` to the `Numericalize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "280ecb41-c125-43e9-b4ed-78683fed3abd",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tfms = [Tokenizer.from_df('text'), attrgetter(\"text\"), Numericalize(vocab=lm_vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20ec3d30-eb23-4136-a748-da8d9757017e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tls_x = TfmdLists(df, x_tfms, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a775ac4c-02f3-409a-83eb-2d0ce45fdfed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# len(tls_x.train), len(tls_x.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9f02c20e-85de-4b01-8e4a-91c3ac4e9311",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# a_text = tls_x.train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "629e82fe-bd37-41bd-8ebb-cb140889b825",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# a_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "847f040a-ce82-48de-819c-9b8851823bd7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(tls_x.decode(a_text)[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a7060",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c498102",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Sidebar: Practice Transforms:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8f9d3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`MultiCategorize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5872903b-cac8-43b1-938c-bb2e5a3b3423",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat = MultiCategorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1430f7c-38b0-4a3f-979c-db1ac1d97d5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lbls = [['b', 'c'], ['a'], ['a', 'c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d08829a9-478f-4abb-8255-f76e482d29d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat.setup(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7f6be71-880d-424e-bec7-53737e7579e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b83d5c4-89d8-497f-80ae-32b5c7a99821",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = cat(lbls[0])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "306f622a-cee4-4c4c-8c75-4cd0e99f26ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) ['b','c']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.vocab.map_ids(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9917db26-2adb-494f-af88-f134d10e90ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = TfmdLists([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d77b737-6f8d-4f08-b418-8dd6ad32a573",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79dbe1d2-3473-4363-a14e-140a252fb4a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([1, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c291aa2e-532a-4894-948f-cefd39bd33b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "887927d2-c4ee-4b8e-aae6-eb7d1d156ba4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([0, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37b6c349-1a97-4f20-80f0-c1f91e4db874",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f0db1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`OneHotEncode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d54dcdf8-cb1e-432f-8c8f-5eb25e793219",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2382516a-32c7-4e4f-bae4-0d158bd24822",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncode -- {'c': 3}:\n",
       "encodes: (object,object) -> encodes\n",
       "decodes: (object,object) -> decodes"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55d00c05-35d3-4e02-9b41-90008bec8f30",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([1., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tfm([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0c307d2-080d-49c5-9192-c287910a8750",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([0., 1., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tfm([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "622cfb03-bd1a-4bbf-a89b-1b88707b6291",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([0., 0., 1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tfm([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2545d3b-c65d-425d-b8e9-e6687c0d62a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([1., 1., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tfm([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77804173-3d4c-4f4e-8170-1ff04e6a227c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4542/2991036562.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_tfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'{self.name}:\\nencodes: {self.encodes}decodes: {self.decodes}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_idx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastcore/transform.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'returns'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastcore/dispatch.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/data/transforms.py\u001b[0m in \u001b[0;36mencodes\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Couldn't infer the number of classes, please pass a value for `c` at init\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mencodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mTensorMultiCategory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mone_hot_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(x, c)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "_tfm([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93af1127",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = [MultiCategorize(), OneHotEncode()]\n",
    "tds = TfmdLists([['b', 'c'], ['a'], ['a', 'c'], []], tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b6d4fa1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64c8785f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([0., 1., 1.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "952053b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([1., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de9a72d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([1., 0., 1.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4c66d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`ColReader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "831e4521",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>1 2 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a      b\n",
       "0  a    1 2\n",
       "1  b      0\n",
       "2  c       \n",
       "3  d  1 2 3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'a': 'a b c d'.split(),\n",
    "    'b': ['1 2', '0', '', '1 2 3']\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a1415f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = ColReader('a', pref='0', suff='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2908234c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pandas(Index=0, a='a', b='1 2'),\n",
       " Pandas(Index=1, a='b', b='0'),\n",
       " Pandas(Index=2, a='c', b=''),\n",
       " Pandas(Index=3, a='d', b='1 2 3')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "755a9730",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0a1', '0b1', '0c1', '0d1']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(o) for o in df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c384426f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = ColReader('b', label_delim=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd479d89",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '2'], ['0'], [], ['1', '2', '3']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(o) for o in df.itertuples()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7c865",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f334481c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### b) Transforms for the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ded267ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6594) ['276.7','585.6','348.39','790.7','427.32','507.0','403.10','825.0','E888.9','300.9'...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "560d5c7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_tfms = [ColReader('labels', label_delim=';'), MultiCategorize(vocab=lbls), OneHotEncode()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86d5ce6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30088</td>\n",
       "      <td>172719</td>\n",
       "      <td>Admission Date:  [**2179-3-7**]              Discharge Date:   [**2179-3-18**]\\n\\nDate of Birth:  [**2121-12-23**]             Sex:   M\\n\\nService: MEDICINE\\n\\nAllergies:\\nIbuprofen\\n\\nAttending:[**First Name3 (LF) 613**]\\nChief Complaint:\\ndyspnea, hyperkalemia\\n\\nMajor Surgical or Invasive Procedure:\\nHemodialysis\\nright Femoral central venous line placement and removal\\n\\n\\nHistory of Present Illness:\\n57 y/o M with hx of ESRD presents after intentionally missing\\ndialysis for last 9 days.  Came to the ED due to the coaxing of\\nhis wife.  Complains of SOB and DOE lasting about the last ...</td>\n",
       "      <td>276.7;585.6;348.39;790.7;427.32;507.0;403.10;825.0;E888.9;300.9;301.9;250.62;357.2;250.42;285.21;278.01;427.31;250.82;V15.81;276.52;707.07;707.22;041.19;39.95;38.93</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id  \\\n",
       "0       30088   172719   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Admission Date:  [**2179-3-7**]              Discharge Date:   [**2179-3-18**]\\n\\nDate of Birth:  [**2121-12-23**]             Sex:   M\\n\\nService: MEDICINE\\n\\nAllergies:\\nIbuprofen\\n\\nAttending:[**First Name3 (LF) 613**]\\nChief Complaint:\\ndyspnea, hyperkalemia\\n\\nMajor Surgical or Invasive Procedure:\\nHemodialysis\\nright Femoral central venous line placement and removal\\n\\n\\nHistory of Present Illness:\\n57 y/o M with hx of ESRD presents after intentionally missing\\ndialysis for last 9 days.  Came to the ED due to the coaxing of\\nhis wife.  Complains of SOB and DOE lasting about the last ...   \n",
       "\n",
       "                                                                                                                                                                 labels  \\\n",
       "0  276.7;585.6;348.39;790.7;427.32;507.0;403.10;825.0;E888.9;300.9;301.9;250.62;357.2;250.42;285.21;278.01;427.31;250.82;V15.81;276.52;707.07;707.22;041.19;39.95;38.93   \n",
       "\n",
       "   is_valid  \n",
       "0     False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "212d0dc1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tls_y = TfmdLists(df, y_tfms, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c81efdc",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14839, 979)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tls_y.train), len(tls_y.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd5168ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory([1., 1., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_label = tls_y.train[0]\n",
    "a_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b3c703f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['276.7', '585.6', '348.39', '790.7', '427.32', '507.0', '403.10', '825.0', 'E888.9', '300.9', '301.9', '250.62', '357.2', '250.42', '285.21', '278.01', '427.31', '250.82', 'V15.81', '276.52', '707.07', '707.22', '041.19', '39.95', '38.93', '455.5', '303.00', '571.2', '291.81', '070.70', '284.8', '286.7', '562.10', '571.1', '211.2', '456.21', '305.1', '276.8', '45.13', '45.23', '99.05', '99.07', '96.34', 'V10.05', 'V45.72', 'V15.82', '788.30', '531.40', '998.59', '682.6', '438.89', '728.87', '458.29', '564.09', '401.9', '285.9', '294.8', '311', '272.0', 'E878.2', 'V31.00', '765.17', '765.27', '770.2', '745.5', '774.2', '779.3', '770.6', '772.6', '770.81', '779.81', 'V50.2', 'V05.3', 'V29.0', 'V18.0', '754.81', '64.0', '93.9', '99.15', '99.83', '99.55', '410.61', '785.51', '414.01', '427.89', '272.4', '36.01', '36.06', '37.61', '37.23', '88.56', '96.72', '96.04', '487.0', '518.81', '428.0', '202.80', '996.62', '112.0', '244.9', '451.84', '300.4', '99.04', '434.91', '070.54', 'V15.3', 'V10.21', '431', '535.50', '398.90', '530.81', '368.46', '88.41', '532.40', '285.1', '530.85', '401.1', '715.90', '303.90', '44.43', '410.71', '425.4', '424.0', '584.9', '496', '250.00', '274.0', '300.00', '288.8', '66.0', '40.0', '37.22', '88.72', '89.64', '97.44', '038.11', '518.82', '112.5', '286.6', '785.59', '572.2', '486', '96.05', '14.', '54.91', '38.95', '33.24', '38.91', '93.90', '198.5', '577.0', '196.5', '197.0', '196.1', '511.9', '275.42', '280.9', 'V10.83', '780.53', '528.01', 'E933.1', '77.49', '86.07', '99.25', 'V30.00', '770.1', '770.84', '747.83', '691.0', '753.29', '96.71', '33.1', '428.33', '349.82', '599.0', '276.2', '041.3', '276.51', '416.9', '333.94', '403.90', '585.9', 'V46.2', '434.11', '345.80', '424.1', '781.3', '303.93', '421.0', '038.0', '996.73', '852.31', '008.45', '276.5', '996.1', '424.90', '39.43', '99.10', '97.49', '276.3', 'V10.87', '553.3', '346.90', '35.51', '39.61', '154.1', '198.89', '595.0', '595.2', '596.1', '48.62', '57.71', '56.51', '57.83', 'V30.01', '765.02', '769', '770.7', '771.81', '772.11', '550.90', '765.22', '362.21', '747.0', '999.9', '776.6', '53.01', '17.0', '35.21', '36.12', '36.15', '808.0', '823.00', '801.01', '807.09', '861.21', '865.00', '443.21', '482.41', '802.4', 'E812.0', '873.20', '79.39', '31.1', '79.36', '76.72', '20.2', '38.7', '33.27', '21.81', '43.19', '96.6', '93.46', '482.83', '279.00', '358.1', '253.6', '518.0', '790.01', '199.1', '285.29', '238.71', '783.21', '33.22', '96.56', '99.14', '553.21', '574.71', '569.69', '428.30', '358.00', '211.3', '041.12', '412', 'V45.82', 'V45.81', 'E878.8', '782.8', '707.8', '45.94', '46.52', '53.61', '51.22', '45.42', '51.88', '51.85', '99.71', '93.59', '426.0', '276.1', 'V42.2', '458.9', '37.83', '37.72', '13.0', '43.11', '37.78', '99.62', '203.00', '415.19', '996.85', '785.0', 'E878.0', '852.21', '733.00', 'E888.1', '519.09', '335.20', '518.83', 'E879.8', '280.0', 'V02.54', '344.9', '39.98', '33.21', '97.23', '807.02', '860.0', '852.06', '810.02', 'E816.2', 'E849.5', '225.2', '493.90', '441.01', '780.01', '995.92', '997.01', '348.1', '997.31', '453.89', '441.2', '041.85', '780.39', '414.00', 'V45.01', '38.45', '44.39', '34.04', '33.23', '193', '999.31', '997.79', '453.8', '428.20', 'V09.0', '585.3', '287.5', '274.9', '61.1', '60.1', '99.1', 'V31.01', '765.19', '765.28', '775.0', '806.4', 'V85.41', 'E881.0', 'E849.8', 'V10.52', 'V43.65', '720.0', '81.04', '77.79', '81.62', '84.51', '87.21', '414.2', '266.2', '36.13', '515', '441.4', '780.52', '327.23', '39.73', '39.22', '88.47', '88.44', '996.72', '789.00', 'V17.3', '35.33', '89.6', '88.53', '530.21', '995.91', '558.2', '197.7', '196.9', '286.9', 'V10.06', 'V12.51', '707.03', 'E849.7', '584.5', '569.49', 'E879.2', '48.24', '86.05', '188.8', '511.81', '491.21', '599.71', '331.82', '294.10', '564.00', '785.6', '427.5', '57.49', '57.33', '38.97', '428.31', '429.71', '35.71', '868.09', '813.41', '863.84', '933.1', 'E912', '45.62', '43.6', '52.09', '79.32', '79.02', '574.00', '426.3', '787.91', '396.2', '997.1', '427.1', '997.5', 'V45.02', '35.23', '36.11', '682.2', '785.4', '250.10', '709.3', '250.70', '250.60', '250.50', '362.01', '041.09', '041.6', 'V58.67', 'V12.72', '86.22', '71.09', '83.09', '86.04', '89.26', '038.19', '410.91', '578.9', '99.61', '512.1', '780.2', '369.4', '600.00', '197.2', 'V10.04', '934.1', '34.91', '428.22', '250.40', '296.80', '780.09', 'V49.86', '410.01', '37.32', '35.53', '89.68', '398.91', '396.3', '397.0', '276.50', '250.80', '414.8', '50.0', '437.2', '403.01', '296.89', '290.40', '437.0', '297.1', '345.90', '96.07', '575.0', '576.1', '51.01', '51.87', '852.00', '204.10', '921.1', 'V34.01', '775.5', '322.9', '416.0', '765.23', '776.7', '779.89', '38.92', '765.26', '770.89', '747.10', '998.2', '730.08', '041.11', '278.00', '34.03', '34.4', '83.82', '765.03', '550.92', '53.1', '331.4', '15.9', '22.', '42.23', '038.9', '574.50', '567.2', '785.52', '54.19', '54.12', '519.02', '411.1', '780.57', '162.3', '32.4', '32.5', '34.22', '40.11', '710.3', '570', '288.4', '567.29', '263.9', '560.89', '785.50', '276.4', '728.88', '995.93', '127.3', '284.1', '276.69', '934.9', '41.2', '45.73', '45.75', '46.21', '83.21', '99.77', '46.85', '86.11', '41.31', '423.9', '305.01', 'V10.3', 'V45.71', 'V12.55', '729.89', '731.3', '998.31', '438.0', '77.61', '77.81', '84.94', '86.74', '416.8', '294.20', 'V10.51', 'V58.61', '997.4', '576.2', 'V42.7', '571.5', 'V10.07', '698.9', '576.8', '51.37', '51.94', '51.1', '87.51', '51.98', '46.0', '41.0', '296.7', '724.5', '719.46', 'E884.2', '519.1', '295.90', '466.0', '293.9', '31.79', '33.48', '32.01', '98.15', '557.0', '567.89', '518.5', '789.59', '568.89', '574.20', '227.3', '255.41', '253.4', '76.2', '588.1', '440.23', '707.23', '682.7', '440.4', '707.15', 'E932.3', '458.0', 'V12.04', '592.0', 'V87.41', 'V58.65', '39.29', '88.42', '746.4', 'V15.1', '038.42', '81.91', '428.23', '440.24', '725', '424.2', 'V49.75', '35.22', '88.48', '430', '401.0', '780.1', '283.9', '293.0', '782.3', '781.94', '790.4', '300.01', '309.81', '305.60', '305.50', 'V10.41', '070.71', '789.5', '567.23', 'V45.1', '301.20', '608.4', '782.7', '765.16', '428.21', '707.0', '427.41', '053.9', 'V42.82', '201.50', '799.02', '414.02', '443.9', '426.4', '533.90', '519.4', '716.90', '577.1', '998.11', '44.32', '998.12', '433.10', '61.0', '39.31', '63.0', '154.8', '189.1', '197.6', 'V45.3', 'E878.6', '220', '48.52', '55.51', '54.21', '38.07', '92.27', '303.01', '720.2', '995.1', 'E928.9', '250.11', '344.1', '276.0', '757.32', '578.1', '852.20', '782.4', 'V66.7', '348.4', '238.75', '331.0', '212.7', '303.91', '368.2', '781.2', '37.33', '250.01', '344.09', '560.1', '041.7', '596.54', '340', '041.4', '573.8', '337.3', 'V13.02', '996.66', '282.49', 'V10.81', '728.89', '241.1', '80.05', '14.0', '83.39', '77.65', '84.56', '413.9', 'E879.0', '765.15', '460', 'V55.2', 'V10.09', '46.51', '54.59', '45.74', '54.3', 'E888', '13.9', '250.51', '250.61', '250.81', '296.20', '806.04', '291.0', 'E880.9', '29.4', '93.41', '410.11', '349.1', '39.65', '37.66', '39.32', '45.76', '54.63', '86.09', '185', '36.14', '562.11', '518.51', '428.32', '552.1', '729.73', '53.49', '54.25', '54.62', '46.11', '289.7', 'V42.83', 'V42.0', '268.9', '530.12', 'V10.44', 'E931.8', '998.89', '780.6', '21.2', '39.72', '773.2', '197.4', '420.0', '535.51', '332.0', 'V44.3', '45.14', '765.18', '88.75', '714.0', '35.11', '39.49', '348.30', '805.02', '807.2', '813.44', '807.03', 'E816.0', '357.6', '198.3', '189.0', '577.9', '560.9', '997.3', '77.89', '31.75', '31.74', '996.45', 'V43.64', '81.53', '84.57', '042', '799.4', 'E870.9', 'V12.01', '766.1', '998.0', '292.81', '696.1', 'E939.4', '36.99', 'E819.0', '601.1', '595.1', '359.89', '60.29', '571.8', '729.81', '110.1', '459.81', '320.9', '345.10', '383.00', '079.99', '564.1', '723.0', '288.60', 'V43.3', '45.24', '403.91', '362.34', '38.12', '348.5', '342.02', '569.3', '522.4', '041.01', '599.72', '440.21', '455.2', '37.36', '23.19', '770.82', '775.6', '764.97', '151.0', '338.12', '519.3', '42.41', '42.52', '43.5', '40.3', '46.39', '728.86', '174.8', '86.69', '83.32', '83.45', '83.87', '493.20', '273.1', 'V70.7', '274.01', '478.29', '600.01', 'V07.1', 'V14.0', 'V64.1', '426.13', '788.20', '041.02', '99.12', '518.84', 'V44.0', '11.0', '434.01', '343.2', '753.3', '784.3', '250.02', '414.12', '48.0', '410.41', '995.0', 'E934.2', '790.29', 'E932.0', '008.8', '275.2', '794.31', '275.3', '250.41', '465.9', '249.91', '36.05', '36.07', '88.52', '88.55', '99.2', '952.08', '415.11', '721.1', '997.2', '453.40', '344.00', '81.03', '81.63', '45.25', '692.9', '272.1', '693.0', 'E930.0', '251.2', '532.00', '482.0', '305.00', '530.6', '719.47', '719.41', '44.44', '287.4', '61.', '63.', '770.0', '774.6', '191.8', 'V54.19', '438.11', '11.3', '228.04', '562.00', 'E947.8', '577.8', '771.7', '414.11', 'E878.1', '995.27', 'E930.8', 'E931.9', 'V16.0', '36.91', '588.81', '574.51', '820.09', '719.06', 'E884.4', '573.9', '81.92', '99.29', '99.6', '79.35', '456.0', '452', '995.90', '45.95', '410.81', '997.02', '88.45', '45.0', '161.8', '519.8', '31.43', '39.41', '741.93', '440.20', '429.5', '35.12', '156.0', '196.2', '254.0', '254.8', '350.1', '78.2', '593.9', '99.20', '805.4', '831.00', '991.6', '478.24', '288.09', '453.81', '682.1', '277.4', '794.8', '782.1', '83.02', '60.2', '136.3', '514', '710.1', '492.8', '425.5', '553.1', '443.0', '37.21', 'V10.46', '518.89', '88.73', '493.92', '253.2', '198.82', '112.2', '56.52', '55.03', '87.74', '733.13', '426.51', '275.0', '535.61', '457.1', 'V10.82', '39.5', '39.9', '567.21', '569.5', '451.89', '572.3', '314.01', '088.82', '117.9', '054.9', '54.4', '51.11', '866.00', 'E966', 'E849.0', '41.95', '55.81', '156.1', '574.11', '51.32', '821.23', '553.8', 'V64.2', '041.04', '707.05', '707.21', '93.44', '432.9', '342.00', '351.8', '519.19', '362.50', '366.9', '276.6', '251.8', '511.0', '996.81', '34.51', '286.3', '72.2', '88.91', '87.61', 'V45.73', '250.33', '238.77', '404.91', '425.8', 'V45.85', '250.43', '583.81', 'V45.11', '250.53', '783.1', '587', '155.0', '070.32', '453.0', '751.69', '50.22', '40.29', '196.3', '23.9', '23.4', '92.3', '715.96', '764.06', '779.2', '761.2', '250.71', '135', '99.60', '342.90', '426.11', '787.23', '432.1', '780.60', '241.0', '282.62', '416.2', '517.3', '301.22', '709.2', 'E929.0', 'V45.2', '429.9', '86.63', '86.4', '722.52', '041.49', '715.36', 'V10.42', 'V88.01', '45.16', '88.74', '482.42', '453.41', '996.64', '333.85', 'E947.9', 'E879.6', 'V62.5', '81.54', '765.25', 'V85.4', '44.38', '295.72', '277.39', '48.23', '88.43', '362.84', 'V53.91', 'V49.72', '13.1', '10.9', '620.2', '038.44', '263.0', '444.1', '998.6', '568.0', '569.89', 'E870.0', '65.49', '46.75', '458.8', 'V10.11', '577.2', '50.11', '38.44', '458.2', '88.57', '428.43', 'V53.32', '52.', '37.26', '13.', '365.9', '600.90', '429.3', '37.99', '790.92', '724.2', 'V12.54', '482.1', '275.5', '756.6', '51.03', '51.14', '557.9', '480.1', '707.14', '372.72', '252.00', '997.69', 'E878.5', '428.40', '440.1', '784.51', 'V45.89', '786.09', '787.20', 'V10.79', '876.0', '875.0', '901.82', '901.9', '54.11', '34.02', '38.85', '574.60', '291.2', '357.5', 'V44.6', 'V11.3', '51.23', '440.0', '358.0', '038.49', '576.4', '333.1', 'E942.0', 'V58.66', '788.41', '788.63', '438.19', '304.01', '722.92', '478.31', 'V44.1', '492.0', '31.0', '493.22', '255.5', '202.88', '99.28', '55.23', '729.1', '999.2', '39.63', '590.10', '599.7', '591', '999.32', '200.20', '284.19', '288.00', '342.81', '338.29', '481', '305.91', '410.31', '55.69', '52.80', '583.9', '35.24', '454.9', 'V15.88', '39.71', '983.9', '535.41', '976.7', '963.0', 'E950.7', 'E950.4', 'E849.3', '942.14', '948.00', 'E958.1', '989.9', '530.19', '456.20', '537.82', '585.2', 'V49.83', 'V12.71', '42.33', '746.6', '746.09', 'E885.9', '715.97', '746.89', '81.66', '427.81', '470', '455.8', '271.3', '44.95', '295.70', '348.31', '288.03', '157.8', '455.3', '97.55', '865.02', '807.4', '958.4', '868.03', '807.06', '958.7', '959.12', '41.5', '39.0', '34.09', '070.20', '305.61', '305.51', '285.8', '765.29', '574.70', '338.18', '296.90', '51.36', '51.41', '39.64', '341.9', '331.3', '715.35', '772.10', '191.6', '255.4', '787.2', '411.89', '37.34', '37.27', '37.28', '442.3', '39.52', '823.12', '851.81', '807.01', '758.0', '830.0', 'E813.1', '810.01', '873.40', '920', '801.11', '79.66', '78.17', '78.67', '79.06', '84.72', '86.59', '304.11', '291.1', '292.0', 'V85.24', '805.04', '805.06', '707.19', '792.1', '805.2', '296.30', '296.33', '881.02', '873.0', '305.20', 'E957.1', 'E956', 'E901.0', '536.3', '50.59', '447.4', '296.50', '851.80', '813.05', '78.13', '969.0', '296.23', 'E950.3', '777.5', '721.0', '851.86', '461.0', '750.9', '42.42', '33.39', 'E870.6', 'E871.6', '162.8', '478.5', '162.9', '478.74', '31.42', '342.91', '153.9', '39.74', '789.01', '572.4', '568.81', '50.12', '110.5', '426.82', 'V46.11', '574.41', '295.30', '053.19', 'V10.43', '765.14', '765.24', '786.3', '494.0', '39.79', 'V45.4', '562.12', '038.8', '239.0', '54.72', 'V62.84', '133.0', '301.4', 'V60.0', '482.2', '721.8', '464.10', '041.10', '238.4', 'V49.87', '722.6', '789.2', 'E942.6', '162.5', '32.29', '482.82', '575.12', '998.32', 'V64.41', '788.5', '793.11', '238.72', '288.50', '455.0', '696.0', '96.33', '786.2', '510.9', '567.38', '867.0', 'V53.31', 'V13.01', '34.52', '34.2', '862.1', '922.1', '34.82', '291.3', '359.4', '444.89', '442.2', '99.69', '038.10', '853.01', '200.30', 'E884.9', '802.8', '802.0', '389.9', 'V45.78', '21.71', '453.42', '153.5', '197.5', '198.1', '45.26', '47.09', '342.92', '348.8', '15.3', '478.30', '996.59', '701.5', '530.5', '625.6', '44.67', '31.5', '89.32', '997.09', '336.1', 'V85.43', '343.0', '754.70', 'V46.3', '84.17', '84.3', '935.2', '301.83', '535.40', 'E915', '98.03', '806.09', '35.3', '707.24', '730.17', '730.15', '326', '698.3', '289.0', '197.8', '275.41', '46.73', '511.89', '428.42', '585.4', '784.7', '426.7', '21.01', '997.49', '795.5', '37.0', '89.59', '812.21', '866.02', '807.00', '808.41', '372.00', 'V49.62', '79.01', '261', '707.12', '041.86', '537.89', '996.74', '184.8', '808.2', 'E887', '996.69', 'V58.83', 'V16.3', 'V55.3', 'V55.6', '68.8', '71.5', '46.13', '71.79', '56.71', '40.52', '40.54', '40.59', '59.8', '279.01', '309.0', '324.0', 'V58.11', '285.22', '780.61', '50.94', '437.3', '305.03', '89.61', '274.00', '780.97', 'E937.9', '778.8', '821.33', '958.92', '873.42', 'E813.8', '813.02', '873.63', '815.00', '79.65', '83.14', '83.64', '77.67', '83.65', '78.63', '999.39', '682.3', '451.82', '15.1', '040.82', '711.02', '881.21', '881.11', '726.33', '009.0', 'E917.9', '80.82', '153.3', '733.09', '55.53', '440.30', '444.22', '786.59', 'E878.4', '38.08', '441.03', '772.12', '775.7', '770.5', '777.6', '765.12', '14.24', '278.03', '535.00', '337.1', '530.20', '281.0', '701.1', '703.8', '709.8', '780.50', '54.98', '807.07', '850.11', '338.11', '410.21', '778.6', '716.96', '244.0', '33.91', '33.78', '287.49', 'V12.09', '354.9', '38.14', '39.56', '813.51', '816.01', '79.62', '78.59', '96.59', '490', '369.60', '784.5', '295.60', 'E879.9', '265.1', '425.1', '244.2', '572.0', '574.31', '50.91', '802.29', '512.0', '996.79', 'E917.5', 'E849.4', 'E007.1', '76.76', '528.3', '525.79', '477.9', '558.9', '453.82', '556.9', '835.00', '977.8', 'E858.8', '79.75', '250.72', '965.8', 'E850.8', '273.3', 'V17.49', '567.22', '289.59', '041.84', '478.79', '456.8', '31.99', '41.1', '423.8', '733.90', '37.31', '444.21', '780.62', '99.23', '38.03', '756.12', '724.02', '737.30', '81.08', '84.52', '146.1', '29.33', '40.41', '76.09', '76.43', '86.89', '86.28', '336.8', '605', '573.3', '995.94', 'E936.3', 'E936.1', '719.45', '357.82', '611.1', '512.8', '32.1', '996.2', '24.2', '491.22', '39.59', '307.9', '94.62', '874.4', 'E870.8', '998.81', '531.71', '537.0', 'V85.0', '537.3', '789.07', '724.3', '43.7', '44.0', '802.1', '870.0', '88.1', '901.0', '860.2', '578.0', 'V12.59', '81.02', '776.1', '772.0', 'V72.1', '95.43', '238.7', '579.0', '153.4', '575.11', '50.3', '54.23', '693.1', 'V15.02', '773.0', '99.01', '786.6', '852.26', '801.26', '891.0', 'E822.7', '51.02', '150.5', '998.01', '996.09', '414.04', '34.79', '59.0', '553.20', '253.5', '277.89', '249.00', 'V13.51', '205.02', '721.90', '996.82', '532.30', '250.13', '250.63', '250.73', '443.81', '537.83', '209.29', '209.72', '453.86', '569.84', '790.94', '39.1', '88.64', '96.06', '343.9', '319', '746.87', '530.82', '623.8', '593.81', '527.2', 'E939.3', '281.9', '87.54', '423.3', '852.01', '860.4', '810.10', '811.00', '811.03', 'E812.2', '79.69', '197.3', '198.4', '336.3', 'E935.3', '736.79', '788.62', '81.05', '80.99', '81.64', '345.40', '252.08', '801.36', '805.07', 'E814.7', '800.36', '555.9', '723.1', 'E879.1', 'V44.2', '532.90', '52.93', '569.83', '998.83', '569.81', '557.1', '45.91', '54.61', '511.8', '996.04', '37.98', 'V85.36', '788.29', 'E938.4', '786.1', '31.29', '65.39', '729.9', '38.18', '218.0', '68.29', '274.02', '787.22', '530.10', '44.2', '225.0', '157.0', '150.8', '43.89', '530.7', '532.10', '567.82', '44.42', '99.21', '333.2', '99.81', '284.9', '435.9', '787.29', '596.3', '283.0', '936', 'E958.8', '869.0', '969.4', '305.90', '535.60', '301.7', '301.81', '276.61', '88.51', '038.12', '747.3', '440.22', '39.25', '821.20', '807.08', '780.72', '823.82', '863.89', '822.0', '786.4', '79.16', '55.4', '585', 'E885.4', '39.57', '438.83', '453.2', '851.82', '478.6', '715.31', '300.3', '607.84', 'V45.79', '198.7', '54.0', '286.4', '22.19', '070.30', 'V08', '305.93', '535.10', '753.13', '288.3', '394.1', 'V45.86', '531.10', '44.41', '560.81', 'E878.3', '46.1', '48.63', '46.2', '440.31', '851.01', 'E968.9', '782.0', 'E911', '590.80', '438.9', '379.41', '757.33', '38.16', '37.73', '37.82', '37.94', '331.9', '038.43', '710.0', '616.4', '593.89', '616.50', '71.3', '48.81', '996.01', '794.39', '37.76', '89.45', '254.1', '773.1', '567.9', 'V85.33', '17.36', '851.85', '482.9', 'E819.1', '785.9', '530.0', '42.0', '538', '290.12', '868.02', '864.01', '864.05', 'E929.1', '309.28', 'V61.0', '711.01', '780.65', '80.21', '666.24', '646.64', '648.24', '654.14', '218.9', '665.54', '69.52', '68.49', '886.1', '816.03', 'E920.1', '282.4', '82.86', '79.34', '43.', '710.8', '424.3', '35.25', '441.3', 'V12.79', '246.9', '433.30', '070.44', '608.89', '501', '732.0', '530.3', 'V10.02', '42.92', '722.93', '764.08', '356.8', '537.9', '88.6', '843.9', '345.41', '517.8', '298.9', '596.51', 'E935.2', '588.89', 'V54.13', '242.20', '586', '37.71', '37.77', '47.0', '42.55', '45.93', '250.22', '182.0', '615.0', '614.0', '627.1', '760.76', '621.4', '041.05', 'V85.23', '69.09', '65.61', '91.46', '96.38', '537.84', '531.00', '442.83', '721.3', '349.31', '738.4', '80.51', '35.9', '805.6', '867.8', '446.4', 'V64.42', '32.49', '34.99', '742.2', '752.61', '755.10', '300.7', '758.9', '478.19', '394.2', '793.81', '85.11', '155.1', '97.05', '51.84', '038.2', '117.3', '054.79', '382.01', '453.9', '788.42', '690.10', '969.3', '780.79', 'V58.43', '731.0', 'V09.80', '952.14', '438.22', '262', '341.8', '801.21', '22.0', '783.7', '96.08', '89.62', '733.82', '905.4', 'E929.3', '230.0', 'V10.00', '29.12', '34.92', '87.41', '81.51', '790.5', 'V10.85', '805.01', '784.69', 'V85.1', '81.01', '277.30', '921.2', '733.14', '996.49', '733.19', '81.52', '78.65', '801.10', '801.20', 'V64.4', '50.29', '374.30', '442.89', '255.0', '360.00', '695.89', 'E931.7', '698.2', '815.02', '862.22', '42.82', '42.87', '824.8', '83.85', '81.13', '423.2', 'E879.4', '441.02', '447.1', '39.50', '39.90', '730.18', '722.71', '307.89', 'V44.4', '794.09', '852.25', '852.05', '584.8', '580.89', '788.21', 'V58.69', '799.0', '722.10', 'V65.49', '997.39', '410.72', '695.3', 'E945.7', '802.6', '482.40', 'E823.0', '801.00', '825.25', '79.17', '53.41', '22.01', '881.00', 'E815.0', '611.0', '85.0', '152.0', '52.7', '990', '12.4', '153.8', '402.91', '730.28', '647.83', '646.63', '242.00', '648.13', '648.93', '648.23', '864.03', '873.53', '873.54', '873.71', '317', '907.0', '27.59', '40.4', '24.32', '355.9', '831.01', '727.61', 'E888.8', '747.40', '37.81', '420.90', '428.1', '37.75', '342.80', '348.89', '87.03', '281.1', '536.42', '97.02', '575.4', '707.10', '996.61', '289.81', '366.8', '569.9', '39.62', '494.1', '438.20', 'V55.0', '461.9', '22.63', '22.42', '21.5', '21.3', '999.33', '112.89', '403.11', '263.8', '724.00', '791.0', '599.70', '338.3', '356.9', '88.93', '776.4', '777.4', '783.41', '766.21', '749.00', '744.29', '748.1', '742.4', '743.63', '96.35', '952.05', 'E968.2', '872.01', '880.00', '30.9', '34.0', '18.4', '540.0', '47.2', '566', '249.01', '420.99', '728.85', '787.01', '365.70', '37.12', '850.5', 'E828.2', '201.90', '618.4', '614.6', '112.3', '68.59', '70.77', '57.32', '745.4', '173.7', '969.8', '333.99', '389.10', '205.00', '722.0', '599.69', '600.91', '473.9', '344.01', '806.00', '560.2', '564.7', 'V55.1', '290.0', '008.5', '235.2', '579.9', '534.90', '730.12', '94.0', '820.21', '240.9', '96.48', '599.1', '596.0', '909.2', '730.25', '980.0', '305.40', 'E853.8', 'E853.2', 'E860.0', '764.07', '710.2', '785.2', '810.00', '865.03', '054.3', '991.1', '991.2', '915.2', '21.21', '996.71', 'V32.01', '820.8', '191.4', '784.0', 'V16.8', '573.4', '518.4', '592.1', '368.40', '648.44', '642.44', '669.34', '649.34', '674.84', '965.4', 'E950.0', '648.94', '251.1', '572.8', '93.0', '89.14', '530.2', '768.9', '760.75', 'V29.3', '422.90', '362.75', '433.11', '96.18', '438.13', 'E933.0', '780.99', '582.9', '753.0', '93.96', '202.10', '88.54', 'V10.89', '45.11', '038.40', '46.10', '275.03', '790.93', 'V16.6', 'V16.1', '528.00', '41.05', '92.29', '402.90', '886.0', 'E919.8', '84.22', '45.79', '53.51', '801.76', '864.04', '868.01', '802.5', '738.19', '800.76', 'E882', '913.0', '158.0', '070.51', '324.1', '40.2', '44.1', '211.1', '79.15', '795.79', '730.24', 'V49.76', '458.21', '88.49', '041.89', '35.39', '51.0', '608.86', '771.6', '443.22', '284.11', '197.1', '337.9', '821.29', 'E884.6', 'V15.51', '446.6', '283.11', '521.00', '386.00', '155.2', '39.26', '99.06', 'E928.8', '427.0', '89.49', '285.3', '433.31', '647.84', '648.14', '403.00', '39.99', '756.16', '345.51', '112.85', '694.5', '305.02', 'E812.1', '428.41', '34.21', '117.5', '288.0', '965.02', 'E850.1', '46.32', 'V71.4', '296.40', '910.0', 'E814.0', '251.3', 'V88.12', '770.8', '322.0', 'E942.1', '746.02', '204.00', '277.88', '379.24', '99.72', '39.2', '722.73', '705.1', '372.73', 'E935.7', 'E942.9', '456.1', 'V18.3', '70.0', '748.3', '362.52', '710.4', '358.01', '34.84', '34.93', '765.04', '772.13', '53.00', '579.3', '296.24', '729.5', 'E937.0', '047.9', '39.51', '702.19', '555.1', '790.99', '680.2', '99.63', '153.6', '038.3', '599.6', '200.80', 'V58.12', '528.0', '15.0', '71.1', '99.26', '518.52', '198.2', '289.9', '812.03', '831.09', '953.4', '79.71', '905.0', '906.0', '20.6', '97.33', '290.41', '152.8', '51.69', '780.93', '345.3', 'E929.9', '315.9', 'V06.6', 'V04.82', 'V04.81', 'V05.8', '99.59', '99.52', '171.5', 'E944.4', '304.20', '980.2', '191.9', 'E860.3', '237.70', '444.81', '384.20', '820.22', '825.21', '825.23', '484.1', '008.69', '078.5', '362.10', '52.52', '39.91', '150.9', '78.69', 'V49.84', '598.9', '58.6', 'V45.75', '054.10', '997.91', '238.76', '425.9', '541', '41.04', '238.79', '272.2', '715.98', '574.21', '196.0', '802.39', '802.26', '707.25', '110.3', 'E850.4', '582.81', '368.8', '530.11', '24.0', '778.0', '752.51', '012.05', '789.30', '295.62', '410.92', '746.7', '814.00', '977.9', 'E980.5', '801.22', '812.01', 'V85.44', '300.14', 'V15.41', 'V15.52', '78.41', '348.3', '36.16', '789.06', '338.19', '338.4', '787.03', 'V55.4', 'V18.9', 'E953.0', '435.2', '530.13', '935.1', '34.1', '794.15', '99.82', '202.81', '20.49', '564.81', '907.2', '519.2', '34.01', '874.8', '60.9', '824.4', '621.30', 'E935.6', '731.8', '714.30', '707.13', '806.07', 'E001.0', '282.60', '112.1', '642.33', '250.92', '747.81', '88.61', '716.94', '57.94', '46.8', '807.05', 'E885.3', '97.89', '540.9', '47.01', '786.50', '459.9', '93.', '574.10', '318.2', '45.82', '46.23', '279.8', '593.2', '596.7', '595.82', '57.0', '380.10', '80.76', '780.4', '786.52', '98.04', '17.55', '283.19', '293.1', '796.1', '727.00', '836.2', '724.8', '275.49', '712.36', 'V45.61', '536.8', '567.81', '821.01', '808.49', '459.0', 'E819.2', '824.2', '87.76', '421.9', '449', '437.5', '333.0', '789.09', '250.12', '51.12', '530.89', '443.24', 'V29.8', '775.4', '279.11', '779.0', '756.10', '748.60', '756.3', '524.00', '998.09', '440.8', 'V43.61', '711.07', '84.15', '77.69', '786.06', '405.99', '746.83', '558.3', '441.7', '597.89', '516.8', '429.0', '531.90', '996.4', '723.4', 'V15.08', '77.77', '411.0', '410.12', '31.41', '839.05', '144.0', '27.49', '76.31', '76.91', '25.2', '40.42', '26.32', '77.73', '78.53', '550.00', '597.0', '608.83', '58.91', '585.5', '411.81', '300.11', '996.52', '78.51', '86.75', '995.61', '307.51', 'V65.2', '410.51', '38.43', '287.3', '147.8', '62.0', '65.0', '36.19', '860.3', '864.11', '759.6', '958.91', '862.0', '868.13', '459.2', '354.0', '44.3', '799.89', '620.9', 'V65.3', '46.74', '53.69', '189.2', '970.8', '996.02', '707.09', '299.80', '729.71', '82.09', '82.22', '786.05', 'E935.9', '027.0', '323.9', '348.9', '205.90', '569.82', '593.3', '567.8', '701.9', '729.39', '86.83', '57.95', 'V85.42', '434.90', '041.5', '22.1', '191.1', 'V85.31', '37.64', '45.43', '765.13', '438.82', '926.19', '807.04', '619.1', '97.37', 'E939.2', '787.02', '910.8', '357.0', '780.64', 'E934.6', '289.82', '417.8', '800.21', '839.02', '433.20', '209.25', '209.71', '292.12', 'E935.8', '52.53', '994.1', 'E954', '966.3', 'V61.42', '781.99', 'E968.8', '921.3', '426.6', 'E876.8', '593.4', '305.21', '574.90', '46.71', '447.9', '760.0', '523.40', '211.4', '86.27', '35.27', 'V10.90', '151.9', '273.8', '453.3', '325', '776.5', '314.00', '893.0', '337.20', '447.6', 'V44.50', '43.0', '487.8', '39.75', '277.7', '040.0', '906.3', 'E929.8', '83.44', '39.76', '423.0', '786.30', '304.41', '707.20', '56.2', '42.4', '44.29', '967.0', 'E950.1', '38.87', '33.29', '414.10', '37.25', '704.8', '10.2', '580.9', 'V45.76', '76.75', '11.8', '433.21', '351.0', '580.81', '97.51', '39.27', '852.22', '853.02', '237.73', '626.0', '304.00', '803.75', '812.00', '86.3', '238.1', '552.21', '44.31', '45.02', '965.09', '304.70', 'E850.2', '642.24', '271.0', '378.00', 'E849.9', '620.8', '289.89', 'V09.91', '112.4', '357.8', '998.13', '823.32', '824.1', '823.22', '852.40', '847.0', '34.06', '194.1', '252.1', '784.2', '68.9', '292.84', '304.10', '821.11', '604.0', '607.2', '64.2', '57.18', '62.3', '46.03', '64.49', '46.01', '58.39', '61.3', '49.21', '55.93', '455.1', '112.84', '49.42', 'V67.2', 'V67.1', '996.67', '711.06', '567.31', '720.9', '527.7', '80.15', '80.16', '571.6', 'V56.0', '287.31', 'V85.32', '303.92', '571.0', '569.1', 'E826.1', '123.1', '793.1', '681.11', '972.4', '307.50', '97.64', '790.6', '753.12', '426.10', '92.24', 'V19.5', 'V16.7', '327.26', '453.85', '83.95', '980.9', 'E860.9', '304.30', '521.09', 'E945.5', '661.11', '642.51', '648.61', '647.82', 'V27.0', '659.51', '648.91', '74.1', '73.4', '73.09', 'V15.84', '32.39', '787.3', '764.04', '804.22', '639.8', '639.0', '789.04', '615.9', '574.80', '50.14', '250.83', '715.80', '304.21', '711.05', '304.02', '71.0', '80.85', '80.75', '805.8', '911.0', '912.0', '349.81', '870.8', '808.43', '823.81', '873.49', '924.00', '79.19', '76.79', '76.92', '79.07', '93.55', '442.81', '525.8', '77.88', '84.11', '93.57', '031.2', '046.3', '707.04', '78.19', '79.09', '34.', '30.2', '975.4', '276.9', '305.70', 'V74.1', '52.82', '812.20', '823.92', '838.05', '79.78', '79.31', '78.57', '821.10', '813.83', '310.0', '39.42', '29.1', '771.4', '762.1', '821.21', '823.02', '844.1', '836.0', '438.53', '191.2', '695.9', '094.0', '996.76', '713.5', '318.1', '745.60', '257.2', '709.01', '347.00', '89.19', '245.2', '288.02', '710.9', '751.1', '968.0', '964.2', '433.00', 'V01.1', '853.00', '620.1', '69.7', '78.49', '378.52', '753.10', 'V02.59', 'V12.41', '815.09', 'E818.7', '79.33', '48.71', '724.4', '77.7', '344.81', '729.92', '196.6', '46.86', '839.06', '853.05', '364.00', '796.3', '745.2', '751.2', '750.3', '98.02', '53.8', '47.19', 'V85.38', '763.83', '574.40', '999.8', '805.08', 'E931.0', '478.75', '528.9', '575.8', '783.0', '273.0', '40.24', '52.12', '487.1', '342.10', '722.91', 'V45.77', '259.2', '209.36', '209.75', '21.03', '362.30', '779.5', '760.72', '763.0', '444.0', '052.1', '425.7', '596.8', '796.2', '788.39', '491.20', '34.24', '414.9', 'E938.2', '806.20', 'E823.2', '33.0', '415.12', 'V45.88', '305.63', '997.41', 'E930.9', '851.02', '682.4', '274.82', '12.5', '790.8', '239.7', '965.1', '730.27', '997.99', '457.8', '601.0', '478.1', '813.42', '729.72', '289.84', '429.79', '288.63', '462', '427.69', '772.4', '45.3', '737.10', '755.31', '626.2', '625.9', 'E932.2', '616.10', '426.89', '250.52', 'V60.2', '348.0', '11.4', '786.8', '205.10', '784.42', '041.82', '429.89', '873.64', 'E928.3', '306.8', '24.5', '282.5', '373.00', '742.3', '368.16', '454.0', '909.9', '394.0', '958.3', '891.1', 'V12.53', '368.47', '244.8', '76.1', '21.1', '756.79', '54.24', '611.72', 'E938.3', '800.12', '801.12', '924.11', '138', '435.3', '42.81', '730.07', '77.68', '56.0', '56.31', '994.7', '157.1', '157.2', '777.1', '294.9', '346.80', '153.0', '44.13', 'V42.5', '304.23', '305.23', '305.73', '344.40', '86.67', '97.29', '420.91', '473.3', '110.9', '564.89', '22.64', '969.6', '305.30', 'E854.1', '396.0', 'V10.72', 'E849.6', '532.60', '812.40', '45.01', '93.54', '560.0', '353.6', '307.59', '596.9', 'E876.2', '556.1', '755.01', '86.26', '437.4', '781.0', '716.97', '735.4', '700', '279.53', '996.88', '934.8', '803.76', '803.66', '873.43', '27.51', '396.8', '290.3', '70.72', '57.81', '862.29', 'E816.1', '308.9', '054.19', '296.34', '965.61', '556.8', '295.64', '608.20', 'V26.52', '355.79', '244.1', '741.90', '569.41', '746.9', '410.82', '774.30', '778.3', '361.89', '190.5', '305.22', '079.51', 'V44.59', '780.33', '94.65', '903.01', '873.8', '796.4', '535.30', '716.95', '228.09', '534.40', '112.9', 'V10.03', '37.87', '897.3', '821.39', '824.9', '928.10', '881.10', '813.43', '839.20', '77.63', '455.6', '569.61', '45.61', '737.39', '780.59', '575.10', '345.71', '344.89', '173.3', '362.03', '76.45', '21.4', '16.59', '38.34', '996.39', '916.2', '913.2', '910.2', '914.2', '38.22', '94.25', '813.11', '748.8', '212.6', '78.1', '37.4', '289.51', '507.1', '99.19', '359.81', '45.22', '161.9', '82.12', 'E884.3', '362.02', '365.63', '14.74', '13.41', '12.92', '13.71', '12.73', '14.9', '715.37', '81.11', '81.29', '996.43', '719.50', '72.0', '579.8', 'V18.59', '45.15', 'V58.64', '513.0', '33.93', '712.33', '873.44', '480.8', '488.1', '191.3', 'V14.5', 'V14.8', '571.42', '18.0', '530.4', '42.89', '372.30', '861.32', '868.14', '881.20', '902.53', '860.5', 'E922.9', '38.84', '529.8', '29.11', '50.19', '37.49', '429.4', '583.1', '701.3', '443.89', '426.52', '534.50', '361.9', '423.1', '482.84', '130.7', '787.6', '616.0', '68.4', '65.91', '996.41', '451.19', '453.52', '453.51', '38.99', '600.0', '252.02', '918.9', '726.0', '716.99', '228.02', '355.1', '362.74', '801.06', '786.03', '288.61', '214.8', '813.01', '788.1', 'E935.1', '681.10', '295.32', '48.82', '89.39', '569.62', '97.03', '380.39', '812.10', '813.92', '930.1', '881.01', '79.61', '79.22', '16.81', '10.6', '294.11', 'V43.0', 'V64.3', '616.89', 'E930.1', '111.9', 'E930.5', '962.3', 'E858.0', '48.69', '820.03', '202.00', '77.45', '569.85', 'E980.9', '779.82', 'V20.2', '482.81', '284.89', '733.11', '528.09', '560.32', '532.20', '442.84', '282.0', '242.21', '359.3', '794.5', '762.7', '746.85', '775.9', '743.65', '728.71', '510.0', '250.20', '20.5', '840.4', '840.8', '715.91', '83.63', 'V54.9', '793.89', 'E943.0', '35.52', '96.27', '154.0', '800.22', '817.0', '215.0', '996.44', '475', '478.21', '034.0', '078.19', '28.0', '880.03', '883.0', '46.42', '761.3', '437.9', 'V58.62', 'V14.2', '518.3', '447.0', '865.01', '861.01', '45.8', '46.20', '975.2', '701.0', '719.65', '295.92', '364.9', '053.13', 'E910.0', 'E002.6', 'E831.4', '428.9', '294.21', '32.28', '228.01', '722.2', '674.54', '865.13', '923.01', '967.8', 'E950.2', '172.9', '378.54', '733.99', '622.11', 'V45.12', '969.09', '562.13', 'E945.2', '924.10', '751.5', '806.05', '344.03', '54.64', '996.86', '52.6', '38.09', '56.82', 'V01.7', '802.28', 'E825.2', '782.5', '357.89', '358.9', '825.22', '415.0', '791.9', '38.06', '958.2', '808.8', '607.9', '62.5', '64.98', '53.02', '196.8', '729.6', '85.82', '85.22', '811.02', '417.1', '522.5', '426.12', 'V12.02', '446.5', '205.01', '88.5', '35.14', '429.83', '212.5', '246.2', '34.25', '070.1', '999.89', '48.76', '69.98', '70.92', '405.91', '183.0', '789.51', '218.1', '65.62', '39.24', '88.67', '54.99', '345.50', '003.1', '556.6', '771.1', '537.81', '812.09', 'E825.1', '815.01', '814.05', '814.06', '814.07', '79.13', '331.5', '296.25', '78.05', '550.12', '771.83', '777.8', '733.81', '728.13', '905.3', 'V85.39', '698.8', '50.13', '38.98', '719.16', '252.8', '745.8', '747.42', '35.61', '35.91', '771.8', '304.71', 'E938.7', '395.0', '453.1', '33.2', '68.41', '65.63', '277.3', '33.28', '85.43', '85.7', '531.70', '695.4', '592.9', '755.63', '77.39', '78.09', 'V61.41', '803.26', 'E821.1', 'V42.81', '348.82', '801.25', '730.20', '569.42', '519.9', '154.3', '806.25', 'E835.3', '77.99', '864.02', '845.00', '446.29', '120.9', '491.9', '471.9', '707.11', '453.87', '719.02', '279.52', '923.10', '970.81', 'E854.3', '39.92', '69.0', '88.65', '139.8', '43.41', '719.7', '516.9', '36.02', '742.1', 'E815.1', '551.1', '808.42', '310.2', '053.79', '87.77', '987.8', 'E869.8', '305.62', '209.79', '209.20', '209.73', '81.06', '279.03', '780.71', '43.99', '46.41', '278.8', '96.55', '626.8', '88.79', '733.42', '614.3', '44.69', '88.01', '789.1', '760.79', 'E939.0', '573.0', '272.7', 'V85.35', '359.1', '377.49', 'V86.0', '300.29', '780.03', '438.50', '404.93', '60.5', '614.5', 'E950.9', '493.91', '523.10', '868.04', 'E933.4', '867.2', '863.21', '56.75', '151.4', '535.01', '171.2', '82.56', '40.23', '357.7', '369.00', '38.86', '585.1', '800.31', '238.2', '900.03', 'V26.51', 'V17.1', '388.70', '11.', '748.61', '152.9', '031.0', '627.3', '851.41', '288.62', '53.71', '703.0', '52.22', '300.15', '305.53', '36.04', '053.29', '273.2', '806.03', '45.31', '286.0', 'V54.12', '726.11', '357.81', '34.81', '45.72', '299.00', '478.4', '21.09', '741.00', '334.1', '54.74', '93.56', '965.00', 'E980.0', 'E980.3', '349.0', '268.2', '742.59', '367.4', '438.14', '995.80', 'E967.3', '300.02', '864.15', '890.0', '801.02', '812.59', '356.1', '821.00', '854.06', '79.05', '581.9', '781.8', '438.12', '195.3', 'V49.73', '788.91', '530.84', '31.73', '40.7', 'V85.37', '156.2', '44.14', '600.9', '508.1', '242.90', '485', '996.65', '382.9', '59.94', '32.2', '37.91', '48.1', '574.61', '404.90', '250.30', '921.0', '99.17', 'V13.65', '377.41', '339.3', '054.40', '414.19', 'V17.4', '216.7', '162.4', '272.8', '37.24', '839.03', '952.00', '263.1', '52.01', 'E942.2', '800.85', 'E906.8', '78.18', '767.19', '99.0', '388.69', '921.9', '923.00', '774.39', '743.30', '743.20', '216.5', '242.80', '121.1', '726.10', '43.82', '54.51', '252.01', '048', '079.83', '378.10', '161.3', 'E931.3', '53.9', '296.53', '88.14', '34.23', '250.90', '87.53', '202.82', '770.16', '764.98', '685.1', '99.09', '48.36', '596.59', '35.72', '965.01', '81.35', '767.0', '853.06', '35.70', '171.3', 'V02.62', '836.1', '715.16', '80.6', 'E937.8', 'E003.2', '959.01', '227.0', '37.86', '32.6', '813.82', '865.09', '333.6', '536.49', '751.62', '614.4', '86.01', '110.4', '365.73', '342.82', '440.29', '457.0', '441.6', '764.05', '438.7', '37.74', '733.6', 'V14.1', '780.94', '426.9', '334.3', '581.2', '477.8', '427.61', '200.21', '153.1', '453.84', '996.47', '78.55', '711.03', '80.13', '824.3', '823.30', '928.21', '890.1', 'E814.1', '83.77', '560.39', '309.24', '863.29', '54.75', '384.01', 'V85.30', '882.0', '778.4', '459.89', '009.1', '132.0', 'E812.3', '537.4', '44.63', '716.80', '380.22', '50.61', '765.21', '943.23', '945.34', '007.4', '44.5', '162.2', '191.5', '53.7', '157.9', '552.3', 'V12.61', 'E987.1', '871.1', '25.51', '11.51', '38.82', '975.5', 'E980.4', '23.09', '53.0', '786.39', '256.4', '629.81', '923.20', '438.21', '32.59', '198.81', '852.41', 'E817.1', '088.81', '422.0', '52.11', '39.21', '52.59', '99.03', '704.01', 'V15.07', '708.9', '483.0', '601.9', '368.41', 'V49.85', '203.02', '805.05', 'E813.6', '365.89', '801.31', 'E960.0', '451.83', '378.81', '91.63', '772.14', '45.19', '801.32', '759.89', '282.46', '823.42', '57.89', 'E916', '873.1', '810.03', '292.85', 'E939.8', '92.0', '95.47', '737.19', '851.40', '29.3', '57.6', '57.17', '235.4', '607.83', '800.25', '379.43', '253.3', '77.1', '38.04', 'V54.89', '141.4', '144.9', '525.50', '525.10', '27.56', '25.59', '27.57', '815.03', '582.89', '425.3', '20.3', 'V58.81', '593.5', '307.1', '996.56', '599.60', 'V58.1', '786.07', '996.31', 'V17.41', 'E930.6', '621.0', '519.01', '38.68', '387.9', '013.00', '013.30', '891.2', '852.02', '80.86', '715.89', '806.06', '249.90', 'V03.82', '596.4', '852.11', '506.0', 'E942.4', '453.83', '35.96', '621.8', '535.11', 'V85.21', '552.29', '53.59', 'V15.5', 'V10.53', '556.0', '707.01', '60.3', 'E019.0', '89.38', '801.75', '806.21', '802.9', '872.69', '864.13', '839.00', '652.21', '644.21', '648.21', '648.31', '75.34', '590.2', '55.92', '349.2', '35.1', 'V54.81', '755.26', '764.92', '733.15', '46.81', '646.71', '669.11', '669.32', '642.52', '651.01', '656.51', '657.01', '649.31', '659.71', 'V27.2', '648.22', 'V91.03', '652.61', '66.69', 'V12.52', '256.39', '583.89', '31.44', '80.06', '174.9', '201.98', '375.55', '749.10', '97.88', '762.3', 'V49.71', '289.50', '779.7', '764.93', '269.0', '788.31', '292.82', '972.6', 'E858.3', '516.0', '784.59', '701.8', '85.6', '98.13', 'V01.79', '42.59', '806.8', '824.5', 'E848', '447.71', '34.3', '42.32', 'V09.81', '604.90', '82.0', '81.0', '716.15', 'V10.01', '770.4', '12.3', '300.21', '81.81', '478.22', '788.33', '864.12', '866.12', '996.40', '813.93', '718.40', 'E941.3', '381.4', '383.9', '202.83', '011.90', '321.0', '37.1', '304.81', '783.6', '552.8', '287.1', 'E901.8', 'E924.1', '991.3', '041.00', '519.11', '94.68', '799.59', 'E969', '249.81', '726.69', '922.2', '394.9', 'V58.63', '532.01', '34.59', '805.03', '826.0', '79.08', 'E930.3', 'E818.2', '715.95', '705.83', '110.0', '511.1', '303.03', '337.0', 'V55.5', '525.9', '787.21', '861.12', '901.41', '33.43', 'V45.69', '957.9', '802.20', '76.74', '76.78', '310.8', '783.5', '140.1', '27.42', '729.4', '838.09', '306.1', '521.08', '942.24', '426.53', '719.44', '508.0', 'E908.1', 'E941.1', '53.81', '996.89', '998.51', 'V54.82', '041.9', '320.1', '794.9', '45.71', '038.41', '917.2', '512.89', '156.8', '036.0', '242.01', '883.2', '874.5', '201.92', '40.22', '730.23', 'E870.5', '526.2', '34.6', '332.1', '972.9', '310.9', '333.82', '793.0', '426.2', '233.7', '552.20', '334.9', '433.80', '761.7', '35.99', '719.90', '794.01', '279.06', '588.0', '751.0', '543.9', '237.71', '813.52', '833.11', '816.00', '811.09', '85.9', '79.14', '664.11', '666.12', '648.52', '785.1', '648.92', '648.42', '73.6', '75.69', '801.65', 'E955.0', '45.03', '368.9', '730.26', '727.09', '715.00', '750.4', '774.1', '569.0', '46.93', '52.92', '923.03', '209.69', '38.88', '764.02', '204.12', '695.81', '707.02', '255.9', '610.1', '344.60', '788.65', '474.9', '892.0', '938', 'E943.8', '154.2', '48.5', '60.62', '971.1', 'E855.4', '304.31', 'E855.0', '955.1', 'E815.2', '863.0', '861.02', '305.41', 'V10.47', '44.61', '902.9', '35.31', '969.7', '802.21', '802.24', '806.01', 'E823.1', '379.50', '78.15', '51.10', '173.5', '781.6', 'V06.8', 'V03.81', '495.9', '723.6', '282.8', 'V12.42', '802.38', '571.3', '862.9', '861.31', '942.32', '376.33', '218.2', '729.30', '359.9', '461.8', 'E934.8', '288.04', '309.4', '22.11', '188.9', 'V44.51', '369.9', '982.8', '355.8', '824.0', '770.83', '255.2', 'V62.82', '34.73', '747.61', '603.9', '716.91', '60.95', '425.11', '728.3', '295.20', '686.9', '427.2', '473.8', '200.22', '518.1', '079.6', '78.68', '172.4', '999.3', '760.2', '967.9', 'E852.9', '825.1', '825.31', '825.34', '825.35', '79.37', '79.67', '79.38', '200.50', '483.8', '772.8', '39.53', 'E864.1', '255.42', '804.26', '918.1', '648.64', '648.84', '649.14', '275.1', '88.76', '861.22', 'E878.9', '516.36', '303.02', '919.0', '437.8', '327.21', '345.01', '282.40', '12.6', '12.7', '574.01', '772.2', '33.26', '282.2', '691.8', '041.2', '422.91', '480.9', 'V54.01', '81.8', '799.3', '753.21', '270.4', '958.0', 'E958.5', '813.22', '867.6', '814.01', '719.42', '863.43', '844.9', '569.71', '288.66', '386.10', '738.0', '598.00', '758.81', '756.19', '30.09', '507.8', '607.1', '998.4', '289.83', '111.0', '289.52', '488.01', '595.9', '707.06', '188.3', '441.1', '331.83', '759.9', 'V90.10', 'V15.89', '555.0', '747.63', '692.4', '53.62', '482.89', '438.84', '172.5', '730.22', '727.41', '934.0', '969.05', 'E854.0', 'V59.6', '484.6', '99.79', '742.9', '146.8', '141.0', '493.21', '880.13', '308.0', '813.32', '833.02', '804.70', '851.09', '873.59', '79.73', '93.53', '801.72', '801.62', '892.1', '950.9', '68.39', '839.08', '581.1', '719.49', '320.2', '198.6', '59.02', '590.9', '281.2', '997.62', '718.46', '320.3', '584.6', 'E862.4', 'V54.11', '158.8', '649.43', '345.11', '649.03', '646.53', '649.13', '444.9', '824.6', '79.03', '574.81', '309.9', '35.32', '35.05', '444.09', '250.03', '84.08', '85.47', '38.83', '413.1', '709.09', '333.84', '275.40', '724.01', '84.12', '265.0', '357.4', '265.2', '191.0', '279.51', '865.14', '445.02', '969.01', '305.80', 'V15.05', 'V85.34', '88.38', '244.3', '874.02', '093.1', '54.93', '473.0', '12.0', '99.11', '998.3', '459.10', '337.21', '801.16', '695.1', 'E944.5', '730.01', '300.22', '150.3', '054.72', '786.9', '916.0', '377.75', 'E913.2', '987.9', '18.21', '29.39', '38.62', '812.31', '812.54', '84.71', 'E919.2', 'E818.1', '582.1', '767.8', '174.4', 'V15.42', '620.5', '46.82', '97.56', 'V02.61', '88.26', '478.34', '345.70', 'E850.0', '715.34', '686.01', '74.4', 'V63.2', '99.95', '804.25', 'E813.0', '607.82', '999.82', '198.0', 'E003.9', '316', '279.4', '386.11', '054.2', '372.40', '360.01', '379.00', '376.32', '370.05', '16.49', '46.72', '389.08', '694.8', '745.10', '729.82', '441.00', '176.5', '115.19', '634.01', '69.02', '674.04', 'V29.1', '51.51', '903.8', '255.8', '38.94', '368.44', '600.10', '60.11', '729.2', '791.3', '057.9', 'E000.9', '724.03', '721.42', '379.90', '171.0', '173.8', '83.49', '76.39', '195.0', '780.96', '999.84', '150.4', '76.11', '618.3', '453.6', 'V02.0', '623.5', '385.89', '909.3', 'E870.4', '996.70', '41.39', '372.14', '286.2', '437.1', 'V62.6', '434.00', '754.79', '33.34', '794.4', '438.30', '438.40', '378.51', '745.61', '751.4', '96.09', '253.7', '151.8', '618.1', '96.01', '57.92', '362.81', '98.14', 'E885.2', '369.01', '55.04', '87.75', 'E821.0', '40.64', '44.62', '130.0', '762.6', '333.90', 'E917.7', '536.41', '369.8', '39.55', '16.0', '81.07', '364.3', '863.99', 'E813.2', '81.95', '97.85', '998.30', '255.10', '707.00', '989.4', 'E950.6', '386.30', '599.4', '533.40', '524.60', '438.81', '760.8', '49.2', '86.96', '642.64', 'V03.7', '078.11', 'E920.3', '478.33', '436', '277.87', '359.21', 'V02.9', '199.0', '12.8', '213.0', '738.5', '788.99', '803.60', '22.79', '85.34', '85.89', 'E965.0', '860.1', 'E965.1', '535.21', '708.0', '35.62', '723.5', '287.32', '435.8', '787.60', '209.57', '885.0', 'E919.4', '84.21', '99.99', '312.9', '304.90', '756.0', '097.0', '272.6', '698.1', '727.51', '345.81', '728.2', '743.43', '46.76', '88.66', '682.8', '627.0', '718.87', '80.87', '339.02', '996.84', '820.20', '68.12', '823.10', '79.26', '237.3', '44.12', '448.9', '36.2', '51.63', '78.02', '443.29', 'V46.1', '37.92', '24.3', '38.02', '225.4', '122.8', '722.83', 'E883.0', '952.06', 'V42.1', '756.51', '304.60', '599.84', '788.8', '302.50', '799.1', '788.37', '17.', '275.01', '464.31', '87.69', '530.87', '564.3', '737.41', '21.72', '642.61', '647.81', '654.21', '648.41', '958.93', '39.66', '447.2', '38.66', '44.93', '97.01', '77.82', '84.55', '571.49', '200.40', '728.0', '756.71', '195.8', '142.0', 'E944.3', 'E870.3', 'V15.04', '84.14', '684', 'E920.8', '171.6', '70.24', '209.43', '868.19', '29.5', 'E881.1', '529.0', '642.41', '659.61', '663.31', '376.01', '27.92', 'E884.1', '923.11', '070.22', '903.9', '446.0', '84.05', '151.1', '723.8', '23.1', 'E941.2', '617.9', '788.43', '682.0', '27.0', '20.4', '76.73', '32.0', 'V15.85', '779.8', '370.34', '755.02', '617.0', '617.3', '617.1', '596.89', '493.00', '68.25', '214.3', '44.66', '191.7', '709.9', '76.93', '800.10', '996.78', '877.0', '333.72', '908.9', 'E989', '594.1', '608.9', '153.2', '170.0', '289.8', '904.0', '814.04', '814.08', '959.4', '079.98', '78.14', 'E935.4', '379.91', '854.02', '378.87', 'V43.1', '55.01', '733.45', '018.03', '784.61', '911.6', '71.6', '574.91', '85.1', '38.63', '202.52', '376.30', '16.09', '952.9', '863.55', '808.3', '682.5', '879.7', '879.5', '878.7', '878.5', '625.8', '70.71', '71.71', '49.71', '87.44', '493.02', '474.12', '719.43', '37.65', '763.89', '793.5', '442.1', '972.1', '974.4', 'E858.5', '614.2', '147.9', '802.22', '900.89', '884.0', '76.99', '21.0', '528.2', '451.9', '271.8', '51.79', '32.24', '996.75', '388.30', '28.11', '466.11', '354.8', '759.82', '448.1', '787.99', '225.1', '40.1', '882.1', '335.23', '260', '764.95', '38.21', '555.2', '354.3', '478.32', '362.13', 'V13.89', '761.5', '304.03', 'V17.5', 'V16.2', '753.6', '62.99', '49.39', '63.09', '783.40', '712.30', '344.61', '951.4', 'E965.4', '873.74', '308.3', '478.25', '161.1', '902.25', '958.5', '863.49', '863.81', '902.33', '433.01', '96.36', '211.5', '996.03', '850.4', '736.89', '320.0', '473.1', '22.41', '164.0', '556.4', '391.1', 'E980.1', 'E852.8', '702.0', '250.93', '273.4', '338.21', '533.70', '996.63', '455.4', '039.2', '615.1', '464.51', '553.29', '694.4', '343.4', 'E931.5', '845.12', '968.4', '968.5', '472.0', 'V54.16', '647.61', 'V27.1', '73.59', '301.13', '760.70', '753.14', '611.8', '733.3', '97.38', '334.8', '117.7', '531.30', '482.49', '16.51', '200.70', '42.24', '151.2', '035', '078.10', 'V54.17', '952.04', '813.13', '998.33', '746.00', '752.69', '983.1', '751.7', '52.4', '335.10', '86.21', '383.1', '32.9', '56.41', 'E906.3', '529.3', '795.51', '455.9', '863.39', '863.53', '924.01', '67.39', '202.40', 'V12.03', '366.41', '518.53', '236.91', '217', '562.02', '295.74', '278.02', '376.11', '376.12', '041.03', '767.3', '96.49', '970.1', 'V53.39', '996.57', '435.0', '245.9', '44.9', '670.04', '665.34', '654.04', '666.34', '56.42', '887.2', '44.92', '806.29', '336.9', '626.9', '426.54', '453.75', '728.9', '528.5', '350.9', '22.62', '833.01', '958.8', '344.2', '342.01', '692.82', 'E934.3', '37.89', '77.66', '442.82', '362.51', '730.16', '44.01', '55.21', 'E922.5', '376.89', '304.93', 'E917.4', 'E924.8', '373.11', '708.8', 'V14.6', '203.12', '079.89', '389.8', '54.95', 'V02.3', '461.1', '88.04', '009.2', '780.8', '766.0', '909.4', '972.0', 'V16.52', '156.9', '793.99', '482.30', '484.7', '942.09', '297.8', '345.91', '77.42', '77.62', '78.62', '63.3', 'E938.9', 'E938.5', '999.41', '346.20', '49.95', '764.94', '203.10', '298.4', '32.41', '32.3', '841.1', '835.01', '79.64', '959.9', '429.6', '396.1', '45.33', '473.2', '471.8', '471.0', '53.72', '952.07', '719.58', '852.03', '388.42', '50.23', '50.69', '901.1', '854.01', '825.29', '825.24', '843.8', '78.12', '845.09', '81.47', '12.2', '851.42', '866.01', '120.8', '823.01', 'E917.8', '762.2', '747.29', '202.03', '995.83', 'E967.7', 'V62.89', '94.49', '54.92', '51.04', '552.9', '618.04', '70.52', '70.8', '865.04', 'V03.89', '992.0', 'E900.0', '764.96', '755.29', '755.59', '344.04', '434.10', '909.5', '56.74', '239.6', '762.5', '799.53', '172.6', '713.1', '45.92', '094.9', '404.92', '754.32', '115.99', '216.3', '425.18', '44.91', '44.99', '42.91', 'V10.84', '999.1', '97.62', '97.61', 'E934.5', '362.89', '296.32', '446.21', 'V45.87', 'V02.53', 'E945.1', '45.12', '292.89', '598.8', '414.05', '173.4', '023.9', '42.84', '33.42', '343.8', '341.20', '727.3', '752.49', '96.22', '998.9', '803.22', '524.69', '789.39', 'V05.2', 'V09.50', '800.24', '801.24', '747.82', 'V64.43', '084.6', '960.5', 'E858.2', 'E856', '914.9', '882.2', '927.20', '927.21', '86.71', '86.61', 'V86.1', '320.82', '756.83', '202.85', '18.11', '763.3', '404.01', '180.9', '529.6', '48.32', '727.82', 'E927', '273.9', '789.03', '200.10', '070.41', 'E958.9', '790.22', '750.29', '750.19', '863.1', '770.3', 'E013.9', '288.01', '837.0', '81.46', '79.87', '590.00', '136.1', '852.29', '161.0', '307.81', '323.81', 'E858.1', '379.99', '801.35', '851.00', '522.6', '81.34', '81.32', '253.0', '753.17', '41.01', '359.71', '575.6', '92.39', '348.2', '355.3', '819.0', '924.8', '780.51', 'V15.09', '362.31', '786.04', '742.0', '534.01', '379.56', 'E910.2', '81.37', '583.2', '881.22', '815.13', '79.63', '041.83', '200.00', '81.28', '99.02', '751.3', '919.6', '147.1', '864.09', '512.84', '793.19', '789.60', '144.8', '27.24', '719.01', '759.3', '99.39', '052.9', 'V30.1', '745.69', '433.81', '438.85', '569.44', 'V69.8', '17.35', 'E819.9', '854.04', '957.8', '30.3', '872.00', '806.26', '790.2', '803.01', '201.52', '35.93', '523.8', '531.11', '763.5', '202.06', '712.39', '410.42', '812.49', '516.3', '962.7', '250.21', '241.9', 'E927.8', '78.66', 'V85.25', '388.61', '82.44', '84.01', '235.3', '004.1', '464.30', '464.50', '995.29', '786.02', '872.61', '764.09', '312.89', 'V15.29', '306.2', '171.4', '012.15', '939.2', '832.09', '79.72', '97.12', '98.27', '761.8', '341.0', '788.34', '011.93', '770.87', '42.11', 'E930.7', '594.9', '38.67', '52.9', '775.8', '706.2', 'E871.0', '44.22', '192.2', '204.11', '25.02', '233.0', '85.84', '85.85', 'E854.2', 'E855.1', '88.71', '813.54', '89.50', '532.50', '347.10', '53.10', '53.43', '94.2', '112.83', '363.62', '44.03', '40.19', '243', '565.1', '40.21', 'V70.3', '33.73', '477.2', 'E944.7', '959.19', '634.12', '903.5', '903.2', '955.3', '86.73', '280.8', '721.2', '971.0', '722.72', '233.1', '55.02', '67.12', '44.19', '278.1', '801.15', 'E874.2', '588.8', '565.0', '842.00', '438.10', '536.2', '900.82', '68.16', 'V16.42', 'nan', '378.53', '746.1', '966.1', '286.1', '327.27', '194.3', '352.4', '389.18', '81.49', '80.47', 'V64.0', '44.68', '531.91', '743.53', 'V07.8', '552.00', '53.29', '315.8', '550.10', '53.05', '415.13', '803.32', '096', '42.65', '77.31', '746.01', '753.15', '192.1', '331.19', '581.81', '52.96', '058.29', '053.14', '368.12', '646.21', '656.41', '582.2', '763.84', '719.66', '618.0', '70.50', '59.79', 'V10.88', '729.91', '846.1', '83.88', '164.8', '37.95', '150.0', '873.41', '46.79', '753.19', 'V15.86', '429.81', '717.6', '83.19', '806.08', '722.4', '902.89', '525.63', '601.8', '616.2', '71.23', '748.5', '754.89', '556.2', 'E940.1', '816.12', '955.7', '927.3', '82.01', '203.01', '831.04', '55.39', 'E880.1', '395.1', '379.23', '474.11', '28.7', '28.2', '786.01', '22.2', '532.41', '780.55', '746.3', '97.41', '52.0', '800.26', '410.02', '422.93', '427.9', '21.86', '45.34', '801.09', '351.9', '37.68', '37.79', '808.53', 'E825.7', '928.01', '236.2', '985.8', '78.56', 'V16.9', '736.81', '097.9', '995.7', '793.7', '971.3', '969.1', '337.22', '642.54', '642.14', '813.81', '568.82', '37.11', 'V15.01', '523.9', '388.5', '389.15', '386.12', 'V42.84', '727.03', '42.7', '44.11', '286.5', '51.59', '782.2', '237.5', '65.29', '800.06', '13.2', '079.0', '719.40', '21.02', '97.32', '564.0', '136.9', '47.9', '16.31', '99.22', '68.23', '164.3', '648.63', '673.33', '644.03', '648.43', '96.54', '164.2', 'V15.06', '502', '831.14', '80.81', '861.03', '86.72', '429.2', '795.00', '542', '711.09', '365.10', '989.89', '627.4', 'V07.4', 'E861.9', '516.33', '803.50', '800.00', '189.8', '15.', '208.90', 'V10.20', '786.51', 'E825.0', 'V10.29', '036.2', '629.89', '149.8', '803.25', '345.00', '368.15', '801.80', '823.20', '800.80', '376.52', 'E883.9', '790.1', '43.42', '466.19', 'V06.3', '733.49', '288.1', '279.49', '726.65', '380.4', '53.84', '804.66', '812.50', '706.1', '625.3', '96.53', '443.1', 'V58.41', '21.83', '327.20', '813.21', '304.91', '93.52', '33.41', '96.70', '10.1', '315.31', '666.32', '641.21', '674.32', '69.49', 'V45.74', '752.63', 'V10.69', 'V58.3', '446.7', '443.23', '377.30', '491.8', '53.04', '304.73', '736.72', '41.91', '77.47', '77.87', '378.9', '160.2', '526.4', '753.8', '702.8', '81.55', '618.82', '294.0', '34.71', '79.29', '521.81', '79.04', '84.18', '513.1', '345.2', '205.11', 'V10.91', '86.02', '38.42', '98.51', '274.03', '51.83', '38.48', '744.41', '744.01', '744.23', '355.2', '87.72', 'V62.85', '194.0', '34.27', '770.12', '596.6', '941.08', '88.77', '801.30', '807.18', '951.5', '800.23', '868.10', '176.0', '464.00', '918.0', '727.62', '33.99', '77.48', '235.7', '37.2', '404.03', '88.03', '999.5', 'V62.0', '78.48', '83.11', 'V85.45', '054.71', '903.3', '86.7', '44.02', '726.79', '80.17', '049.9', '270.6', '908.6', '757.39', '454.8', '31.3', '593.1', '969.72', '971.2', 'E855.5', '533.00', '077.99', '202.60', '42.51', '813.18', '800.75', '77.6', '83.43', '779.9', '482.31', '045.90', '20.09', '531.41', 'E910.8', '296.99', '442.0', 'V65.5', '909.0', 'E929.2', '51.24', '85.31', '45.00', '808.51', '88.4', '879.4', '755.13', '736.6', '80.0', '573.1', '63.9', '575.2', '813.23', '77.85', '48.9', '284.12', '714.2', '99.78', '209.61', '45.21', '807.3', '807.10', 'E970', '734', '759.0', '493.81', '834.02', 'E866.8', '902.41', '51.62', 'V44.8', '540.1', '324.9', '968.3', '969.79', '959.7', '354.2', '97.59', '96.7', '451.0', '88.92', '318.0', '296.00', '309.89', '82.36', '77.64', '930.8', '98.21', '211.8', '173.9', '957.0', '76.69', '223.0', '56.91', 'V10.22', 'E920.4', '754.53', '99.41', '777.9', '349.89', '905.5', '249.60', '176.4', '363.20', '755.55', '521.9', '881.12', '955.2', '788.38', '524.10', '617.5', '532.70', '53.11', 'V10.49', '729.99', '784.49', '878.2', '879.6', '706.8', '821.30', '873.52', '713.2', '764.99', '517.2', 'E943.3', '763.82', '532.61', '38.57', '558.41', '759.81', '853.10', '16.82', '88.9', '31.93', '635.02', '204.01', '996.42', '73.0', 'V13.09', '802.27', '887.5', '854.05', '812.19', '880.23', '903.1', '904.41', '955.8', '956.3', '38.89', '81.33', '52.13', '77.41', '68.6', '796.0', '93.91', '084.0', '599.3', '304.80', '963.5', '315.4', '315.39', '209.17', '737.12', '48.75', '539.89', '211.9', '207.80', '158.9', '864.00', '805.3', '805.5', '603.8', '803.21', '359.22', '558.1', '322.2', '784.1', '296.04', '239.5', '357.3', '790.09', '33.79', '768.3', '946.2', '948.40', '755.67', '81.12', '453.50', '88.63', '805.00', '520.6', '524.4', '188.5', '813.03', '79.11', '79.42', '68.69', '437.7', 'V54.26', '747.21', '12.', '011.86', '573.5', '77.11', '792.0', '564.01', '89.44', '377.39', '46.4', '712.38', '86.95', '253.8', '76.3', '648.03', 'V61.8', '695.14', '789.47', '80.12', 'E934.4', '523.30', '55.24', '38.46', '338.28', '825.39', '730.06', '904.42', '904.51', '80.41', '80.71', '902.21', '767.6', '763.1', '807.5', 'E953.8', '31.64', '775.89', '41.03', '45.41', '402.10', '771.2', 'V45.09', '30.29', '62.41', '802.23', '81.83', '482.39', '362.83', '395.2', '922.32', '39.23', '995.64', '753.23', '800.34', '726.5', '251.5', '369.70', '297.9', '011.94', '365.22', '112.81', '747.49', '35.7', 'V87.45', '704.1', '718.31', 'V85.22', '804.75', '804.85', '289.3', '753.9', '642.31', '75.52', '163.9', '307.49', '269.2', 'E819.7', '50.4', '91.0', '29.9', '728.79', '372.39', '29.32', '714.9', '812.51', '77.33', '146.0', '79.12', '801.50', '802.7', '802.34', '99.45', '18.09', '375.15', '366.16', 'V43.63', '875.1', '847.1', '745.12', '17.42', '776.2', '377.01', '704.09', 'V04.0', 'V06.1', '38.69', 'V16.49', '176.9', '277.8', '89.65', '38.05', 'E901.9', '289.4', '079.4', '277.6', '053.11', '380.03', '96.23', '170.7', '78.47', '78.07', '80.49', '669.14', '670.14', '38.8', '83.94', '300.16', '648.81', '76.0', 'V69.4', '800.20', '146.7', '26.30', '367.1', '778.9', '800.01', '793.6', '74.0', 'V16.51', '270.0', '176.8', '004.8', '68.3', '305.52', '445.81', 'E957.0', '35.5', '35.28', '429.1', '36.09', '715.94', '115.90', '692.3', '904.7', '388.8', '737.34', '295.22', '821.31', '236.7', '17.33', '526.89', '27.31', '27.55', '551.00', '53.21', '22.52', '211.6', '290.10', '187.4', '64.3', '58.0', '375.9', '453.76', 'E003.1', '576.3', '793.4', '438.31', 'V88.11', '97.39', '441.9', '33.71', '532.51', '862.39', '143.1', '813.33', '814.19', '817.1', '927.10', '955.6', '82.29', '86.62', '516.31', '237.0', '76.5', '52.83', '237.1', '861.13', '174.3', 'V50.41', '85.42', '85.54', '952.03', '86.1', '15.7', '802.35', '524.89', 'E960.1', 'E967.9', '57.93', '852.24', 'E861.3', '75.0', '287.9', '323.6', 'V10.12', '823.80', 'E918', '235.5', '553.00', '039.1', '453.77', '250.32', '38.38', '959.14', '269.9', 'E824.1', '78.03', '463', '806.24', '011.23', 'E850.3', '238.73', '762.8', '207.22', '686.09', '741.03', '389.7', '658.01', '672.02', '582.4', '924.20', '756.17', '339.12', 'E823.8', '800.61', '801.61', '508.2', 'E890.8', 'E890.2', '753.5', '626.1', '200.42', '719.11', '80.11', '80.14', '790.95', '806.22', '282.7', '906.4', '31.92', '89.69', '879.2', '87.09', '378.50', '305.71', '804.00', 'V43.4', '85.74', '58.31', '334.2', '746.81', '683', '901.81', '673.24', 'V32.00', '567.0', '97.82', '245.4', '003.8', '362.11', '221.8', '65.11', '902.22', '811.01', '79.89', '803.20', '714.89', '803.15', '866.03', '031.9', '904.53', '482.32', 'E884.0', '212.3', '518.7', 'E934.7', '201.58', '447.8', '851.05', '344.30', '258.9', '969.5', '80.98', '771.89', '902.23', '141.9', '756.13', '353.0', '569.2', '45.81', '79.46', '200.24', '922.4', '712.96', '922.0', '816.02', '789.33', '84.0', '80.36', '531.50', '625.70', '239.1', '097.1', '39.4', '86.06', '758.39', '69.5', '253.1', 'E891.8', '83.61', '93.16', '31.69', '148.1', '950.0', 'E976', 'E975', '718.91', '533.41', '310.1', '293.83', '16.63', '905.6', '963.1', '897.2', '808.9', '79.27', 'V49.60', '697.0', '368.00', '737.32', '550.91', '873.65', '215.4', 'V06.5', '333.4', '537.1', '80.46', '874.9', 'E922.0', '208.00', '361.06', '839.01', '756.89', '803.16', '721.7', '79.18', '375.56', '802.30', '99.76', '343.1', '594.0', '673.23', '643.03', '377.51', '258.01', '82.45', '718.55', '320.7', '865.12', '59.09', '727.42', '995.3', '160.9', '16.', '21.69', '735.9', '552.02', '53.31', '008.04', '438.6', '157.4', '304.61', '151.5', '755.21', '727.89', '83.5', '995.89', '373.13', '86.86', '130.9', '784.41', 'E006.9', '231.2', '031.8', '341.1', '642.92', '654.41', '646.82', '92.32', '804.41', '801.41', '277.00', '820.02', '632', '646.23', '724.6', '114.9', '99.00', '451.11', 'V53.99', '84.04', '84.02', '952.3', 'E820.0', '242.91', '389.12', '461.3', '55.0', '323.41', '804.32', '95.25', '480.2', '225.3', '733.41', '272.5', 'E812.6', '99.57', '141.8', '25.3', '29.59', '374.10', '743.61', '70.12', '346.00', '214.1', '97.52', '362.53', '52.99', '372.9', '604.99', '750.0', '750.26', '767.2', '25.92', '26.21', '162.0', '666.04', '747.69', '50.24', '333.7', 'E939.1', '55.86', '55.12', '879.0', '872.8', '85.81', 'E942.5', '43.3', '747.22', '603.1', 'V49.81', '799.55', '45.9', '30.4', '523.33', 'E879.5', '216.6', '902.29', '77.09', '551.29', '906.8', '60.12', '46.94', '995.67', '93.35', '622.10', '865.10', '905.1', '95.03', 'E811.0', '525.3', '37.85', '40.69', '89.22', '681.00', 'E917.3', '448.0', '534.30', '879.8', '137.0', '550.11', '173.2', '18.29', '375.01', '370.00', '374.89', '802.25', '40.9', '163.0', '293.89', '839.04', 'E855.6', '735.8', '50.51', '159.8', '988.1', 'E865.5', '368.13', '803.72', '049.8', '277.1', '900.1', '901.3', '600.11', '53.14', '595.89', '206.00', 'V31.1', '337.29', '767.1', '58.22', '447.72', '246.8', '256.1', '628.9', 'E932.4', '733.29', '534.00', 'V49.61', 'E871.7', '83.0', 'V88.21', '31.95', '39.28', 'V18.8', '51.', '880.01', '754.33', '602.1', '60.94', '277.09', '277.02', '427.42', '927.01', '811.10', '296.44', '352.6', '953.1', '754.0', '762.4', '81.38', '49.31', '863.42', '127.2', '359.0', '743.62', '758.89', '534.41', '775.3', '249.80', '904.1', '355.71', '35.41', '200.02', '52.51', 'V02.52', '745.9', '729.90', '88.97', '873.73', '426.50', '764.03', '84.73', 'E000.8', '388.72', '748.69', 'V18.2', '788.64', 'V15.53', '31.45', '94.27', '58.41', '564.2', '695.2', '711.08', '730.05', '80.89', '383.02', '383.21', '381.00', '20.41', '20.01', '696.2', '722.90', '682.9', 'E938.6', '373.2', '379.42', '39.93', '733.16', '841.8', 'E885.1', '171.8', '110.8', '641.01', '670.12', '75.8', '348.81', '735.5', 'V42.89', '596.55', '454.2', '070.0', '999.6', 'V10.61', 'V16.41', '371.40', '374.20', '85.2', '53.03', '607.89', '46.43', '958.1', '808.1', '232.9', '71.4', '718.65', '864.14', '77.71', '726.12', '83.13', '85.36', '851.90', 'E985.0', '801.82', 'E831.8', '190.6', '883.1', '132.9', '053.12', '57.34', '57.87', '851.89', 'E932.5', '995.2', '626.4', '23.3', '374.43', '758.7', '799.23', '572.1', '172.0', 'E876.7', '34.72', '282.9', '259.8', '359.5', '98.26', '118', '214.2', '289.1', 'E851', '405.11', '730.88', '015.04', '99.84', '776.3', '453.79', '77.95', '83.75', '959.09', '378.55', '863.30', 'V40.0', '999.71', '309.1', '009.3', '836.51', '79.76', '81.45', '945.32', '52.8', '44.97', '365.44', '495.8', '51.64', '26.99', '716.93', '077.8', '82.19', '957.1', '389.22', '601.2', '60.0', '60.91', '512.2', '948.50', '943.25', '945.19', '928.20', 'E800.2', '812.43', '571.9', '941.28', '941.27', '41.43', '88.40', '51.43', '54.29', '45.63', '709.00', 'V04.89', 'V17.0', '530.9', '22.9', '839.21', '648.04', '216.9', '347.01', '996.68', 'E805.8', '736.70', '94.63', '89.60', '756.9', '839.07', '484.8', '535.31', '160.8', '21.32', '333.92', '823.90', '826.1', '79.68', '186.9', '78.61', '996.77', '137.3', '77.75', '161.2', '852.42', '783.3', '649.33', '642.93', '735.0', '81.14', '77.59', '77.58', '87.73', '453.74', '453.71', '308.2', '854.03', '553.9', '951.8', '715.09', '84.59', '76.77', '27.61', '27.52', 'E884.5', '672.04', '372.75', '027.9', '995.86', '005.81', '003.0', '943.32', '942.34', '870.2', '997.32', '784.91', '85.44', '759.83', '346.91', 'E814.6', '125.1', '794.02', '975.3', '863.93', '863.52', '806.39', '839.61', '839.42', '14.41']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tls_y.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf90dd89",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6594"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tls_y.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3cde10",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are 3 ways of decoding this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc86bd81",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#25) ['276.7','585.6','348.39','790.7','427.32','507.0','403.10','825.0','E888.9','300.9'...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tls_y.decode(a_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53981b11",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276.7;585.6;348.39;790.7;427.32;507.0;403.10;825.0;E888.9;300.9;301.9;250.62;357.2;250.42;285.21;278.01;427.31;250.82;V15.81;276.52;707.07;707.22;041.19;39.95;38.93\n"
     ]
    }
   ],
   "source": [
    "show_at(tls_y.train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03700c75",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#25) ['276.7','585.6','348.39','790.7','427.32','507.0','403.10','825.0','E888.9','300.9'...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tls_y.vocab[torch.where(a_label == 1)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4127d6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 3. Making the `Datasets` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d478a37e",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_tfms = [Tokenizer.from_df('text'), attrgetter(\"text\"), Numericalize(vocab=lm_vocab)]\n",
    "y_tfms = [ColReader('labels', label_delim=';'), MultiCategorize(vocab=lbls), OneHotEncode()]\n",
    "tfms = [x_tfms, y_tfms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9388164b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsets = Datasets(df, tfms, splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b18b3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's now check if our `Datasets` got created alright:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e01a3676",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14839, 979)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsets.train), len(dsets.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "361970b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorText([ 2,  8, 72,  ...,  9,  9, 15]),\n",
       " TensorMultiCategory([1., 1., 1.,  ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2fdf398",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"xxbos xxmaj admission xxmaj date : [ * * 2179 - 3 - 7 * * ] xxmaj discharge xxmaj date : [ * * 2179 - 3 - 18 * * ] \\n\\n xxmaj date of xxmaj birth : [ * * 2121 - 12 - 23 * * ] xxmaj sex : m \\n\\n xxmaj service : xxup medicine \\n\\n xxmaj allergies : \\n xxmaj ibuprofen \\n\\n attending:[**first xxmaj name3 ( lf ) 613 * * ] \\n xxmaj chief xxmaj complaint : \\n dyspnea , hyperkalemia \\n\\n xxmaj major xxmaj surgical or xxmaj invasive xxmaj procedure : \\n xxmaj hemodialysis \\n right xxmaj femoral central venous line placement and removal \\n\\n\\n xxmaj history of xxmaj present xxmaj illness : \\n 57 y / o m with hx of xxup esrd presents after intentionally missing \\n dialysis for last 9 days . xxmaj came to the xxup ed due to the coaxing of \\n his wife . xxmaj complains of xxup sob and xxup doe lasting about the last five \\n days . xxmaj also has cough with clear sputum production . xxmaj also \\n complains of bilateral pedal edema , xxup r > l , starting around the \\n time xxup sob started . xxmaj no fevers , chills . xxmaj no xxup cp , palpitations . \\n xxmaj denies dizziness , fainting , falls . xxmaj says he stopped going to \\n dialysis for no particular reason , although per xxup ed reports after \\n talking with his wife , it is possible he had passive xxup si . xxmaj no \\n other complaints except for mild nausea . \\n . \\n xxmaj in the xxup ed , his vitals were t 98.0 , xxup bp 130 / 87 , xxup hr 92 , r 22 , 99 % \\n on xxup nrb weaned to room air over course of xxup ed stay . xxmaj he was noted \\n to be hyperkalemic to 8.1 . xxmaj there were no xxup ekg changes . xxmaj he was \\n treated with xxmaj ca , insulin / dextrose , and bicarb . xxmaj he was given \\n kayexcelate but did not have a xxup bm by time of arrival to the \\n floor . xxmaj he was also found to have a xxup rll pneumonia and was \\n treated with azithromycin and ceftriaxone . a l femoral line was \\n placed for access . xxmaj renal team was consulted . \\n . \\n xxmaj on the floor , the patient was feeling well . xxmaj had no complaints . \\n xxmaj no dizziness , nausea , strange taste in mouth , abdominal pain . \\n xxmaj no chest pain , palpitations . xxmaj shortness of breath had resolved . \\n xxmaj he is confused and a poor historian . \\n\\n xxmaj past xxmaj medical xxmaj history : \\n - xxup esrd on xxup hd ( tthsa ) . xxup av fistula in the right arm with \\n complications of clot and thrombectomy last in [ * * 2177 * * ] . xxmaj now with xxup hd \\n\\n line in place . xxmaj undergoing transplant eval with xxmaj dr . [ * * last xxmaj name ( stitle ) * * ] , not \\n yet listed . \\n - xxup htn \\n - xxup dm \\n - xxup cad s / p xxup mi in [ * * 2164 * * ] \\n - a xxmaj fib / xxmaj flutter s / p ablation in [ * * 2173 * * ] \\n - xxmaj morbid obesity \\n - xxmaj sigmoid diverticulosis \\n - hx of entercoccus bacteremia associated with line infection \\n - personality disorder \\n\\n\\n xxmaj social xxmaj history : \\n xxmaj pt lives at home with wife and 2 sons . [ * * name ( ni ) 1403 * * ] part time [ * * street xxmaj address(1 ) xxunk * * ] xxmaj bank . 50pack yr h / o tobacco use , quit in [ * * 2160 * * ] . xxmaj very \\n distant marijuana use , no other drugs , no etoh . \\n\\n\\n xxmaj family xxmaj history : \\n noncontributory \\n\\n\\n xxmaj physical xxmaj exam : \\n xxmaj vitals : t afebrile , p 105 , xxup bp 167 / 86 , r 20 , 97 % on xxup ra \\n xxmaj gen : obese man , resting comfortably , xxup nad , a+ox2 although \\n rambling and not making sense during prolonged interactions \\n xxup heent - xxup atnc , xxup perrla , xxup eomi , moist mucous membranes , xxup jvd \\n difficult to assess secondary to size \\n xxup cv - distant xxup hs , xxrep 3 r , no m , r , g \\n xxmaj lungs - decreased at bases , otherwise xxup cta , no crackles , wheezes \\n xxmaj abd - obese , soft , xxup nt , xxup nd , normoactive bowel sounds \\n xxmaj ext - 2 + pedal edema on xxup r , 1 + on xxup l ; palp pulses , r foot bandaged \\n due to heel ulcer , neither leg tender to palpation \\n xxmaj neuro - xxup cn intact , strength 5 / 5 , + asterixis , not cooperating \\n fully with neuro exam \\n\\n xxmaj pertinent xxmaj results : \\n [ * * 2179 - 3 - 7 * * ] 07:30pm xxup glucose-112 * xxup urea xxup xxunk * xxup xxunk * # \\n xxup sodium-139 xxup potassium-8.1 * xxup chloride-99 xxup total xxup co2 - 19 * xxup anion \\n xxup gap-29 * \\n [ * * 2179 - 3 - 7 * * ] 07:30pm estgfr - using this \\n [ * * 2179 - 3 - 7 * * ] 07:30pm xxup asa - neg xxup ethanol - neg xxup acetmnphn - neg \\n bnzodzpn - neg barbitrt - neg tricyclic - neg \\n [ * * 2179 - 3 - 7 * * ] 07:30pm xxup wbc-11.2 * # xxup rbc-3.73 * xxup hgb-10.7 * xxup hct-32.8 * \\n xxup mcv-88 xxup mch-28.6 xxup mchc-32.5 xxup rdw-15.7 * \\n [ * * 2179 - 3 - 7 * * ] 07:30pm xxup neuts-80.0 * xxup lymphs-10.0 * xxup monos-7.1 xxup eos-2.5 \\n xxup basos-0.4 \\n [ * * 2179 - 3 - 7 * * ] 07:30pm xxup plt xxup count-251 \\n [ * * 2179 - 3 - 7 * * ] 07:30pm xxup pt-14.1 * xxup ptt-37.5 * xxup inr(pt)-1.2 * \\n\\n [ * * 3 - 7 * * ] xxup cxr : \\n xxmaj infiltrate at the right lung base likely indicating infection . \\n xxmaj please ensure followup to clearance . \\n\\n [ * * 3 - 8 * * ] r xxmaj heel xxmaj xray : \\n xxmaj two radiographs of the right heel demonstrate a displaced and \\n angulated \\n fracture involving the posterior calcaneal body and the \\n calcaneal xxunk . \\n xxmaj the superior fracture fragment is displaced approximately 3 cm . \\n xxmaj mild to \\n moderate degenerative change about the osseous structures of the \\n mid foot is noted . xxmaj no discrete soft tissue loss is appreciated . \\n xxmaj no subcutaneous \\n emphysema is seen . xxmaj there is a plantar calcaneal spur . \\n\\n xxup impression : \\n xxmaj displaced calcaneal fracture . \\n\\n [ * * 3 - 10 * * ] : abis \\n xxup right xxup leg : xxmaj there is triphasic flow pattern on the femoral , \\n popliteal and \\n posterior tibial arteries and monophasic flow pattern on the \\n dorsalis pedis \\n artery . xxmaj the segmental limb pressures are mildly reduced on the \\n calf and over \\n xxup dp . xxmaj the ankle brachial index at rest 0.95 . \\n\\n xxup left xxup leg : xxmaj there is triphasic flow pattern on the femoral , \\n popliteal , \\n posterior tibial and dorsalis pedis arteries . xxmaj the segmental limb \\n pressures \\n are unremarkable at all levels . xxmaj the ankle brachial index at rest \\n 1.18 . \\n\\n xxmaj the patient was not exercised . \\n\\n xxup impression : xxmaj mild right tibial distal disease at rest and no \\n evidence of \\n peripheral vascular disease on the left leg . \\n\\n [ * * 3 - 10 * * ] : \\n xxup findings : xxmaj the right common femoral , superficial femoral , and \\n popliteal veins show no evidence of deep vein thrombosis . xxmaj the \\n patient declined examination of the left groin , so the left \\n common femoral vein was not assessed . xxmaj however the left \\n superficial and popliteal veins appear entirely normal . \\n\\n xxup impression : xxmaj no evidence of deep vein thrombosis noting that the \\n patient \\n declined examination of the left groin by the radiologist . \\n\\n xxmaj discharge xxmaj labs : \\n\\n\\n xxmaj brief xxmaj hospital xxmaj course : \\n 57 y / o m with xxup esrd on xxup hd presents after missing 9 days of \\n dialysis , incidentally found to have a right calcaneal xxunk \\n fracture . \\n\\n 1 . xxup esrd : xxmaj the patient was found to be severely hyperkalemic , \\n uremic and encephalopathic on admission to the xxup icu . xxmaj dialysis \\n was re - initiated during this admission and these conditions \\n normalized without permanent sequellae . xxmaj the patient will return \\n to xxmaj monday / xxmaj wednesday / xxmaj friday schedule . \\n\\n 2 . xxmaj right calcaneous fracture : xxmaj the patient was noted to have r \\n lower extremity swelling with a superficial ulcer on exam . xxmaj heel \\n x - ray displayed a calcaneal fracture . lenis negative . xxmaj podiatry , \\n orthopedics & vascular surgery evaluated the patient and \\n determined that [ * * hospital1 * * ] xxunk casting , wound care and non - operative \\n management was indicated . xxmaj the patient will follow with xxmaj dr . [ * * first xxmaj name ( stitle ) 3209 * * ] \\n of podiatry . xxmaj he should continue prophylactic xxup sc heparin \\n injections until fully ambulatory to prevent xxup dvt . \\n\\n 3 . xxmaj diabetes : xxmaj patient was initially hypoglycemic for unclear \\n reasons on initial presentation . xxmaj during his hospital course , \\n however , his glucose was persistently elevated and his basal \\n 70 / 30 insulin was titrated up . xxmaj his blood sugars should be \\n monitored four times daily with sliding scale coverage of blood \\n sugars per the attached sliding scale . \\n\\n 4 . xxmaj cough : xxmaj the patient displayed some dyspnea and a cough . \\n xxmaj initial xxup cxr indicated a possible pneumonia for which he was \\n started on xxmaj ceftriaxone and azithromycin . xxmaj upon reevaluation on \\n the medical floor the event was likely aspiration pneumonitis \\n due to clearing of x - ray and antibiotics were stopped . xxmaj the \\n patient was continued on tessalon perles and guaifenisin as \\n needed . \\n\\n 5 . xxmaj psych : xxmaj throughout the admission the patient intermittently \\n claimed passive suicidality without true ideation or intention . \\n xxmaj his mood rapidly cycled first due to delerium and then due to \\n baseline pathology . xxmaj the patient was very labile with frequent \\n outbursts and demands during his hospital stay . xxmaj psychiatry was \\n consulted and cleared him from 1:1 sitter on which he was \\n initially placed . xxmaj he should contact the [ * * name2 ( ni ) * * ] to set up follow up \\n with a counselor if he chooses . \\n\\n 6 . xxup htn : xxmaj the patient was conitnued on metoprolol & lisinopril . \\n xxmaj he was normotensive to borderline hypotensive after dialysis . \\n\\n 7 . xxup cad : xxmaj the patient was continued on xxmaj aspirin & metoprolol . \\n\\n 7 . xxmaj prophylaxis : xxmaj patient received heparin xxup sq during his admission \\n which should be continued as above . \\n\\n xxmaj medications on xxmaj admission : \\n xxmaj humulin 70 / 30 45 u [ * * hospital1 * * ] \\n xxmaj asa 325 mg daily \\n xxmaj lisinopril 5 mg daily \\n xxmaj hydroxyzine 50 mg tid xxup prn \\n xxmaj metoprolol xxup sr 25 mg daily \\n xxunk - c complex daily \\n phoslo 667 caps , 3 caps tid \\n xxmaj folic xxmaj acid 1 mg daily \\n\\n\\n xxmaj discharge xxmaj medications : \\n 1 . xxmaj insulin xxup nph & xxmaj regular xxmaj human 100 unit / ml ( 70 - 30 ) xxmaj cartridge \\n xxmaj sig : xxmaj as directed xxmaj units xxmaj subcutaneous twice a day : xxmaj please take 54 \\n u in the morning and 50 u in the evening . \\n 2 . xxmaj aspirin 325 mg xxmaj tablet xxmaj sig : xxmaj one ( 1 ) xxmaj tablet xxup po xxup daily ( daily ) . \\n 3 . xxmaj lisinopril 5 mg xxmaj tablet xxmaj sig : xxmaj one ( 1 ) xxmaj tablet xxup po xxup daily ( daily ) . \\n\\n 4 . xxmaj hydroxyzine hcl 25 mg xxmaj tablet xxmaj sig : xxmaj two ( 2 ) xxmaj tablet xxup po every \\n eight ( 8) hours as needed . \\n 5 . xxmaj metoprolol xxmaj tartrate 25 mg xxmaj tablet xxmaj sig : [ * * 1 - 15 * * ] xxmaj tablet xxup po xxup bid ( 2 \\n times a day ) . \\n 6 . xxmaj nephrocaps 1 mg xxmaj capsule xxmaj sig : xxmaj one ( 1 ) xxmaj capsule xxup po once a day . \\n 7 . xxmaj calcium xxmaj acetate 667 mg xxmaj capsule xxmaj sig : xxmaj three ( 3 ) xxmaj capsule xxup po xxup tid \\n w / xxup meals ( 3 xxup times a xxup day xxup with xxup meals ) . \\n 8 . xxmaj folic xxmaj acid 1 mg xxmaj tablet xxmaj sig : xxmaj one ( 1 ) xxmaj tablet xxup po xxup daily ( daily ) . \\n\\n 9 . xxup insulin \\n xxmaj please continue your 70 / 30 insulin with 54 u in the morning and \\n 50 u at night . xxmaj this is an increase from your previous dose . xxmaj you \\n need to check your blood sugars four times per day . \\n\\n xxmaj please continue humalog sliding scale insulin while at rehab \\n with the attached sliding scale . \\n 10 . xxmaj heparin ( porcine ) 5 , xxrep 3 0 unit / ml xxmaj syringe xxmaj sig : 5 xxrep 3 0 ( 5 xxrep 3 0 ) u \\n xxmaj injection three times a day : xxmaj until fully ambulatory . \\n\\n\\n xxmaj discharge xxmaj disposition : \\n xxmaj extended xxmaj care \\n\\n xxmaj facility : \\n [ * * hospital3 672 * * ] xxmaj hospital \\n\\n xxmaj discharge xxmaj diagnosis : \\n xxmaj primary xxmaj diagnosis : \\n 1 . chronic kidney disease stage xxup v , on xxup hd \\n 2 . xxmaj suicidality , resolved \\n 3 . r calcaneal fracture \\n\\n xxmaj secondary xxmaj diagnosis \\n 1 . xxmaj hypertension \\n 2 . xxmaj diabetes mellitus type xxup ii , uncontrolled with complications \\n 3 . xxmaj personality disorder not otherwise specified \\n\\n\\n xxmaj discharge xxmaj condition : \\n xxmaj afebrile , normotensive , comfortable on room air \\n\\n\\n xxmaj discharge xxmaj instructions : \\n 1 . xxmaj you have been admitted to the hospital because of an extended \\n period without hemodialysis . xxmaj while you were here we xxunk \\n you on hemodialysis and you will return to a xxmaj monday , xxmaj wednesday , \\n xxmaj friday xxmaj schedule . \\n\\n 2 . xxmaj also while you were here it was noted that you have developed \\n a right heel fracture at some point likely within the last two \\n weeks . xxmaj our xxunk & orthopedic surgeons were consulted and \\n recommended a cast with regular dressing changes for your ulcer . \\n▁ xxmaj no surgery is indicated at this time . xxmaj you were also evaluated \\n by the xxunk therapists , who recommended that you go to a \\n rehab facility . \\n\\n 3 . xxmaj suicidality : xxmaj you also expressed some suicidality during your \\n admission and were evaluated by psychiatry . xxmaj if you develop \\n worsening feelings of hurting yourself or others , go to your \\n local xxmaj emergency xxmaj department or call 911 immediately . \\n\\n 4 . xxmaj unless otherwise indicated , please resume all of your \\n medications as taken prior to admission . xxmaj it is very important \\n that you take your medications as prescribed . \\n\\n 5 . xxmaj please follow rehab 's instructions regarding your xxmaj right foot , \\n to keep the weight off as directed . \\n\\n 6 . xxmaj please call your doctor or 911 if you experience suicidal \\n thoughts , chest pain , shortness of breath or any other \\n concerning medical symptom . \\n\\n xxmaj followup xxmaj instructions : \\n xxmaj hemodialysis as previously scheduled xxmaj monday , xxmaj wednesday , xxmaj friday \\n\\n xxmaj please follow up with xxmaj dr . [ * * first xxmaj name ( stitle ) * * ] in the the xxmaj podiatry department \\n on [ * * 2179 - 4 - 2 * * ] . xxmaj provider : [ * * first xxmaj name11 ( name xxmaj pattern1 ) 3210 * * ] [ * * initial ( namepattern1 ) * * ] [ * * last xxmaj name ( namepattern4 ) * * ] , xxup dpm \\n phone:[**telephone / xxmaj fax ( 1 ) 543 * * ] xxmaj date / xxmaj time:[**2179 - 4 - 2 * * ] 1:00 \\n\\n xxmaj please contact your provider at the xxup va in [ * * location 1268 * * ] if you \\n desire counseling in the future . \\n\\n xxmaj please contact your xxup pcp , [ * * last xxmaj name ( namepattern4 ) * * ] . [ * * last xxmaj name ( stitle ) xxunk * * ] , for a follow up \\n appointment within the next two weeks at [ * * telephone / xxmaj fax ( 1 ) 9075 * * ] . \\n\\n\\n▁ [ * * first xxmaj name5 ( namepattern1 ) * * ] [ * * last xxmaj name ( namepattern1 ) * * ] xxup md [ * * md xxmaj number(2 ) 617 * * ] \\n\\n xxmaj completed by:[**2179 - 3 - 18 * * ]\",\n",
       " (#25) ['276.7','585.6','348.39','790.7','427.32','507.0','403.10','825.0','E888.9','300.9'...])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets.decode(dsets.train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1650deed",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj admission xxmaj date : [ * * 2179 - 3 - 7 * * ] xxmaj discharge xxmaj date : [ * * 2179 - 3 - 18 * * ] \n",
      "\n",
      " xxmaj date of xxmaj birth : [ * * 2121 - 12 - 23 * * ] xxmaj sex : m \n",
      "\n",
      " xxmaj service : xxup medicine \n",
      "\n",
      " xxmaj allergies : \n",
      " xxmaj ibuprofen \n",
      "\n",
      " attending:[**first xxmaj name3 ( lf ) 613 * * ] \n",
      " xxmaj chief xxmaj complaint : \n",
      " dyspnea , hyperkalemia \n",
      "\n",
      " xxmaj major xxmaj surgical or xxmaj invasive xxmaj procedure : \n",
      " xxmaj hemodialysis \n",
      " right xxmaj femoral central venous line placement and removal \n",
      "\n",
      "\n",
      " xxmaj history of xxmaj present xxmaj illness : \n",
      " 57 y / o m with hx of xxup esrd presents after intentionally missing \n",
      " dialysis for last 9 days . xxmaj came to the xxup ed due to the coaxing of \n",
      " his wife . xxmaj complains of xxup sob and xxup doe lasting about the last five \n",
      " days . xxmaj also has cough with clear sputum production . xxmaj also \n",
      " complains of bilateral pedal edema , xxup r > l , starting around the \n",
      " time xxup sob started . xxmaj no fevers , chills . xxmaj no xxup cp , palpitations . \n",
      " xxmaj denies dizziness , fainting , falls . xxmaj says he stopped going to \n",
      " dialysis for no particular reason , although per xxup ed reports after \n",
      " talking with his wife , it is possible he had passive xxup si . xxmaj no \n",
      " other complaints except for mild nausea . \n",
      " . \n",
      " xxmaj in the xxup ed , his vitals were t 98.0 , xxup bp 130 / 87 , xxup hr 92 , r 22 , 99 % \n",
      " on xxup nrb weaned to room air over course of xxup ed stay . xxmaj he was noted \n",
      " to be hyperkalemic to 8.1 . xxmaj there were no xxup ekg changes . xxmaj he was \n",
      " treated with xxmaj ca , insulin / dextrose , and bicarb . xxmaj he was given \n",
      " kayexcelate but did not have a xxup bm by time of arrival to the \n",
      " floor . xxmaj he was also found to have a xxup rll pneumonia and was \n",
      " treated with azithromycin and ceftriaxone . a l femoral line was \n",
      " placed for access . xxmaj renal team was consulted . \n",
      " . \n",
      " xxmaj on the floor , the patient was feeling well . xxmaj had no complaints . \n",
      " xxmaj no dizziness , nausea , strange taste in mouth , abdominal pain . \n",
      " xxmaj no chest pain , palpitations . xxmaj shortness of breath had resolved . \n",
      " xxmaj he is confused and a poor historian . \n",
      "\n",
      " xxmaj past xxmaj medical xxmaj history : \n",
      " - xxup esrd on xxup hd ( tthsa ) . xxup av fistula in the right arm with \n",
      " complications of clot and thrombectomy last in [ * * 2177 * * ] . xxmaj now with xxup hd \n",
      "\n",
      " line in place . xxmaj undergoing transplant eval with xxmaj dr . [ * * last xxmaj name ( stitle ) * * ] , not \n",
      " yet listed . \n",
      " - xxup htn \n",
      " - xxup dm \n",
      " - xxup cad s / p xxup mi in [ * * 2164 * * ] \n",
      " - a xxmaj fib / xxmaj flutter s / p ablation in [ * * 2173 * * ] \n",
      " - xxmaj morbid obesity \n",
      " - xxmaj sigmoid diverticulosis \n",
      " - hx of entercoccus bacteremia associated with line infection \n",
      " - personality disorder \n",
      "\n",
      "\n",
      " xxmaj social xxmaj history : \n",
      " xxmaj pt lives at home with wife and 2 sons . [ * * name ( ni ) 1403 * * ] part time [ * * street xxmaj address(1 ) xxunk * * ] xxmaj bank . 50pack yr h / o tobacco use , quit in [ * * 2160 * * ] . xxmaj very \n",
      " distant marijuana use , no other drugs , no etoh . \n",
      "\n",
      "\n",
      " xxmaj family xxmaj history : \n",
      " noncontributory \n",
      "\n",
      "\n",
      " xxmaj physical xxmaj exam : \n",
      " xxmaj vitals : t afebrile , p 105 , xxup bp 167 / 86 , r 20 , 97 % on xxup ra \n",
      " xxmaj gen : obese man , resting comfortably , xxup nad , a+ox2 although \n",
      " rambling and not making sense during prolonged interactions \n",
      " xxup heent - xxup atnc , xxup perrla , xxup eomi , moist mucous membranes , xxup jvd \n",
      " difficult to assess secondary to size \n",
      " xxup cv - distant xxup hs , xxrep 3 r , no m , r , g \n",
      " xxmaj lungs - decreased at bases , otherwise xxup cta , no crackles , wheezes \n",
      " xxmaj abd - obese , soft , xxup nt , xxup nd , normoactive bowel sounds \n",
      " xxmaj ext - 2 + pedal edema on xxup r , 1 + on xxup l ; palp pulses , r foot bandaged \n",
      " due to heel ulcer , neither leg tender to palpation \n",
      " xxmaj neuro - xxup cn intact , strength 5 / 5 , + asterixis , not cooperating \n",
      " fully with neuro exam \n",
      "\n",
      " xxmaj pertinent xxmaj results : \n",
      " [ * * 2179 - 3 - 7 * * ] 07:30pm xxup glucose-112 * xxup urea xxup xxunk * xxup xxunk * # \n",
      " xxup sodium-139 xxup potassium-8.1 * xxup chloride-99 xxup total xxup co2 - 19 * xxup anion \n",
      " xxup gap-29 * \n",
      " [ * * 2179 - 3 - 7 * * ] 07:30pm estgfr - using this \n",
      " [ * * 2179 - 3 - 7 * * ] 07:30pm xxup asa - neg xxup ethanol - neg xxup acetmnphn - neg \n",
      " bnzodzpn - neg barbitrt - neg tricyclic - neg \n",
      " [ * * 2179 - 3 - 7 * * ] 07:30pm xxup wbc-11.2 * # xxup rbc-3.73 * xxup hgb-10.7 * xxup hct-32.8 * \n",
      " xxup mcv-88 xxup mch-28.6 xxup mchc-32.5 xxup rdw-15.7 * \n",
      " [ * * 2179 - 3 - 7 * * ] 07:30pm xxup neuts-80.0 * xxup lymphs-10.0 * xxup monos-7.1 xxup eos-2.5 \n",
      " xxup basos-0.4 \n",
      " [ * * 2179 - 3 - 7 * * ] 07:30pm xxup plt xxup count-251 \n",
      " [ * * 2179 - 3 - 7 * * ] 07:30pm xxup pt-14.1 * xxup ptt-37.5 * xxup inr(pt)-1.2 * \n",
      "\n",
      " [ * * 3 - 7 * * ] xxup cxr : \n",
      " xxmaj infiltrate at the right lung base likely indicating infection . \n",
      " xxmaj please ensure followup to clearance . \n",
      "\n",
      " [ * * 3 - 8 * * ] r xxmaj heel xxmaj xray : \n",
      " xxmaj two radiographs of the right heel demonstrate a displaced and \n",
      " angulated \n",
      " fracture involving the posterior calcaneal body and the \n",
      " calcaneal xxunk . \n",
      " xxmaj the superior fracture fragment is displaced approximately 3 cm . \n",
      " xxmaj mild to \n",
      " moderate degenerative change about the osseous structures of the \n",
      " mid foot is noted . xxmaj no discrete soft tissue loss is appreciated . \n",
      " xxmaj no subcutaneous \n",
      " emphysema is seen . xxmaj there is a plantar calcaneal spur . \n",
      "\n",
      " xxup impression : \n",
      " xxmaj displaced calcaneal fracture . \n",
      "\n",
      " [ * * 3 - 10 * * ] : abis \n",
      " xxup right xxup leg : xxmaj there is triphasic flow pattern on the femoral , \n",
      " popliteal and \n",
      " posterior tibial arteries and monophasic flow pattern on the \n",
      " dorsalis pedis \n",
      " artery . xxmaj the segmental limb pressures are mildly reduced on the \n",
      " calf and over \n",
      " xxup dp . xxmaj the ankle brachial index at rest 0.95 . \n",
      "\n",
      " xxup left xxup leg : xxmaj there is triphasic flow pattern on the femoral , \n",
      " popliteal , \n",
      " posterior tibial and dorsalis pedis arteries . xxmaj the segmental limb \n",
      " pressures \n",
      " are unremarkable at all levels . xxmaj the ankle brachial index at rest \n",
      " 1.18 . \n",
      "\n",
      " xxmaj the patient was not exercised . \n",
      "\n",
      " xxup impression : xxmaj mild right tibial distal disease at rest and no \n",
      " evidence of \n",
      " peripheral vascular disease on the left leg . \n",
      "\n",
      " [ * * 3 - 10 * * ] : \n",
      " xxup findings : xxmaj the right common femoral , superficial femoral , and \n",
      " popliteal veins show no evidence of deep vein thrombosis . xxmaj the \n",
      " patient declined examination of the left groin , so the left \n",
      " common femoral vein was not assessed . xxmaj however the left \n",
      " superficial and popliteal veins appear entirely normal . \n",
      "\n",
      " xxup impression : xxmaj no evidence of deep vein thrombosis noting that the \n",
      " patient \n",
      " declined examination of the left groin by the radiologist . \n",
      "\n",
      " xxmaj discharge xxmaj labs : \n",
      "\n",
      "\n",
      " xxmaj brief xxmaj hospital xxmaj course : \n",
      " 57 y / o m with xxup esrd on xxup hd presents after missing 9 days of \n",
      " dialysis , incidentally found to have a right calcaneal xxunk \n",
      " fracture . \n",
      "\n",
      " 1 . xxup esrd : xxmaj the patient was found to be severely hyperkalemic , \n",
      " uremic and encephalopathic on admission to the xxup icu . xxmaj dialysis \n",
      " was re - initiated during this admission and these conditions \n",
      " normalized without permanent sequellae . xxmaj the patient will return \n",
      " to xxmaj monday / xxmaj wednesday / xxmaj friday schedule . \n",
      "\n",
      " 2 . xxmaj right calcaneous fracture : xxmaj the patient was noted to have r \n",
      " lower extremity swelling with a superficial ulcer on exam . xxmaj heel \n",
      " x - ray displayed a calcaneal fracture . lenis negative . xxmaj podiatry , \n",
      " orthopedics & vascular surgery evaluated the patient and \n",
      " determined that [ * * hospital1 * * ] xxunk casting , wound care and non - operative \n",
      " management was indicated . xxmaj the patient will follow with xxmaj dr . [ * * first xxmaj name ( stitle ) 3209 * * ] \n",
      " of podiatry . xxmaj he should continue prophylactic xxup sc heparin \n",
      " injections until fully ambulatory to prevent xxup dvt . \n",
      "\n",
      " 3 . xxmaj diabetes : xxmaj patient was initially hypoglycemic for unclear \n",
      " reasons on initial presentation . xxmaj during his hospital course , \n",
      " however , his glucose was persistently elevated and his basal \n",
      " 70 / 30 insulin was titrated up . xxmaj his blood sugars should be \n",
      " monitored four times daily with sliding scale coverage of blood \n",
      " sugars per the attached sliding scale . \n",
      "\n",
      " 4 . xxmaj cough : xxmaj the patient displayed some dyspnea and a cough . \n",
      " xxmaj initial xxup cxr indicated a possible pneumonia for which he was \n",
      " started on xxmaj ceftriaxone and azithromycin . xxmaj upon reevaluation on \n",
      " the medical floor the event was likely aspiration pneumonitis \n",
      " due to clearing of x - ray and antibiotics were stopped . xxmaj the \n",
      " patient was continued on tessalon perles and guaifenisin as \n",
      " needed . \n",
      "\n",
      " 5 . xxmaj psych : xxmaj throughout the admission the patient intermittently \n",
      " claimed passive suicidality without true ideation or intention . \n",
      " xxmaj his mood rapidly cycled first due to delerium and then due to \n",
      " baseline pathology . xxmaj the patient was very labile with frequent \n",
      " outbursts and demands during his hospital stay . xxmaj psychiatry was \n",
      " consulted and cleared him from 1:1 sitter on which he was \n",
      " initially placed . xxmaj he should contact the [ * * name2 ( ni ) * * ] to set up follow up \n",
      " with a counselor if he chooses . \n",
      "\n",
      " 6 . xxup htn : xxmaj the patient was conitnued on metoprolol & lisinopril . \n",
      " xxmaj he was normotensive to borderline hypotensive after dialysis . \n",
      "\n",
      " 7 . xxup cad : xxmaj the patient was continued on xxmaj aspirin & metoprolol . \n",
      "\n",
      " 7 . xxmaj prophylaxis : xxmaj patient received heparin xxup sq during his admission \n",
      " which should be continued as above . \n",
      "\n",
      " xxmaj medications on xxmaj admission : \n",
      " xxmaj humulin 70 / 30 45 u [ * * hospital1 * * ] \n",
      " xxmaj asa 325 mg daily \n",
      " xxmaj lisinopril 5 mg daily \n",
      " xxmaj hydroxyzine 50 mg tid xxup prn \n",
      " xxmaj metoprolol xxup sr 25 mg daily \n",
      " xxunk - c complex daily \n",
      " phoslo 667 caps , 3 caps tid \n",
      " xxmaj folic xxmaj acid 1 mg daily \n",
      "\n",
      "\n",
      " xxmaj discharge xxmaj medications : \n",
      " 1 . xxmaj insulin xxup nph & xxmaj regular xxmaj human 100 unit / ml ( 70 - 30 ) xxmaj cartridge \n",
      " xxmaj sig : xxmaj as directed xxmaj units xxmaj subcutaneous twice a day : xxmaj please take 54 \n",
      " u in the morning and 50 u in the evening . \n",
      " 2 . xxmaj aspirin 325 mg xxmaj tablet xxmaj sig : xxmaj one ( 1 ) xxmaj tablet xxup po xxup daily ( daily ) . \n",
      " 3 . xxmaj lisinopril 5 mg xxmaj tablet xxmaj sig : xxmaj one ( 1 ) xxmaj tablet xxup po xxup daily ( daily ) . \n",
      "\n",
      " 4 . xxmaj hydroxyzine hcl 25 mg xxmaj tablet xxmaj sig : xxmaj two ( 2 ) xxmaj tablet xxup po every \n",
      " eight ( 8) hours as needed . \n",
      " 5 . xxmaj metoprolol xxmaj tartrate 25 mg xxmaj tablet xxmaj sig : [ * * 1 - 15 * * ] xxmaj tablet xxup po xxup bid ( 2 \n",
      " times a day ) . \n",
      " 6 . xxmaj nephrocaps 1 mg xxmaj capsule xxmaj sig : xxmaj one ( 1 ) xxmaj capsule xxup po once a day . \n",
      " 7 . xxmaj calcium xxmaj acetate 667 mg xxmaj capsule xxmaj sig : xxmaj three ( 3 ) xxmaj capsule xxup po xxup tid \n",
      " w / xxup meals ( 3 xxup times a xxup day xxup with xxup meals ) . \n",
      " 8 . xxmaj folic xxmaj acid 1 mg xxmaj tablet xxmaj sig : xxmaj one ( 1 ) xxmaj tablet xxup po xxup daily ( daily ) . \n",
      "\n",
      " 9 . xxup insulin \n",
      " xxmaj please continue your 70 / 30 insulin with 54 u in the morning and \n",
      " 50 u at night . xxmaj this is an increase from your previous dose . xxmaj you \n",
      " need to check your blood sugars four times per day . \n",
      "\n",
      " xxmaj please continue humalog sliding scale insulin while at rehab \n",
      " with the attached sliding scale . \n",
      " 10 . xxmaj heparin ( porcine ) 5 , xxrep 3 0 unit / ml xxmaj syringe xxmaj sig : 5 xxrep 3 0 ( 5 xxrep 3 0 ) u \n",
      " xxmaj injection three times a day : xxmaj until fully ambulatory . \n",
      "\n",
      "\n",
      " xxmaj discharge xxmaj disposition : \n",
      " xxmaj extended xxmaj care \n",
      "\n",
      " xxmaj facility : \n",
      " [ * * hospital3 672 * * ] xxmaj hospital \n",
      "\n",
      " xxmaj discharge xxmaj diagnosis : \n",
      " xxmaj primary xxmaj diagnosis : \n",
      " 1 . chronic kidney disease stage xxup v , on xxup hd \n",
      " 2 . xxmaj suicidality , resolved \n",
      " 3 . r calcaneal fracture \n",
      "\n",
      " xxmaj secondary xxmaj diagnosis \n",
      " 1 . xxmaj hypertension \n",
      " 2 . xxmaj diabetes mellitus type xxup ii , uncontrolled with complications \n",
      " 3 . xxmaj personality disorder not otherwise specified \n",
      "\n",
      "\n",
      " xxmaj discharge xxmaj condition : \n",
      " xxmaj afebrile , normotensive , comfortable on room air \n",
      "\n",
      "\n",
      " xxmaj discharge xxmaj instructions : \n",
      " 1 . xxmaj you have been admitted to the hospital because of an extended \n",
      " period without hemodialysis . xxmaj while you were here we xxunk \n",
      " you on hemodialysis and you will return to a xxmaj monday , xxmaj wednesday , \n",
      " xxmaj friday xxmaj schedule . \n",
      "\n",
      " 2 . xxmaj also while you were here it was noted that you have developed \n",
      " a right heel fracture at some point likely within the last two \n",
      " weeks . xxmaj our xxunk & orthopedic surgeons were consulted and \n",
      " recommended a cast with regular dressing changes for your ulcer . \n",
      "▁ xxmaj no surgery is indicated at this time . xxmaj you were also evaluated \n",
      " by the xxunk therapists , who recommended that you go to a \n",
      " rehab facility . \n",
      "\n",
      " 3 . xxmaj suicidality : xxmaj you also expressed some suicidality during your \n",
      " admission and were evaluated by psychiatry . xxmaj if you develop \n",
      " worsening feelings of hurting yourself or others , go to your \n",
      " local xxmaj emergency xxmaj department or call 911 immediately . \n",
      "\n",
      " 4 . xxmaj unless otherwise indicated , please resume all of your \n",
      " medications as taken prior to admission . xxmaj it is very important \n",
      " that you take your medications as prescribed . \n",
      "\n",
      " 5 . xxmaj please follow rehab 's instructions regarding your xxmaj right foot , \n",
      " to keep the weight off as directed . \n",
      "\n",
      " 6 . xxmaj please call your doctor or 911 if you experience suicidal \n",
      " thoughts , chest pain , shortness of breath or any other \n",
      " concerning medical symptom . \n",
      "\n",
      " xxmaj followup xxmaj instructions : \n",
      " xxmaj hemodialysis as previously scheduled xxmaj monday , xxmaj wednesday , xxmaj friday \n",
      "\n",
      " xxmaj please follow up with xxmaj dr . [ * * first xxmaj name ( stitle ) * * ] in the the xxmaj podiatry department \n",
      " on [ * * 2179 - 4 - 2 * * ] . xxmaj provider : [ * * first xxmaj name11 ( name xxmaj pattern1 ) 3210 * * ] [ * * initial ( namepattern1 ) * * ] [ * * last xxmaj name ( namepattern4 ) * * ] , xxup dpm \n",
      " phone:[**telephone / xxmaj fax ( 1 ) 543 * * ] xxmaj date / xxmaj time:[**2179 - 4 - 2 * * ] 1:00 \n",
      "\n",
      " xxmaj please contact your provider at the xxup va in [ * * location 1268 * * ] if you \n",
      " desire counseling in the future . \n",
      "\n",
      " xxmaj please contact your xxup pcp , [ * * last xxmaj name ( namepattern4 ) * * ] . [ * * last xxmaj name ( stitle ) xxunk * * ] , for a follow up \n",
      " appointment within the next two weeks at [ * * telephone / xxmaj fax ( 1 ) 9075 * * ] . \n",
      "\n",
      "\n",
      "▁ [ * * first xxmaj name5 ( namepattern1 ) * * ] [ * * last xxmaj name ( namepattern1 ) * * ] xxup md [ * * md xxmaj number(2 ) 617 * * ] \n",
      "\n",
      " xxmaj completed by:[**2179 - 3 - 18 * * ]\n",
      "276.7;585.6;348.39;790.7;427.32;507.0;403.10;825.0;E888.9;300.9;301.9;250.62;357.2;250.42;285.21;278.01;427.31;250.82;V15.81;276.52;707.07;707.22;041.19;39.95;38.93\n"
     ]
    }
   ],
   "source": [
    "dsets.show(dsets.train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26659eb0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f9c79a",
   "metadata": {
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 4. Making the `DataLoaders` object:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eabc06",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to pick the sequence length and the batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef0bdf85",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs, sl = 64, 72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cd7b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will use the `dl_type` argument of the `DataLoaders`. The purpose is to tell `DataLoaders` to use `SortedDL` class of the `DataLoader`, and not the usual one. `SortedDL` constructs batches by putting samples of roughly the same lengths into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1b5b0b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dl_type = partial(SortedDL, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9cde48-5633-48b1-a7a3-40b2cae52193",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Crucial:** \n",
    "- We will use **`pad_input_chunk`** because our encoder `AWD_LSTM` will be wrapped inside `SentenceEncoder`. \n",
    "- A `SenetenceEncoder` expects that all the documents are padded, \n",
    "- with most of the padding at the beginning of the document, with each sequence beginning at a round multiple of bptt\n",
    "- and the rest of the padding at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92169157",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dls_clas = dsets.dataloaders(bs=bs, seq_len=sl, \n",
    "                        dl_type=dl_type,\n",
    "                       before_batch=pad_input_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d755e2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creating the `DataLoaders` object takes considerable amount of time, so let's save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f14c3853",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# torch.save(dls_clas, path_model/'dls_clas_sample_new.pkl')\n",
    "torch.save(dls_clas, path_model/'dls_clas_sample_64.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb36073b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dls_clas = torch.load(path_model/'dls_clas_sample_new.pkl')\n",
    "dls_clas = torch.load(path_model/'dls_clas_sample_64.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94995576",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fef3d",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls_clas.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29c1a7fd-60be-4a18-83a0-48dbf170b6ea",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x, y = dls_clas.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "505a3782-9308-41cb-8b22-907df336b5f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47f8d1db-e24a-477e-9e84-87564aff9b2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# len(dls_clas.vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2256e5c-2e96-4fb4-8805-fa498bba6be9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x[20], len(x[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3541dd6-f3e7-4151-92b4-92e8b0653ede",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(' '.join([dls_clas.vocab[0][o] for o in x[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad6867",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `Learner` for Multi-Label Classifier Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34993915-82d6-4c69-9b25-08dd4f454e8b",
   "metadata": {},
   "source": [
    "In this section we will unwrap fastai's `text_classifier_learner` and manually write all the steps (ofcourse, shamelessly stealing) from fastai's source code!\n",
    "\n",
    "To create a `Learner` from scratch we need two things:\n",
    "- `DataLoaders` `dls`\n",
    "- an architecture `arch` for the `model`\n",
    "\n",
    "We already have our `dls` ready from the previous section, so let's focus on creating our architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a87d173-a05d-4192-87be-091c9f341471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dls_clas = torch.load(path_model/'dls_clas_sample_new.pkl')\n",
    "dls_clas = torch.load(path_model/'dls_clas_sample_64.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730d2b5-79c2-4c84-a7a6-1db42b5d8d6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Architecture Creation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c616826-5167-4f8a-a7b4-3bcd3c81707b",
   "metadata": {},
   "source": [
    "To create an architecture that we can use to build a `model` we need to unwrap fastai's `get_text_classifier`. Let's do that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c82b7ec-8f54-41f2-832c-aecbde0920e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_text_classifier(AWD_LSTM,\n",
    "#                             len(vocab),\n",
    "#                             n_out,\n",
    "#                             seq_len=seq_len,\n",
    "#                             config=config,\n",
    "#                             y_range=y_range,\n",
    "#                             drop_mult=drop_mult,\n",
    "#                             lin_ftrs=lin_ftrs,\n",
    "#                             max_len=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a304d-1799-4c89-98b4-553064c8b84f",
   "metadata": {},
   "source": [
    "The following is a dictionary where keys are the well known (possibly pretarianed) NLP architectures and values are the configurations, urls (where we can download the pretrained weights from) and other info we need to create that architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd780362-5dba-43ee-b783-dcb385411318",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_meta = {\n",
    "    AWD_LSTM: {'hid_name':'emb_sz', 'url':URLs.WT103_FWD, 'url_bwd':URLs.WT103_BWD,'config_lm':awd_lstm_lm_config, 'split_lm': awd_lstm_lm_split,            \n",
    "                'config_clas':awd_lstm_clas_config, 'split_clas': awd_lstm_clas_split\n",
    "              }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb93f61b-7a9c-41ad-9906-6036b8a599d2",
   "metadata": {},
   "source": [
    "Let's define an architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ece6c37-74a4-42ad-85de-bd7adfd5dcf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.models.awdlstm.AWD_LSTM"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = AWD_LSTM\n",
    "arch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503d013-3482-423e-84f3-0321a1a5b20a",
   "metadata": {},
   "source": [
    "Let's get the value (information) of that architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31d5ef8-a692-4987-9e02-9fa6ecfb3ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hid_name': 'emb_sz',\n",
       " 'url': 'https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz',\n",
       " 'url_bwd': 'https://s3.amazonaws.com/fast-ai-modelzoo/wt103-bwd.tgz',\n",
       " 'config_lm': {'emb_sz': 400,\n",
       "  'n_hid': 1152,\n",
       "  'n_layers': 3,\n",
       "  'pad_token': 1,\n",
       "  'bidir': False,\n",
       "  'output_p': 0.1,\n",
       "  'hidden_p': 0.15,\n",
       "  'input_p': 0.25,\n",
       "  'embed_p': 0.02,\n",
       "  'weight_p': 0.2,\n",
       "  'tie_weights': True,\n",
       "  'out_bias': True},\n",
       " 'split_lm': <function fastai.text.models.awdlstm.awd_lstm_lm_split(model)>,\n",
       " 'config_clas': {'emb_sz': 400,\n",
       "  'n_hid': 1152,\n",
       "  'n_layers': 3,\n",
       "  'pad_token': 1,\n",
       "  'bidir': False,\n",
       "  'output_p': 0.4,\n",
       "  'hidden_p': 0.3,\n",
       "  'input_p': 0.4,\n",
       "  'embed_p': 0.05,\n",
       "  'weight_p': 0.5},\n",
       " 'split_clas': <function fastai.text.models.awdlstm.awd_lstm_clas_split(model)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = _model_meta[arch]\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b035d4-6e20-4b6c-bce8-1c64d42db569",
   "metadata": {},
   "source": [
    "Let's now get the default configuration required to build that architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd1a331-9f20-4e4e-81fa-afda5a0e30cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emb_sz': 400,\n",
       " 'n_hid': 1152,\n",
       " 'n_layers': 3,\n",
       " 'pad_token': 1,\n",
       " 'bidir': False,\n",
       " 'output_p': 0.4,\n",
       " 'hidden_p': 0.3,\n",
       " 'input_p': 0.4,\n",
       " 'embed_p': 0.05,\n",
       " 'weight_p': 0.5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = None\n",
    "config = ifnone(config, meta['config_clas']).copy()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd7d66-374b-4050-9fdc-947d2634f800",
   "metadata": {},
   "source": [
    "Alternatively, we could have just grabbed the configuration provided by a fastai convenienece dictionary called `awd_lstm_clas_config`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12e6a60-0311-40a2-a53a-9a38bbeb7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = awd_lstm_clas_config.copy()\n",
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58bd7bb-cbf7-415b-aa5d-3fbeaff5c0e8",
   "metadata": {},
   "source": [
    "**Dropout**:  \n",
    "As we can see the the default configuration has some default dropout probabilities. We can use a multiplier to multiply with each of these probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82b6fb7f-3b77-40ae-af13-c0de0ceaa0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mult = 0.1\n",
    "for k in config.keys():\n",
    "    if k.endswith('_p'): config[k] *= drop_mult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a1573-4c9e-4612-8361-01e0d6b4d81d",
   "metadata": {},
   "source": [
    "NOT SURE (Find out later!) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f462b4-09e7-42b8-be7f-601aa35d7f11",
   "metadata": {},
   "source": [
    "Note: In fastai `ps` was $0.1$, we made it $0.01$ (because in extreme multi-label classification we want to drop out less activations, but need to investigate this later!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785b58f6-892b-44da-a083-3259976f650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.1], [50])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ftrs, ps = None, None\n",
    "if lin_ftrs is None: lin_ftrs = [50]\n",
    "if ps is None: ps = [0.1] * len(lin_ftrs)\n",
    "ps, lin_ftrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba952c-fb63-4d44-8bfc-333e024f44ea",
   "metadata": {},
   "source": [
    "Let's find out the total number of classes from dls (becuase we need this info to build the architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cbd7aab-dbb2-4798-bef6-54436d3a5d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6594"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_out = get_c(dls_clas)\n",
    "n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fbb399-a743-4c5f-9780-cebaf24a7fd2",
   "metadata": {},
   "source": [
    "The embedding size as per the default config is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9285724-f6c3-4a5e-994d-2ced8d98901b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sz = config.get('emb_sz')\n",
    "emb_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb01f97-9429-4256-8644-69ca11ebceb2",
   "metadata": {},
   "source": [
    "The decoder for text classification will be a `PoolingLinearClassifier` with two linear layers:\n",
    "- the first layer will have number of input features 1200 and number of output features 50\n",
    "- the second layer will have number of input features 50 and number of output features equal to `n_out`\n",
    "\n",
    "Let's make these layer configuarion in a list called `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3639b68-4d93-43ef-a11d-b9dc9acef5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1200, 50, 6594]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [emb_sz * 3] + lin_ftrs + [n_out]\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4bdb99-8da0-47a2-b8a5-63062250e920",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65463d-0406-47f9-9bdd-17aa1aa92b7a",
   "metadata": {},
   "source": [
    "**IMPORTANT**: \n",
    "\n",
    "In fastai the number of output features coming out was 400. Then we did a `masked_concat_pool` so the final output fed to the `PoolingLinearClassifier` was 1200. In order to implement **attention** we concat a context of 400 to those previous 1200 features. So the total number output features with attention is 1200+400=1600. Hence the change below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73db0fe-b8b8-45bd-9a08-22f4c02d207a",
   "metadata": {},
   "source": [
    "If using attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3b7b2c9-0f58-43e4-aa6d-56ecaf30c4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10550400, 50, 6594]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_attn = [n_out * (emb_sz * 3 + emb_sz) ] + lin_ftrs + [n_out]\n",
    "layers_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c166adb1-61ff-49dd-bf3e-b99c1b7cd4bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a12ba145-5c72-4477-bd23-769620fa89bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1]\n",
      "[0.04000000000000001, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(ps)\n",
    "ps = [config.pop('output_p')] + ps\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38b45863-8725-48b0-96b6-0ecb7d8fdf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = config.pop('init') if 'init' in config else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1ccf4-c31e-4f86-afe3-894012c1a52c",
   "metadata": {},
   "source": [
    "Now we have reached a point where we can make our Encoder (which in this case will be an AWD_LSTM that is the architecture that we are using). To make the `AWD_LSTM` module we need to pass the `vocab_sz` and the `config` dictionary (after peeling off `output_p` and `init`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0f064f4-cee6-4ffb-ae25-dfbee1d1a375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60008"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = dls_clas.vocab[0]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "804e8f7d-445e-4e56-8f11-b2cd660401ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch = <class 'fastai.text.models.awdlstm.AWD_LSTM'>, \n",
      "\n",
      " config = {'emb_sz': 400, 'n_hid': 1152, 'n_layers': 3, 'pad_token': 1, 'bidir': False, 'hidden_p': 0.03, 'input_p': 0.04000000000000001, 'embed_p': 0.005000000000000001, 'weight_p': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{arch = }, \\n\\n {config = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95d77e-2d29-41a8-a245-18b4b5ffe01c",
   "metadata": {},
   "source": [
    "Let's take a look at how our AWD_LSTM model looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2995aa3-b27b-4b2f-b5c9-0852fa0470f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.models.awdlstm.AWD_LSTM"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5587f7b8-ac5c-4b33-8f73-833f789ed511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.update({'bidir': True})\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "868050ae-75a6-4806-8edd-768c2d4daa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AWD_LSTM(\n",
       "  (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "  (encoder_dp): EmbeddingDropout(\n",
       "    (emb): Embedding(60008, 400, padding_idx=1)\n",
       "  )\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDropout(\n",
       "      (module): LSTM(400, 1152, batch_first=True)\n",
       "    )\n",
       "    (1): WeightDropout(\n",
       "      (module): LSTM(1152, 1152, batch_first=True)\n",
       "    )\n",
       "    (2): WeightDropout(\n",
       "      (module): LSTM(1152, 400, batch_first=True)\n",
       "    )\n",
       "  )\n",
       "  (input_dp): RNNDropout()\n",
       "  (hidden_dps): ModuleList(\n",
       "    (0): RNNDropout()\n",
       "    (1): RNNDropout()\n",
       "    (2): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch(vocab_sz=len(vocab), **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88175c53-ad17-42f1-a5f8-c88a825b7531",
   "metadata": {},
   "source": [
    "**An important thing (of immense practical importance) to note:**  \n",
    "Since we do not have infinite amount of GPU memory so we need to wrap our AWD_LSTM module inside a `SentenceEncoder`.  \n",
    "Need to elaborate further (later on!)\n",
    "\n",
    "fastai's `SentenceEncoder` takes the following positional and keyword arguments:\n",
    "- `bptt` (this is chunk size, mostly `seq_len`, the text document gets broken into)\n",
    "- `module` (this the module that we want to wrap a `SentenceEncoder` around)\n",
    "- `pad_idx` (has a default value of 1 everywhere in fastai)\n",
    "- `max_len` (has a default value 72 * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb2a45-9b36-4810-aac1-f05f1bbad878",
   "metadata": {},
   "source": [
    "We don't really need to write our own `SentenEncoder` we can just use fastai's. But it is exteremely important to understand this source code. So for the sake of completion we include it below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e3a259-6e9e-48a8-bc13-765ae1119410",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "def _pad_tensor(t, bs):\n",
    "    if t.size(0) < bs: return torch.cat([t, t.new_zeros(bs-t.size(0), *t.shape[1:])])\n",
    "    return t\n",
    "\n",
    "class OurSentenceEncoder(Module):\n",
    "    def __init__(self, bptt, module, pad_idx=1, max_len=None):\n",
    "        store_attr('bptt,module,pad_idx,max_len')\n",
    "        \n",
    "    def reset(self): getattr(self.module, 'reset', noop)()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        bs, sl = input.size()\n",
    "#         import pdb; pdb.set_trace()\n",
    "        self.reset()\n",
    "        mask = input == self.pad_idx\n",
    "        outs, masks = [], []\n",
    "        for i in range(0, sl, self.bptt):\n",
    "#             import pdb; pdb.set_trace()\n",
    "            #Note: this expects that sequence really begins on a round multiple of bptt\n",
    "            real_bs = (input[:, i] != self.pad_idx).long().sum()\n",
    "            o = self.module(input[:real_bs, i: min(i+self.bptt, sl)])\n",
    "            if self.max_len is None or sl-i <= self.max_len:\n",
    "                outs.append(o)\n",
    "                masks.append(mask[:, i:min(i+self.bptt, sl)])\n",
    "        outs = torch.cat([_pad_tensor(o, bs) for o in outs], dim=1)\n",
    "        mask = torch.cat(masks, dim=1)\n",
    "        return outs, mask\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe88bc-c8f2-4f80-bbdd-2eec21dbbf35",
   "metadata": {},
   "source": [
    "**IMPORTANT:** To make sure we look at the hidden state for each of the token in the entire document (meaning we want to be looking at `bs,seq_len,nh` where `seq_len` is the entire document length and not just `max_len`) before classifying, we need to let `SentenceEncoder` work with its default `max_len` (instead of passing something like $72*20$ which is what we would do for sentiment analysis)... [Elaborate this later explaining the difference between extreme multilabel classification and sentiment analysis...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7d5bd65-db5d-4a38-a3d4-22a2689636b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceEncoder(\n",
       "  (module): AWD_LSTM(\n",
       "    (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60008, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 72\n",
    "# encoder = OurSentenceEncoder(seq_len, arch(vocab_sz=len(vocab), **config), pad_idx=1, max_len=seq_len*20)\n",
    "encoder = SentenceEncoder(seq_len, arch(vocab_sz=len(vocab), **config), pad_idx=1, max_len=seq_len*20)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca29950-8589-435c-b531-5b4f3054af4a",
   "metadata": {},
   "source": [
    "So now have the encoder and ready to make the decoder. The decoder in this case would be a `PoolingLinearClassifier`. We will make it using the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7508f151-91a8-4be5-b684-26994419f963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1200, 50, 6594], [0.04000000000000001, 0.1], 72)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_range = None\n",
    "layers, ps, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b7ab18-e599-415c-9dda-1a25b75f1d5a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7dfff8-b958-408c-8b23-c88f8a72059a",
   "metadata": {},
   "source": [
    "If using attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9de5c3c-6788-48de-bd43-4a31308ff520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10550400, 50, 6594], [0.04000000000000001, 0.1], 72)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_attn, ps, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2217d-845c-4052-a7bc-7501383f55fa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f4b72-e97d-4995-bc18-dc41b37c05e6",
   "metadata": {},
   "source": [
    "Eventhough now we can just use fastai's `PoolingLinearClassifier`, but later on we will need to modify this module (to incorporate *attention*). So for the purpose of customizability let's copy the source code from fastai and (shamelessly) call it `OurPoolingLinearClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1383b6f5-054a-48aa-a526-4d1006174358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurPoolingLinearClassifier(Module):\n",
    "    def __init__(self, dims, ps, bptt, y_range=None):\n",
    "        if len(ps) != len(dims)-1: raise ValueError(\"Number of layers and dropout values do not match.\")\n",
    "        acts = [nn.ReLU(inplace=True)] * (len(dims) - 2) + [None]\n",
    "        layers = [LinBnDrop(i, o, p=p, act=a) for i,o,p,a in zip(dims[:-1], dims[1:], ps, acts)]\n",
    "        if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.bptt = bptt\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        x = self.layers(x)\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd48a48d-d230-416a-ba88-7cd21a8720e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfefdcf1-e3aa-4146-877e-4e60c6e8d8ca",
   "metadata": {},
   "source": [
    "CAUTION: Work in Progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77c1685d-ccb6-4bd0-a3a5-fb76c6db1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurPoolingAttentionClassifier(Module):\n",
    "    def __init__(self, dims, ps, bptt, y_range=None):\n",
    "        if len(ps) != len(dims)-1: raise ValueError(\"Number of layers and dropout values do not match.\")\n",
    "        acts = [nn.ReLU(inplace=True)] * (len(dims) - 2) + [None]\n",
    "        layers = [LinBnDrop(i, o, p=p, act=a) for i,o,p,a in zip(dims[:-1], dims[1:], ps, acts)]\n",
    "        if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.bptt = bptt\n",
    "        \n",
    "        # new\n",
    "        label_emb_sz=49\n",
    "        self.emb_label = nn.Embedding(n_out, emb_sz)\n",
    "        self.lin = nn.Linear(emb_sz, emb_sz)\n",
    "        self.lin_for_tok_red = nn.Linear(seq_len*20, 50)\n",
    "        self.lin_for_rep_compress = nn.Linear(emb_sz, label_emb_sz)\n",
    "        self.lin_for_rep_decompress = nn.Linear(label_emb_sz, emb_sz)\n",
    "        self.V = self._init_param(label_emb_sz)\n",
    "        # new\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        \n",
    "        # new\n",
    "        num_tok = out.shape[1]\n",
    "        out = F.pad(out, (0,0,0,seq_len*20-num_tok))\n",
    "        bs = out.shape[0]\n",
    "        label_indices = torch.arange(n_out, device=out.device)\n",
    "        labels = label_indices.repeat(bs, 1)\n",
    "        after_grabbing_label_embedding = self.emb_label(labels)\n",
    "        after_first_matmul = self.lin(after_grabbing_label_embedding)\n",
    "        \n",
    "        out = self.lin_for_rep_compress(out)\n",
    "        after_first_matmul = self.lin_for_rep_compress(after_first_matmul)\n",
    "        \n",
    "        out = out.permute(0,2,1).contiguous()\n",
    "        out = self.lin_for_tok_red(out)\n",
    "        out = out.permute(0,2,1).contiguous()\n",
    "        after_nonlinearity = torch.tanh(out[:, :, None] + after_first_matmul[:,None])\n",
    "        attn_wgts = (after_nonlinearity @ self.V)\n",
    "        ctx = (out[:, :, None] * attn_wgts[..., None])\n",
    "        ctx = ctx.sum(1)\n",
    "        \n",
    "        ctx = self.lin_for_rep_decompress(torch.relu(ctx))\n",
    "        \n",
    "        x = x[:, None]\n",
    "        x = x.repeat(1, n_out, 1)\n",
    "        x = torch.cat((x, ctx), dim=-1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # new\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        return x, out, out\n",
    "    \n",
    "    def _init_param(self, *sz): \n",
    "        return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec42aa6",
   "metadata": {},
   "source": [
    "CAUTION ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e377ae-4397-451d-b66e-bb9c1bc94b5c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d27b2782-747e-48c8-9cb2-16af730132d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OurPoolingLinearClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.04000000000000001, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = OurPoolingLinearClassifier(layers, ps, bptt=seq_len, y_range=y_range)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f8c0a-c82a-4b11-80b1-19ef8e53e518",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8bbbe3-d05a-4819-a455-5d1acaaa3704",
   "metadata": {},
   "source": [
    "If using attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35e31d41-3013-4f1f-8ca7-1d9322dfa3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OurPoolingAttentionClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): LinBnDrop(\n",
       "      (0): BatchNorm1d(10550400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.04000000000000001, inplace=False)\n",
       "      (2): Linear(in_features=10550400, out_features=50, bias=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): LinBnDrop(\n",
       "      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (emb_label): Embedding(6594, 400)\n",
       "  (lin): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (lin_for_tok_red): Linear(in_features=1440, out_features=50, bias=True)\n",
       "  (lin_for_rep_compress): Linear(in_features=400, out_features=49, bias=True)\n",
       "  (lin_for_rep_decompress): Linear(in_features=49, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = OurPoolingAttentionClassifier(layers_attn, ps, bptt=seq_len, y_range=y_range)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8d0f1-16c0-480b-b5a2-17dfa71dba9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb1c6c-6a42-4e9a-afc4-643f828c1700",
   "metadata": {},
   "source": [
    "The last thing that we need to do in order to create our architecture module is stack the `encoder` and the `decoder` using `SequentialRNN` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c93a65e-3dde-4d96-b06f-d0a37ebc22e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): SentenceEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60008, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): OurPoolingAttentionClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): LinBnDrop(\n",
       "        (0): BatchNorm1d(10550400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Dropout(p=0.04000000000000001, inplace=False)\n",
       "        (2): Linear(in_features=10550400, out_features=50, bias=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): LinBnDrop(\n",
       "        (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "        (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (emb_label): Embedding(6594, 400)\n",
       "    (lin): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (lin_for_tok_red): Linear(in_features=1440, out_features=50, bias=True)\n",
       "    (lin_for_rep_compress): Linear(in_features=400, out_features=49, bias=True)\n",
       "    (lin_for_rep_decompress): Linear(in_features=49, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialRNN(encoder, decoder)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dc9e226-c693-4d07-8ab0-ba5fdae75318",
   "metadata": {},
   "outputs": [],
   "source": [
    "if init is not None: model = model.apply(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463e7ad-aafa-487e-b883-ef243d5354f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "At this point we are done creating the `model` (that is have replicated every step inside `get_text_classifier`). Next, let's move on to `text_classifier_learner`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f9c72-725c-41fa-91a7-009d29b03da3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7349c-3541-4f3b-b6f1-99e073790771",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "#### Scratchpad: (Build the pieces to implement attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed9d1d36-5e9d-43e7-9e41-b4ecad7a0588",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 18398]),\n",
       " torch.Size([128, 6594]),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dls_clas.one_batch()\n",
    "x.shape, y.shape, x.device, y.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9f359e1-b495-46fc-b571-a5196e7dce96",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SentenceEncoder(\n",
       "   (module): AWD_LSTM(\n",
       "     (encoder): Embedding(60008, 400, padding_idx=1)\n",
       "     (encoder_dp): EmbeddingDropout(\n",
       "       (emb): Embedding(60008, 400, padding_idx=1)\n",
       "     )\n",
       "     (rnns): ModuleList(\n",
       "       (0): WeightDropout(\n",
       "         (module): LSTM(400, 1152, batch_first=True)\n",
       "       )\n",
       "       (1): WeightDropout(\n",
       "         (module): LSTM(1152, 1152, batch_first=True)\n",
       "       )\n",
       "       (2): WeightDropout(\n",
       "         (module): LSTM(1152, 400, batch_first=True)\n",
       "       )\n",
       "     )\n",
       "     (input_dp): RNNDropout()\n",
       "     (hidden_dps): ModuleList(\n",
       "       (0): RNNDropout()\n",
       "       (1): RNNDropout()\n",
       "       (2): RNNDropout()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " OurPoolingAttentionClassifier(\n",
       "   (layers): Sequential(\n",
       "     (0): LinBnDrop(\n",
       "       (0): BatchNorm1d(10550400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (1): Dropout(p=0.04000000000000001, inplace=False)\n",
       "       (2): Linear(in_features=10550400, out_features=50, bias=False)\n",
       "       (3): ReLU(inplace=True)\n",
       "     )\n",
       "     (1): LinBnDrop(\n",
       "       (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (1): Dropout(p=0.1, inplace=False)\n",
       "       (2): Linear(in_features=50, out_features=6594, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (emb_label): Embedding(6594, 400)\n",
       "   (lin): Linear(in_features=400, out_features=400, bias=True)\n",
       "   (lin_for_tok_red): Linear(in_features=1440, out_features=50, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, decoder = model[0], model[1]\n",
    "encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0266325d-a054-4a83-a9d0-86f1c0e34576",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder, decoder = encoder.cuda(), decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b4fc6cb-6bcf-40bc-b913-2b4e1f6679e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc8cccec-43cb-4b81-b236-2c5ba5b240e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1406, 400]), torch.Size([2, 1406]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, mask = encoder(x[:2])\n",
    "out.shape, mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf8887-f670-49b4-92e3-06f40ff0a34b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc5c67-d8a0-4517-883e-81344a087851",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After getting the output from the `encoder` we will do a masked concat pooling as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95ff6b5f-6b2a-403a-bf7b-0300f7f802c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# out_concat_pool = masked_concat_pool(out, mask, bptt=seq_len)\n",
    "# out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07ce8f-44ae-4e08-a891-72010902485f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cde9e1-c552-468a-a84f-5f8532d88cdd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Testing the decoder which is `OurPoolingAttentionCalssifier`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b70cba84-87cd-4d20-97fe-3e5cdfc53b06",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# out, mask, preds, model, encoder, decoder, x, y, dls_clas, learn, m, out_concat_pool = None, None, None, None, None, None, None, None, None, None, None, None\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c203e8c-4d84-4363-8ada-c5fa8de3629e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds, _, _ = decoder((out, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b6256c9-9fc3-4da7-beff-73c413dc1521",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6594])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bfa54-0cb8-40bb-8114-340a85274a5d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1732def1-038e-4c24-804a-ac5f51e47d52",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# var = locals().get('out_concat_pool', 'Shit!!!')\n",
    "# print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ebdb917d-90c5-4a91-97f5-3408714f3621",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x, y, encoder, dls_clas, out, mask, ind_var = None, None, None, None, None, None, None\n",
    "# import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef118554-9522-4a44-92d8-201627cab2b9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "021fd3e9-b533-4d14-a10a-b1f8b14a7351",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 400, 6594)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, emb_sz, n_out = 128, 400, get_c(dls_clas)\n",
    "bs, emb_sz, n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ddf867-81e8-4a42-b3d3-82cdcb13314c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`out` is the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e67d9ee4-876e-4b99-99ef-dca63b291566",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1406, 400])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = torch.randn(bs, 1406, emb_sz, dtype=torch.float)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "904c1c82-d0ca-41f0-a207-08ada45359bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659ac13-2b44-4c67-96d3-4b47e507ccd4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- The `out` is the memory: `(bs, sl, nh)`\n",
    "- meaning of the dimensions:\n",
    "    * For each of the 128 documents we are focussing on the last 1406 tokens each having a hidden vector of length 400\n",
    "- Let us say before predicting a label we want to know which part of the memory we want to pay attention to for that particular label\n",
    "- We need to compute the attention weights for each of the `sl` many `(bs,nh)`\n",
    "- The shape of the attention weights would be `bs,sl`\n",
    "---\n",
    "- To compute the attention weights we will use a mini \"neural network\"\n",
    "- **What would be the input to this mini-nn? The input to this neural network would be that particular label embedding that we want to predict**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4c8b54c3-3db6-4fee-89a5-1183e0eab0d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "n_labels = n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "427469cf-122a-4395-af77-6e32e378ecbd",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "label_emb_sz = 49\n",
    "emb_label = nn.Embedding(n_labels, emb_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dfccb095-479c-4f03-80b5-f193eee1d9c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_label.weight.data = emb_label.weight.type(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2f0cf09f-731e-4f62-be53-1b0617088f75",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_label.weight.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "65750da8-c7d0-444d-aca9-591f732340ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_label.__dict__\n",
    "# [o for o in dir(emb_label) if not o.startswith(\"__\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d3fa30a2-c608-40d8-93df-0e70e14feee6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(6594, 400)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "20d87ca9-b07a-4ac3-921b-1b1c53a42e3a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x = torch.randint(0,5,(10,5))\n",
    "# x.shape, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5af0ea45-0c4d-440a-a3f9-a813cd69c8e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# emb_label(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c0629-8653-44bf-81e0-627bcd235a9f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "33e85231-a914-40cf-8bc0-f75e678b869a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# torch.arange(5)[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a710a119-0626-4236-b485-e6427bf9c3f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# torch.ones(5, bs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9060ee0f-25ba-4b9f-bf23-575fcafb1e74",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# labels = torch.ones(bs, 5, dtype=torch.int64) * torch.arange(5)\n",
    "# labels.shape, labels.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c6299b1e-813e-404d-9899-e13c0b0bda66",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "label_indices = torch.arange(n_labels)\n",
    "labels = label_indices.repeat(128, 1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6a792-d7f2-427a-9cb4-ec29e6e81bef",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note: In `labels`,\n",
    "- 0th axis is bs\n",
    "- 1st axis is label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "47b9d3d9-bccd-44b5-b6a2-3f2a98f29a21",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        ...,\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593],\n",
       "        [   0,    1,    2,  ..., 6591, 6592, 6593]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels[:10, :]\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "12446676-dde2-463f-a73b-dd87e97f34d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# a_label = labels[:,0]\n",
    "# a_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb40aee-791d-48dc-89e3-34980c768030",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d13ee777-8833-4f56-a788-859035cd5de5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "after_grabbing_label_embedding = emb_label(labels)\n",
    "after_grabbing_label_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a5db87f9-6e87-476d-bf5e-1bb29b22da0c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.getsizeof(after_grabbing_label_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40591db4-7a6d-4126-a6f5-d53435922bec",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2bfbd58c-90ff-424f-8f58-d650ddc90315",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# a = torch.randint(0, 5, size=(3,2,4))\n",
    "# b = torch.randint(0, 5, size=(4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8a1ccb93-0ece-472f-aaaa-e3c21f5787a0",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "24738d52-c8ec-443a-a79a-b3e35fd74eaa",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1816775e-ad67-42db-8765-19a9f17c7bcc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (a@b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d797f899-4108-447e-ba24-0388dcd9a663",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (a@b).permute(1,0,2).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a85b56-87f2-4a11-93ec-b8ccfcde5590",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b4fe5-5e0d-4e50-8689-024b875a2b9b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Step 0 of mini-nn:* `after_grabbing_label_embedding` is the input to the mini-nn which will answer the following question:   \n",
    "\n",
    "**Which part of the memory `out` should I pay attention before making a prediction about a label**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cb457-2ba7-4617-b119-8c4dc088e0f6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Step 1 of mini-nn: Doing the first matrix multiply:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cc3cf029-feff-4636-b1f0-cc36aadd4b6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=400, out_features=400, bias=True)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "lin = nn.Linear(emb_sz, emb_sz)\n",
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4e62ae17-d8b3-46d7-9b5f-2f369c1df2bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lin.weight.data = lin.weight.type(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7abc9c04-ddf7-4b99-b38e-8a93544075ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6594, 400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "print(after_grabbing_label_embedding.shape)\n",
    "after_first_matmul = lin(after_grabbing_label_embedding)\n",
    "after_first_matmul.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb57842-993f-42c9-9d80-992124cca0d6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At this point the axes mean the following:\n",
    "- 0th axis is the bs\n",
    "- 1st axis is label\n",
    "- 2nd axis is emb_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ea1d649-fefa-43ea-ab7d-f8ff80ec6dbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# after_first_matmul = after_first_matmul.permute(1,0,2).contiguous()\n",
    "# after_first_matmul.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0146a77-1a0b-4a50-88fd-c948b40798e0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Think of it this way:  \n",
    "In each of the 128 documents, each of the 6594 labels has a representation vector of length 400."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83004f66-044d-4ec4-af4d-cfee287b26a6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Step 2 of mini-nn: Applying non-linearity:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4f2a9-6f24-420a-beb9-6ec89aaccf53",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But before applying a non-linearity we want to add the `after_first_matmul` to the entire memory `out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d5623d1d-8d5a-4a49-9a09-e1e9524eb922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1406, 400])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b68a6-e4f1-4a3f-9a85-90cfe14a3bd4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To this memory we will add a singleton dimension at the 2nd position (think of this as adding a label specific dimension to our memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ff4c62f5-d3c8-4314-900d-960f0ecf0c3a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out[:, :, None].shape = torch.Size([128, 1406, 1, 400])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{out[:, :, None].shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b4a11-d5f8-4b67-b6ef-78a610d3b486",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We want to literally add to our memory the `after_first_matmul`. So to line things up perfectly we add a singleton dimension at the 1st position in `after_first_matmul` (think of this as the token specific dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "744381b5-ce24-4bb6-9b77-491e680fbe88",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after_first_matmul[:,None].shape = torch.Size([128, 1, 6594, 400])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{after_first_matmul[:,None].shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "374e1dc5-cff0-4c81-ace6-c41b3b268809",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# out.type(torch.half), after_first_matmul.type(torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f3f3a663-0bb8-437a-a954-213838b6ec25",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test = after_nonlinearity = torch.tanh(out[:, :50, None] + after_first_matmul[:,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88cbd8-f591-47b4-8bea-d0126235f7d0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7772e7d5-e0d0-4f5a-89c5-8d5febf5a4f8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At this point we are faced with a realistic issue:  \n",
    "We cannot afford to \n",
    "- consider all the 1406 tokens in our memory (stored in `out`), and \n",
    "- have those tokens have a representation length of 400.   \n",
    "Solution: (Like always) We we will have to do a matrix multiplication to preform compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d5be8705-595c-482f-8e5a-a1bf3ea91af5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1406, 400])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a8f79543-e277-4b7f-9839-fee8cb7d9aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=400, out_features=49, bias=True)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "lin_for_rep_red = nn.Linear(emb_sz, label_emb_sz)\n",
    "lin_for_rep_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "339e0183-054c-4e0d-8935-68999fdb9f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1406, 49])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = lin_for_rep_red(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055f6a4-d746-45fa-a95c-159f1337a0a9",
   "metadata": {},
   "source": [
    "Let's also compress the representation length of the the last dimension in `after_first_matmul`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9f6ffab8-811a-481e-af41-58a675a853ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_first_matmul.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3ae4625f-482f-4fbc-aeca-24c0b7433042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 49])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "after_first_matmul = lin_for_rep_red(after_first_matmul)\n",
    "after_first_matmul.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf30c1a-a0c3-4211-b1c7-d75f3d8bd5df",
   "metadata": {},
   "source": [
    "Now, let's compress the number of tokens in `out` from 1406 to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "05ef4aef-0898-4069-acee-30f842fe504c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 49, 1406])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = out.permute(0,2,1).contiguous()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "255f44c5-71fd-4d38-8927-952d25e31ee6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1406, out_features=50, bias=True)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "lin_for_tok_red = nn.Linear(1406, 50)\n",
    "lin_for_tok_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3f895fe7-efdf-4a52-abb8-49aadc9d2d50",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 49, 50])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = lin_for_tok_red(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c32ccfee-5160-4207-b496-890cbf4e62eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50, 49])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out = out.permute(0,2,1).contiguous()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a6e0a-f474-4d0a-9854-8bad43117709",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b3709-f02b-48c3-81c2-fb42a2772a19",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we are good to add `after_first_matmul` to our compressed memory (stored in `out`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "327f7d97-3a17-49f6-b1f3-998da1e655be",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape = torch.Size([128, 50, 49]), after_first_matmul.shape = torch.Size([128, 6594, 49])\n",
      "after_nonlinearity.shape = torch.Size([128, 50, 6594, 49])\n"
     ]
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "print(f\"{out.shape = }, {after_first_matmul.shape = }\")\n",
    "after_nonlinearity = torch.tanh(out[:, :, None] + after_first_matmul[:,None])\n",
    "print(f\"{after_nonlinearity.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356937d1-5d32-4c3f-9f8d-0748fd86e165",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note what each of the dimension of `after_nonlinearity` means:  \n",
    "In each of the **128 documents**, we are focussing on the last **50 (compressed from 1406) tokens**. Each one of those tokens has a **hidden (compressed) represenation vector of length 49** for each of the **6594 labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "63f048cc-e446-4fe3-b6ab-617154cc5f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_nonlinearity.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed80beb-8975-4ed5-b928-5a1d9e0605c4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "10336495-29bb-4b33-b924-c60edc9e0441",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "def init_param(*sz): print(f\"{sz = }\"); return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ca503b28-1950-4065-9a7a-4f2e97994774",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# init_param(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "aec104dd-ef7f-4c55-8968-74f51ef1042c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# init_param(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a825253f-00d6-452d-b419-d60e1a59ee41",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`V` is for the second matrix multiply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3a8d8f02-7975-43f3-94dc-d9515ab70123",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sz = (49,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([49])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "V = init_param(label_emb_sz)\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ede53-accc-491a-8aff-ed11ff4f852c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Step 3 of mini-nn: Doing a second matrix multiply:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "981f8f6a-89c3-4889-9c15-f1aa99255382",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50, 6594])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "attn_wgts = (after_nonlinearity @ V)\n",
    "attn_wgts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e2a18273-bdd1-448a-9ab0-749d4e8c2453",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5042, -0.4067,  0.2481,  ...,  0.4743,  0.6855,  0.3966],\n",
       "         [ 0.3884, -0.3913,  0.1412,  ...,  0.3579,  0.4673,  0.2750],\n",
       "         [ 0.3630, -0.3703,  0.1130,  ...,  0.3201,  0.4854,  0.1989],\n",
       "         ...,\n",
       "         [ 0.5318, -0.3458,  0.2158,  ...,  0.4740,  0.6765,  0.3409],\n",
       "         [ 0.0388, -0.7875, -0.2704,  ...,  0.0134,  0.2340, -0.1294],\n",
       "         [ 0.2823, -0.5718, -0.0493,  ...,  0.2117,  0.4972,  0.1334]],\n",
       "\n",
       "        [[ 0.1241, -0.7451, -0.1825,  ...,  0.0953,  0.2921, -0.0203],\n",
       "         [ 0.2909, -0.5416,  0.0215,  ...,  0.2523,  0.4723,  0.1960],\n",
       "         [ 0.1338, -0.5911, -0.0852,  ...,  0.2431,  0.3780,  0.0520],\n",
       "         ...,\n",
       "         [ 0.7050, -0.1777,  0.4014,  ...,  0.7176,  0.8624,  0.6345],\n",
       "         [ 0.4314, -0.4561,  0.2013,  ...,  0.4348,  0.5315,  0.3565],\n",
       "         [ 0.0490, -0.7727, -0.2656,  ..., -0.0220,  0.2699, -0.0791]],\n",
       "\n",
       "        [[ 0.9006,  0.1438,  0.7388,  ...,  1.0048,  1.0604,  0.8983],\n",
       "         [-0.1268, -0.8799, -0.4262,  ..., -0.1184, -0.0549, -0.2492],\n",
       "         [ 0.3554, -0.4827,  0.0140,  ...,  0.3103,  0.4728,  0.2540],\n",
       "         ...,\n",
       "         [ 0.2301, -0.5883,  0.0694,  ...,  0.3032,  0.3562,  0.1801],\n",
       "         [ 0.5709, -0.1793,  0.3390,  ...,  0.6076,  0.7982,  0.4759],\n",
       "         [ 0.0333, -0.8503, -0.3262,  ..., -0.0097,  0.2433, -0.1648]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_wgts[:3, :7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4573156-44a4-4e66-8971-2dc27230d9a7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that the \n",
    "- 0th axis is for the bs\n",
    "- 1st axis is actual attention wgts\n",
    "- 2nd axis is the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b4368-7881-4d79-8ee3-323bc1963ad6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At this point what we have is the following:  \n",
    "- In all the **128 documents** we have **50 (compressed from 1406) numbers** for each of the **6594 labels**.\n",
    "- These 50 numbers are presumably the amount of *attention* we need to pay to   \n",
    "those **50 tokens** each of which have a **49 (compressed) length** hidden represenation vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfee5b-1966-431b-b479-b32a269954cf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Taking linear combination of the memory (`out`) based on the `attn_wgts` to get `ctx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7bdcf55d-0114-4734-92ce-ae28e87001de",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 50, 49]), torch.Size([128, 50, 6594]))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, attn_wgts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5d90094f-043c-4a4b-8eab-4d57f80dfd1b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 50, 1, 49]), torch.Size([128, 50, 6594, 1]))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out[None,...].shape, attn_wgts[...,None].shape\n",
    "out[:, :, None].shape, attn_wgts[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5b8392b1-2630-4108-ba75-0cb79a0db5b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 50, 6594, 49])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "ctx = (out[:, :, None] * attn_wgts[..., None])\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087bb9e-f541-4869-8daa-8f1ced1f62f4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At this point the meaning of `ctx` is:  \n",
    "For each of the **128 documents**, for each of the **50 (compressed from 1406)** tokens, for each of the **6594 labels** we have a **hidden compressed representation of length 49**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ef1245f1-2b8d-4a74-8fc6-245389ee88d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.7465e-03,  6.1149e-02, -2.2250e-01,  ..., -1.0547e-02, -8.3051e-02, -7.1283e-02],\n",
       "          [-1.4087e-03, -4.9323e-02,  1.7947e-01,  ...,  8.5075e-03,  6.6989e-02,  5.7497e-02],\n",
       "          [ 8.5931e-04,  3.0086e-02, -1.0947e-01,  ..., -5.1895e-03, -4.0863e-02, -3.5073e-02],\n",
       "          ...,\n",
       "          [ 1.6427e-03,  5.7516e-02, -2.0928e-01,  ..., -9.9206e-03, -7.8116e-02, -6.7048e-02],\n",
       "          [ 2.3742e-03,  8.3127e-02, -3.0247e-01,  ..., -1.4338e-02, -1.1290e-01, -9.6903e-02],\n",
       "          [ 1.3736e-03,  4.8094e-02, -1.7500e-01,  ..., -8.2956e-03, -6.5320e-02, -5.6065e-02]],\n",
       "\n",
       "         [[ 1.9480e-01, -1.0085e-01, -6.0489e-02,  ..., -1.6415e-02,  7.1366e-02, -7.5854e-02],\n",
       "          [-1.9623e-01,  1.0160e-01,  6.0934e-02,  ...,  1.6536e-02, -7.1891e-02,  7.6413e-02],\n",
       "          [ 7.0810e-02, -3.6661e-02, -2.1989e-02,  ..., -5.9670e-03,  2.5942e-02, -2.7574e-02],\n",
       "          ...,\n",
       "          [ 1.7948e-01, -9.2922e-02, -5.5732e-02,  ..., -1.5124e-02,  6.5753e-02, -6.9889e-02],\n",
       "          [ 2.3434e-01, -1.2133e-01, -7.2768e-02,  ..., -1.9747e-02,  8.5853e-02, -9.1252e-02],\n",
       "          [ 1.3789e-01, -7.1392e-02, -4.2820e-02,  ..., -1.1620e-02,  5.0519e-02, -5.3696e-02]],\n",
       "\n",
       "         [[ 2.0679e-01, -1.9689e-01,  7.2514e-02,  ..., -7.1185e-03,  4.9860e-02, -1.0741e-01],\n",
       "          [-2.1099e-01,  2.0088e-01, -7.3985e-02,  ...,  7.2628e-03, -5.0871e-02,  1.0959e-01],\n",
       "          [ 6.4356e-02, -6.1273e-02,  2.2567e-02,  ..., -2.2153e-03,  1.5517e-02, -3.3427e-02],\n",
       "          ...,\n",
       "          [ 1.8236e-01, -1.7363e-01,  6.3948e-02,  ..., -6.2775e-03,  4.3970e-02, -9.4721e-02],\n",
       "          [ 2.7656e-01, -2.6331e-01,  9.6979e-02,  ..., -9.5201e-03,  6.6682e-02, -1.4365e-01],\n",
       "          [ 1.1330e-01, -1.0787e-01,  3.9731e-02,  ..., -3.9002e-03,  2.7319e-02, -5.8850e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.4640e-01,  1.5364e-01, -8.2277e-02,  ...,  5.0683e-02,  5.1475e-02,  2.4160e-02],\n",
       "          [-2.2529e-01, -9.9923e-02,  5.3511e-02,  ..., -3.2963e-02, -3.3478e-02, -1.5713e-02],\n",
       "          [ 1.4057e-01,  6.2346e-02, -3.3388e-02,  ...,  2.0567e-02,  2.0889e-02,  9.8043e-03],\n",
       "          ...,\n",
       "          [ 3.0877e-01,  1.3695e-01, -7.3340e-02,  ...,  4.5178e-02,  4.5884e-02,  2.1536e-02],\n",
       "          [ 4.4071e-01,  1.9547e-01, -1.0468e-01,  ...,  6.4483e-02,  6.5490e-02,  3.0738e-02],\n",
       "          [ 2.2204e-01,  9.8483e-02, -5.2740e-02,  ...,  3.2488e-02,  3.2996e-02,  1.5487e-02]],\n",
       "\n",
       "         [[ 2.8909e-02,  2.0587e-03,  6.7105e-04,  ..., -7.5653e-03,  5.1221e-03, -2.0617e-02],\n",
       "          [-5.8716e-01, -4.1812e-02, -1.3629e-02,  ...,  1.5366e-01, -1.0403e-01,  4.1874e-01],\n",
       "          [-2.0164e-01, -1.4359e-02, -4.6806e-03,  ...,  5.2768e-02, -3.5727e-02,  1.4380e-01],\n",
       "          ...,\n",
       "          [ 1.0019e-02,  7.1343e-04,  2.3255e-04,  ..., -2.6218e-03,  1.7751e-03, -7.1448e-03],\n",
       "          [ 1.7445e-01,  1.2423e-02,  4.0495e-03,  ..., -4.5653e-02,  3.0909e-02, -1.2441e-01],\n",
       "          [-9.6473e-02, -6.8699e-03, -2.2394e-03,  ...,  2.5246e-02, -1.7093e-02,  6.8800e-02]],\n",
       "\n",
       "         [[-3.7299e-03,  1.8332e-01, -4.7049e-02,  ..., -3.2168e-02, -9.8785e-02,  1.9971e-02],\n",
       "          [ 7.5544e-03, -3.7129e-01,  9.5291e-02,  ...,  6.5153e-02,  2.0008e-01, -4.0450e-02],\n",
       "          [ 6.5156e-04, -3.2024e-02,  8.2189e-03,  ...,  5.6194e-03,  1.7257e-02, -3.4888e-03],\n",
       "          ...,\n",
       "          [-2.7972e-03,  1.3748e-01, -3.5284e-02,  ..., -2.4124e-02, -7.4083e-02,  1.4977e-02],\n",
       "          [-6.5683e-03,  3.2283e-01, -8.2853e-02,  ..., -5.6648e-02, -1.7396e-01,  3.5170e-02],\n",
       "          [-1.7621e-03,  8.6607e-02, -2.2227e-02,  ..., -1.5197e-02, -4.6669e-02,  9.4351e-03]]],\n",
       "\n",
       "\n",
       "        [[[-2.7754e-02,  3.0815e-02,  2.6581e-02,  ...,  1.4434e-03, -3.0631e-04, -4.1400e-02],\n",
       "          [ 1.6667e-01, -1.8505e-01, -1.5963e-01,  ..., -8.6683e-03,  1.8395e-03,  2.4862e-01],\n",
       "          [ 4.0829e-02, -4.5331e-02, -3.9103e-02,  ..., -2.1234e-03,  4.5060e-04,  6.0902e-02],\n",
       "          ...,\n",
       "          [-2.1310e-02,  2.3660e-02,  2.0409e-02,  ...,  1.1083e-03, -2.3519e-04, -3.1788e-02],\n",
       "          [-6.5336e-02,  7.2541e-02,  6.2574e-02,  ...,  3.3980e-03, -7.2108e-04, -9.7459e-02],\n",
       "          [ 4.5340e-03, -5.0340e-03, -4.3423e-03,  ..., -2.3580e-04,  5.0040e-05,  6.7632e-03]],\n",
       "\n",
       "         [[-2.2598e-02,  5.4780e-03,  4.9353e-02,  ..., -4.6649e-02,  7.7002e-04,  1.2219e-01],\n",
       "          [ 4.2078e-02, -1.0200e-02, -9.1897e-02,  ...,  8.6863e-02, -1.4338e-03, -2.2752e-01],\n",
       "          [-1.6696e-03,  4.0473e-04,  3.6463e-03,  ..., -3.4466e-03,  5.6891e-05,  9.0275e-03],\n",
       "          ...,\n",
       "          [-1.9603e-02,  4.7521e-03,  4.2813e-02,  ..., -4.0468e-02,  6.6798e-04,  1.0600e-01],\n",
       "          [-3.6692e-02,  8.8946e-03,  8.0134e-02,  ..., -7.5744e-02,  1.2503e-03,  1.9840e-01],\n",
       "          [-1.5228e-02,  3.6915e-03,  3.3258e-02,  ..., -3.1436e-02,  5.1890e-04,  8.2339e-02]],\n",
       "\n",
       "         [[-1.1614e-02, -1.4625e-02,  2.2434e-02,  ..., -2.1929e-02, -3.3679e-02, -4.8604e-02],\n",
       "          [ 5.1314e-02,  6.4619e-02, -9.9125e-02,  ...,  9.6894e-02,  1.4881e-01,  2.1475e-01],\n",
       "          [ 7.3930e-03,  9.3100e-03, -1.4281e-02,  ...,  1.3960e-02,  2.1440e-02,  3.0941e-02],\n",
       "          ...,\n",
       "          [-2.1101e-02, -2.6572e-02,  4.0761e-02,  ..., -3.9844e-02, -6.1192e-02, -8.8309e-02],\n",
       "          [-3.2814e-02, -4.1323e-02,  6.3389e-02,  ..., -6.1962e-02, -9.5161e-02, -1.3733e-01],\n",
       "          [-4.5096e-03, -5.6789e-03,  8.7113e-03,  ..., -8.5152e-03, -1.3078e-02, -1.8873e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.7286e-02,  5.7431e-02,  2.1055e-01,  ...,  1.1118e-01,  2.3440e-01,  1.0904e-01],\n",
       "          [-1.9484e-02, -1.4478e-02, -5.3079e-02,  ..., -2.8028e-02, -5.9092e-02, -2.7488e-02],\n",
       "          [ 4.3999e-02,  3.2696e-02,  1.1986e-01,  ...,  6.3294e-02,  1.3344e-01,  6.2075e-02],\n",
       "          ...,\n",
       "          [ 7.8666e-02,  5.8456e-02,  2.1430e-01,  ...,  1.1316e-01,  2.3858e-01,  1.1098e-01],\n",
       "          [ 9.4541e-02,  7.0253e-02,  2.5755e-01,  ...,  1.3600e-01,  2.8673e-01,  1.3338e-01],\n",
       "          [ 6.9557e-02,  5.1688e-02,  1.8949e-01,  ...,  1.0006e-01,  2.1096e-01,  9.8133e-02]],\n",
       "\n",
       "         [[-5.9713e-02, -4.3760e-03,  1.2829e-01,  ...,  9.0876e-02, -7.9220e-02, -1.9887e-02],\n",
       "          [ 6.3125e-02,  4.6261e-03, -1.3562e-01,  ..., -9.6068e-02,  8.3747e-02,  2.1024e-02],\n",
       "          [-2.7866e-02, -2.0421e-03,  5.9870e-02,  ...,  4.2409e-02, -3.6969e-02, -9.2808e-03],\n",
       "          ...,\n",
       "          [-6.0179e-02, -4.4102e-03,  1.2929e-01,  ...,  9.1586e-02, -7.9839e-02, -2.0043e-02],\n",
       "          [-7.3566e-02, -5.3912e-03,  1.5806e-01,  ...,  1.1196e-01, -9.7599e-02, -2.4501e-02],\n",
       "          [-4.9341e-02, -3.6160e-03,  1.0601e-01,  ...,  7.5092e-02, -6.5461e-02, -1.6433e-02]],\n",
       "\n",
       "         [[ 1.2593e-02, -6.9963e-04, -1.8169e-02,  ..., -3.0383e-03,  8.6847e-03, -1.5792e-02],\n",
       "          [-1.9843e-01,  1.1024e-02,  2.8629e-01,  ...,  4.7876e-02, -1.3685e-01,  2.4883e-01],\n",
       "          [-6.8205e-02,  3.7892e-03,  9.8401e-02,  ...,  1.6456e-02, -4.7036e-02,  8.5528e-02],\n",
       "          ...,\n",
       "          [-5.6383e-03,  3.1324e-04,  8.1345e-03,  ...,  1.3603e-03, -3.8884e-03,  7.0704e-03],\n",
       "          [ 6.9322e-02, -3.8513e-03, -1.0001e-01,  ..., -1.6725e-02,  4.7807e-02, -8.6929e-02],\n",
       "          [-2.0307e-02,  1.1282e-03,  2.9297e-02,  ...,  4.8994e-03, -1.4004e-02,  2.5465e-02]]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx[:2, :7, :, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c5d228ea-60ca-428c-88f8-74d09cb3fe96",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 49])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "ctx = ctx.sum(1)\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84f911-b5f0-435b-b083-bfaeee799d25",
   "metadata": {},
   "source": [
    "Now, let's decompress the hidden representation length from 49 back to 400 by doing a non-linearity followed by matrix multiply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "78db654c-d058-4b24-9cb5-1e040099aebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "lin_for_rep_decompress = nn.Linear(label_emb_sz, emb_sz)\n",
    "ctx = lin_for_rep_decompress(torch.relu(ctx))\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd682da-f0e2-4c48-9cb0-1fb942c5aff7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's recap what we have so far `ctx`:  \n",
    "For each of the **128 documents** for each of the **6594 labels** we have a **represenation vector of lenth 400** (we obtained this by paying attention to specific parts of the memory).\n",
    "\n",
    "Now this `ctx` will get concatenated with whatever the decoder was previously using without attention (i.e., the output of `masked_concat_pool`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20a04e-676e-47ac-be70-6dfb46e282a3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "05321591-f331-48c9-9e91-e40876c2a541",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1200])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_concat_pool = torch.randn((128,1200))\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "60fb73a0-444e-4654-bed6-2aa192068d58",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 1200])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out_concat_pool = out_concat_pool[:, None]\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a996a4-638c-4566-8d1b-8c9544becc45",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Think of `out_concat_pool` as the label-agnostic **1200 length represenation** of each of the **128 documents**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bd0c2af5-7d71-4ca4-a797-263c43dc8f4e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1200])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out_concat_pool = out_concat_pool.repeat(1, n_labels, 1)\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "92f06b72-a2ce-4156-b4b9-c9fcde717eee",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 400])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ctx = ctx.permute(1,0,2).contiguous()\n",
    "ctx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9623a84-aa4f-4bef-a977-4c441b5e2871",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Think of `ctx` as label-specific **400 length representation** of each of the **128 documents**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9fd00e84-238b-45a1-983e-05a00d43c30d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1600])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out_concat_pool = torch.cat((out_concat_pool, ctx), dim=-1)\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc1e6d-e011-4f90-bec4-c7ab5025d454",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At this point we can flattan the features before feeding it into the Linear-BatchNorm-Droput layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bcf36463-6335-4e7d-9f3b-a21e67dbc63c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1600])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(128, 6594, 1600)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35b5fb32-ce8c-43a8-99c2-54f27fe17114",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1350451200])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8fca5e78-4459-4b62-87b3-126517b5a93c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10550400])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(t.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4f0b83d7-cc0d-4d14-a837-cc72b14054e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='yellow';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10550400])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_bg('yellow')\n",
    "out_concat_pool = out_concat_pool.view(out_concat_pool.shape[0], -1)\n",
    "out_concat_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e485f8d-c28c-4a2e-a13b-bb3a7d92e1c1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e27cde-85c2-4524-a838-ba2a5809f53d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's see how to perform batchnorm on this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc0b25-a56c-4fba-bc2a-9ec613f7b257",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First let's see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40059eb9-175b-4eb2-963e-daa9ee31e77c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(100)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4431b2f9-9e79-4800-8484-ab9cd7a57f55",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input = torch.randn(20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "816c02f0-1190-4fb6-9f37-2ff53b8fe2f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ec2eab2-b223-4ebc-accf-1b0a0091063f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(18)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26a40f14-7ddd-46c7-865e-103272aebbe9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input = torch.randn(20, 18, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "311e0920-fd33-4672-9771-464eaf2a216f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 18, 100])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "977caac5-29ba-41f9-8ce5-a6319ecbc8a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(6594, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(n_out)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c2341706-d497-4dfa-900c-da5aaf019375",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6594, 1600])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(out_concat_pool).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b125f-d036-46e8-bc93-61d35893ffe6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72c912-8967-4633-b2c7-85a259e7208d",
   "metadata": {
    "hidden": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Practice some ufuncs in PyTorch and Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fb68506f-6a40-4589-a4d1-fbe156fbba38",
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "90deaafc-7d4d-4e5f-b288-d1f619eaacb4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[1,2], [3,4]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0a3a286d-111c-44d1-a5a4-3b9c29dd2de8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 3, 3, 4, 4])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(arr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5b0b04ad-993c-4ab7-b4e7-6f5d0fd95713",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 2, 2],\n",
       "       [3, 3, 3, 4, 4, 4]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(arr, 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d2299454-2b0f-4dea-9703-cd6164e425e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(arr, [1, 2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5ffe813a-a31b-45cd-b726-69364d4b88aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), 1, (3,))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0, 1, 2])\n",
    "a, a.ndim, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6de2543f-eb7e-4745-9909-d298b15152fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f416a2a1-36e2-43f3-9657-62e302870258",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
       "       [0, 1, 2, 0, 1, 2, 0, 1, 2]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a, (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5b3815c6-1023-45ba-8c99-652ffca70cc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 2, 0, 1, 2]],\n",
       "\n",
       "       [[0, 1, 2, 0, 1, 2]]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a, (2,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "219a77dd-85b9-4a66-aaf8-d7f11e1862c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2],\n",
       "        [3, 4]]),\n",
       " (2, 2),\n",
       " 2)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[1,2], [3, 4]])\n",
    "b, b.shape, b.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3c8afa99-7d82-4365-8a0e-ba9cd22e5914",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 2],\n",
       "       [3, 4, 3, 4]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(b,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7df80114-cbdf-41a2-b9de-b6ce912949bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(b, (2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "191b2932-d89b-4162-80d1-d06144726e24",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 2, 1, 2],\n",
       "       [3, 4, 3, 4, 3, 4],\n",
       "       [1, 2, 1, 2, 1, 2],\n",
       "       [3, 4, 3, 4, 3, 4]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(b, (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0c949d42-5532-4ff7-a65c-0df0cb8c0cbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([1, 2, 3, 4])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dd3a8eac-dfaa-46c1-9d39-45d5f8069706",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
       "       [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
       "       [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4],\n",
       "       [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(c, (4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77466149-4581-4935-bb7e-8f94cbcaf05c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "73c49c9c-a1f4-410d-bbec-0f99fc866154",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 4, 0, 3, 1],\n",
       "         [3, 1, 3, 0, 3, 2],\n",
       "         [3, 2, 1, 0, 1, 0]]),\n",
       " torch.Size([3, 6]))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randint(0, 5, (3,6))\n",
    "t, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0fd9f19e-1039-4be8-b8df-9ddb8fac7fa7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 1, 4, 0, 3, 1]],\n",
       " \n",
       "         [[3, 1, 3, 0, 3, 2]],\n",
       " \n",
       "         [[3, 2, 1, 0, 1, 0]]]),\n",
       " torch.Size([3, 1, 6]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t[:, None]\n",
    "t, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "31ccecb7-3520-4f63-90ba-fbf4fbe92f98",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 4, 0, 3, 1],\n",
       "         [1, 1, 4, 0, 3, 1],\n",
       "         [1, 1, 4, 0, 3, 1],\n",
       "         [1, 1, 4, 0, 3, 1],\n",
       "         [1, 1, 4, 0, 3, 1]],\n",
       "\n",
       "        [[3, 1, 3, 0, 3, 2],\n",
       "         [3, 1, 3, 0, 3, 2],\n",
       "         [3, 1, 3, 0, 3, 2],\n",
       "         [3, 1, 3, 0, 3, 2],\n",
       "         [3, 1, 3, 0, 3, 2]],\n",
       "\n",
       "        [[3, 2, 1, 0, 1, 0],\n",
       "         [3, 2, 1, 0, 1, 0],\n",
       "         [3, 2, 1, 0, 1, 0],\n",
       "         [3, 2, 1, 0, 1, 0],\n",
       "         [3, 2, 1, 0, 1, 0]]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.repeat(1, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292d21a-04c1-49b5-b990-03245c448d13",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22367468-375d-4187-8ea6-0f7c506dd456",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[1], [2], [3]])\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b7d7d31-b1de-4a01-876e-4077028d8d3c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.expand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6152da6b-d733-48a6-88cd-cb3f80354938",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (5) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [5, 3].  Tensor sizes: [3, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4561/3650102684.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (5) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [5, 3].  Tensor sizes: [3, 1]"
     ]
    }
   ],
   "source": [
    "b.expand(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff63a55-1994-457a-b6d9-7daecea2dcf3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959236d5-4ec7-4d56-97c0-8123c1858da0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `Learner` Creation: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a2e71-7875-4c9d-aad6-94424b045b3f",
   "metadata": {},
   "source": [
    "In this section we will replicate all the steps in `text_classifier_learner`:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae0dc836-6704-4b5e-8dbe-776240667074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.1, metrics=[precision_at_k, precision_at_r]).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b667a6-4fb0-4920-838d-fa8d98663826",
   "metadata": {},
   "source": [
    "There are three things that happens inside `text_classifier_learner`\n",
    "- create the `model` - we have already done this in the previous section\n",
    "- create a `Learner` using `TextLearner`\n",
    "    * `TextLearner` is a Basic class for a `Learner` in NLP.\n",
    "    * Adds a `ModelResetter` and an `RNNRegularizer` with `alpha` and `beta` to the callbacks, the rest is same as `Learner` init.\n",
    "    * Adding functionality to the base class, it has the methods - `load_pretrained`, `save_encoder` and `load_encoder`.\n",
    "- load the pretrained weights (grabbing that information from `_model_meta`) into the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41d4bdfd-44e2-40bd-9797-91ea687aece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = _model_meta[arch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08175f09-7fe8-4b21-bf93-dad7557b8f00",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Metrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79c4513f-c0a5-47dc-967b-b2d0175f018d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def precision_at_k(yhat_raw, y, k=15):\n",
    "    \"\"\"\n",
    "        Inputs: \n",
    "            yhat_raw: activation matrix of ndarray and shape (n_samples, n_labels)\n",
    "            y: binary ground truth matrix of type ndarray and shape (n_samples, n_labels)\n",
    "            k: for @k metric\n",
    "    \"\"\"\n",
    "    yhat_raw, y = to_np(yhat_raw), to_np(y)\n",
    "    # num true labels in the top k predictions / k\n",
    "    sortd = yhat_raw.argsort()[:,::-1]\n",
    "    topk = sortd[:, :k]\n",
    "    \n",
    "    # get precision at k for each sample\n",
    "    vals = []\n",
    "    for i, tk in enumerate(topk):\n",
    "        num_true_in_top_k = y[i,tk].sum()\n",
    "        vals.append(num_true_in_top_k / float(k))\n",
    "    \n",
    "    return np.mean(vals)\n",
    "\n",
    "def precision_at_r(yhat_raw, y):\n",
    "    \"\"\"\n",
    "        Inputs: \n",
    "            yhat_raw: activation matrix of ndarray and shape (n_samples, n_labels)\n",
    "            y: binary ground truth matrix of type ndarray and shape (n_samples, n_labels)\n",
    "    \"\"\"\n",
    "    yhat_raw, y = to_np(yhat_raw), to_np(y)\n",
    "    # num true labels in the top r predictions / r, where r = number of labels associated with that sample \n",
    "    sortd = yhat_raw.argsort()[:, ::-1]\n",
    "    \n",
    "    # get precision at r for each sample\n",
    "    vals = []\n",
    "    for i, sorted_activation_indices in enumerate(sortd):\n",
    "        # compute the number of labels associated with this sample\n",
    "        r = int(y[i].sum())\n",
    "        top_r_indices = sorted_activation_indices[:r] \n",
    "        num_true_in_top_r = y[i, top_r_indices].sum()\n",
    "        vals.append(num_true_in_top_r / float(r))\n",
    "    \n",
    "    return np.mean(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd13c3-90a8-44df-b443-488d58ae4ccc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `TextLearner`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27ef81-b8ea-4ec8-8983-ecf1a2f523af",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's create the `Learner` (we can pass our metrics here:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79f7550c-daf7-4ec6-90d3-d8721d6cce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = TextLearner(dls_clas, model, splitter=meta['split_clas'], metrics=[precision_at_k, precision_at_r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13b51a-d279-44cc-81f4-7ff8445d01d6",
   "metadata": {},
   "source": [
    "Note that in this case fastai was clever to figure out the correct loss (`BCEWithLogitsLoss`) from the `Dataloaders dls_clas`! We could overide this cleverness by specifically passing a `loss_func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6864cd17-5295-4562-af02-781b06b6935f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlattenedLoss of BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0986c468-5cba-4a70-89f8-c822e095bb1a",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pretrained Weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d0fd7-b01e-4c59-98df-754cfd14f4cb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's replace the random weights of the encoder using the pretrained weights (from the url in meta). Note that in this case we can skip this step, because we are anyway later on going to load the encoder weights from our finetuned language model. But let's not skip this step for completeness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cf5848d-8cb4-4585-b0b9-9f94f5187e2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backwards = False\n",
    "url = 'url_bwd' if backwards else 'url'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287221d-55c0-40bf-9c2e-e3ad282879d2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's check if we have pretrained weights for that `arch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdf38318-d15a-4477-b3e6-818c53046e1c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if url not in meta: warn(\"There are no pretrained weights for that architecture yet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747e764-a3a8-4ef6-adc1-f62086d0b3b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get the path which contains the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e305a4c1-cac1-4eb3-9ee0-0f52aeadf152",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/ubuntu/.fastai/models/wt103-fwd/lstm_fwd.pth'),Path('/home/ubuntu/.fastai/models/wt103-fwd/itos_wt103.pkl')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_path = untar_data(meta[url], c_key='model')\n",
    "pretrained_model_path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c797431-ccf3-47ac-9e0f-4b09f915865c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's get the weights of the pretrained model and the vocab that was used to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bf1b3d0-de1c-47a2-88fb-c75edde22b6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('/home/ubuntu/.fastai/models/wt103-fwd/lstm_fwd.pth'),\n",
       " Path('/home/ubuntu/.fastai/models/wt103-fwd/itos_wt103.pkl'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = [list(pretrained_model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "wgts_fname, vocab_fname = fnames\n",
    "wgts_fname, vocab_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5336d94-50b9-4757-bfc2-0e6dc4a9b484",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Just for fun why don't we take a look at the pretrained weights and the vocab that got used to train that model:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "758125d3-814d-4cc0-ab49-c00067963e05",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(collections.OrderedDict, list)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_wgts, old_vocab = torch.load(wgts_fname), load_pickle(vocab_fname)\n",
    "type(pretrained_wgts), type(old_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3f5614e-24ed-4e3e-b8b5-8299c4b97d87",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.encoder.weight  0.encoder_dp.emb.weight  0.rnns.0.weight_hh_l0_raw  0.rnns.0.module.weight_ih_l0  0.rnns.0.module.weight_hh_l0  0.rnns.0.module.bias_ih_l0  0.rnns.0.module.bias_hh_l0  0.rnns.1.weight_hh_l0_raw  0.rnns.1.module.weight_ih_l0  0.rnns.1.module.weight_hh_l0  0.rnns.1.module.bias_ih_l0  0.rnns.1.module.bias_hh_l0  0.rnns.2.weight_hh_l0_raw  0.rnns.2.module.weight_ih_l0  0.rnns.2.module.weight_hh_l0  0.rnns.2.module.bias_ih_l0  0.rnns.2.module.bias_hh_l0  1.decoder.weight  1.decoder.bias  "
     ]
    }
   ],
   "source": [
    "for key in pretrained_wgts: print(key, end='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94eca295-b858-4f51-aeb8-1e378a0f0970",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#60000) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxmaj','xxup','xxrep','xxwrep','the',',','.','of','and','in','to','a','=','\"','was','on','-',\"'s\",'as','for','that','with','by','\\n ',')','(','\\n \\n ','is','his','at','he','it','from','were','an','had','which','be','this','but',\"'\",'are','not','first','their'...]\n"
     ]
    }
   ],
   "source": [
    "print(coll_repr(old_vocab, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef7eea5-eb46-44f7-918c-0922a314f6ef",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we write that magic line which will replace the random weights in our `encoder` i.e., `learn.model[0]`, with the `pretrained_wgts`.  \n",
    "\n",
    "**IMPORTANT**: We need to pass the\n",
    "- `wgts_fname`,\n",
    "- and the `vocab_fname`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea2389dd-f511-4986-9da3-20ce93c4bb31",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#learn.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b5a2c02-8fe0-4250-a4b8-2d6bd0751967",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = learn.load_pretrained(wgts_fname, vocab_fname, model=learn.model[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70b005-00a0-4d02-9d7b-167467e0657f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Additionally, we also need to freeze the `encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5889db8-8fc5-420d-97c1-65b14e355d7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743145c-7d73-4665-9c05-b6f8e5efd61e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Also, to do mixed precision training, we need the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "814a79d8-493d-4bdc-a858-d416bddf5717",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1734e-9c8a-43d4-bca1-2b64c9ea3896",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### LM weights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897fca5-fb38-4124-b0fa-28909503091b",
   "metadata": {},
   "source": [
    "Additionally, we also need to freeze the `encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1550a3f-743f-459b-a676-45301d5526bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6ceee0-8ab9-4fbb-8b32-af5f412d16e4",
   "metadata": {},
   "source": [
    "Also, to do mixed precision training, we need the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "791ef72f-2868-4cf8-b491-6ed35dcde758",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f3364-a146-4539-a1d8-205058abbe29",
   "metadata": {},
   "source": [
    "**IMPORTANT:**  \n",
    "This is where the \"Magic\" happens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c4e70b-a8e3-42d1-9260-ef6de0ea1ed5",
   "metadata": {},
   "source": [
    "The final step prior to training the classifier is to load the encoder from our fine-tuned language model. We will use `load_encoder` instead of `load` because we have only the pretrained weights available for the encoder; `load` by default raises an exception if an incomplete model is loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9a1cebd-3029-4dd9-8b5e-a4c79fc855de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls -lht {path_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ef5fbcb-13bb-49ff-8599-2392467c17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load_encoder(path_model/'lm_finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274cc2b3-e8ff-4aae-bfd2-d29d1b7301b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine-Tuning the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53ac2f-0631-4b89-867e-96eed90b8adc",
   "metadata": {},
   "source": [
    "The last step (yes, the madness will end soon) is to train with:\n",
    "- *discriminative learning rates*: what the *** is this?\n",
    "- *gradual unfreezing*: what the *** is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010625c4-ea48-467c-944a-a926823826c7",
   "metadata": {},
   "source": [
    "Application specific `Learner` (in our case `TextLearner`) does call `freeze` for us, but still ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f135ec4-7ee7-42ae-b9bc-8fc4d81f73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0855bd0-3508-458b-9f0b-a072ec0efd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "lr_min, lr_steep, lr_valley, lr_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dfa4f85-cdfa-47da-9832-89fb7532ea87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f2d03f4-d4df-4d6f-ac38-e2b931e6f06a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>precision_at_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='231' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/231 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.93 GiB (GPU 0; 14.76 GiB total capacity; 12.76 GiB already allocated; 807.75 MiB free; 12.96 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8247/1579288732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#with learn.parallel_ctx():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(f\"Training in {learn.parallel_ctx.__name__} context on GPU {list(range(n_gpu))}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    114\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    115\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/menv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8247/2251649633.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_for_tok_red\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mafter_nonlinearity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mafter_first_matmul\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mattn_wgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mafter_nonlinearity\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mattn_wgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.93 GiB (GPU 0; 14.76 GiB total capacity; 12.76 GiB already allocated; 807.75 MiB free; 12.96 GiB reserved in total by PyTorch)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_8247/2251649633.py\u001b[0m(39)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     37 \u001b[0;31m        \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_for_tok_red\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m        \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 39 \u001b[0;31m        \u001b[0mafter_nonlinearity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mafter_first_matmul\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     40 \u001b[0;31m        \u001b[0mattn_wgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mafter_nonlinearity\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     41 \u001b[0;31m        \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mattn_wgts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%pdb\n",
    "#with learn.parallel_ctx():\n",
    "# print(f\"Training in {learn.parallel_ctx.__name__} context on GPU {list(range(n_gpu))}\")\n",
    "learn.fit_one_cycle(1, lr_max=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d50ff87-d559-434d-975d-82c7c3937a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = None\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dccbc19-c81e-480b-a350-bf51451a728f",
   "metadata": {},
   "source": [
    "This was the result after just three epochs. Now let's unfreeze the last two layers and do discriminative training:  \n",
    "\n",
    "Now we will pass -2 to `freeze_to` to freeze all except the last two parameter groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c174876d-5895-460b-94d6-8138d0721644",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68653ae-73e9-4d1a-8e19-e06a894d027b",
   "metadata": {},
   "source": [
    "Then we will run `lr_find` again, because we now have more layers to train and the weights have also been trained for 2 epochs; meaning the old learning_rate isn't valid anymore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9c8cc62-a554-4652-b770-308833ac56a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.0002511886414140463,\n",
       " 1.0964781722577754e-06,\n",
       " 0.0002754228771664202,\n",
       " 0.05754399299621582)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "lr_min, lr_steep, lr_valley, lr_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd157898-01bd-49ab-9afd-6d36ab5da8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>precision_at_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.010221</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.286823</td>\n",
       "      <td>0.273428</td>\n",
       "      <td>03:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=lr_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4661d6-857c-45ff-a794-c20e922b4429",
   "metadata": {},
   "source": [
    "Now we will unfreeze a bit more, recompute learning rate and continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c8eb628-85bf-4e0e-aea3-fa878d5b7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94902577-44fb-445f-8a4b-7c2bcb127af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.002290867641568184,\n",
       " 1.3182567499825382e-06,\n",
       " 0.002511886414140463,\n",
       " 0.05754399299621582)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "lr_min, lr_steep, lr_valley, lr_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a38f7b03-b436-47ac-87d5-8b776c3637f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>precision_at_r</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>0.288866</td>\n",
       "      <td>0.278189</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.289411</td>\n",
       "      <td>0.280370</td>\n",
       "      <td>03:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.295948</td>\n",
       "      <td>0.284182</td>\n",
       "      <td>03:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, lr_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5101bd9-d2ca-40df-840d-2052ab42e52c",
   "metadata": {},
   "source": [
    "Finally, we will unfreeze the whole model, recompute learning rate and perform training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a9044-361b-4e24-a1f0-e6896a3e1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4976cf2-b11c-401a-bc67-9f54efb0a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\n",
    "lr_min, lr_steep, lr_valley, lr_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d137b-0386-4352-ad0b-419a5cba9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:menv]",
   "language": "python",
   "name": "conda-env-menv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
