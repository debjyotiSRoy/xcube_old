# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_collab.ipynb (unless otherwise specified).

__all__ = ['CollabLearner', 'collab_learner']

# Cell
from fastai.tabular.all import *
from fastai.collab import *

# Cell
class CollabLearner(Learner):
    "Basic class for a `Learner` in Collab."
    def save(self, file, **kwargs):
        "Save model and optimizer state (if `with_opt`) to `self.path/self.model_dir/file`"
        file = join_path_file(file, self.path/self.model_dir, ext='.pth')
        vocab_file = join_path_file('collab_vocab', self.path/self.model_dir, ext='.pkl')
        save_model(file, self.model, getattr(self,'opt', None), **kwargs)
        save_pickle(vocab_file, self.dls.classes)
        return file

# Cell
@delegates(Learner.__init__)
def collab_learner(dls, n_factors=50, use_nn=False, emb_szs=None, layers=None, config=None, y_range=None, loss_func=None, **kwargs):
    "Create a Learner for collaborative filtering on `dls`."
    emb_szs = get_emb_sz(dls, ifnone(emb_szs, {}))
    if loss_func is None: loss_func = MSELossFlat()
    if config is None: config = tabular_config()
    if y_range is not None: config['y_range'] = y_range
    if layers is None: layers = [n_factors]
    if use_nn: model = EmbeddingNN(emb_szs=emb_szs, layers=layers, **config)
    else:      model = EmbeddingDotBias.from_classes(n_factors, dls.classes, y_range=y_range)
    return CollabLearner(dls, model, loss_func=loss_func, **kwargs)